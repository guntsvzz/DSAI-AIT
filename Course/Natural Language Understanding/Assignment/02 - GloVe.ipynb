{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - GloVe : Global Vectors for Word Representation\n",
    "Constraint: Only use our code (not other code....)\n",
    "\n",
    "1. I guess you already try a bigger corpus\n",
    "2. I guess you already try window size 2\n",
    "3. I guess you already have skipgram, skipgram(neg), cbow, glove\n",
    "\n",
    "Do this:\n",
    "1. Compare them based on syntactic accuracy and semantic accuracy, similar to how is done in https://nlp.stanford.edu/pubs/glove.pdf (see Table 2) - NO NEED to try 1000 or 300 embed size.....I just want you to learn how to do experiment.....\n",
    "2. Try to find a correlation with just ONE similarity dataset (which humans judge how similar is two words.....)\n",
    "\n",
    "Point criteria:\n",
    "0:  Not done\n",
    "1: ok\n",
    "2: with comments / explanation / figures just like how Chaky explain thing....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compare them based on syntactic accuracy and semantic accuracy, \n",
    "- similar to how is done in https://nlp.stanford.edu/pubs/glove.pdf (see Table 2) \n",
    "- NO NEED to try 1000 or 300 embed size.....I just want you to learn how to do experiment....."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "A real corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Guntsv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4623"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Set\n",
    "# Use corpus from nltk\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "corpus_tokenized = nltk.corpus.brown.sents(categories='news')\n",
    "len(corpus_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', \"atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['the', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'city', 'executive', 'committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.']]\n"
     ]
    }
   ],
   "source": [
    "#1. tokenize\n",
    "corpus_tokenized = [[word.lower() for word in sent] for sent in corpus_tokenized]\n",
    "print(corpus_tokenized[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13113"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. numericalize (vocab)\n",
    "#2.1 get all the unique words\n",
    "#we want to flatten unit (basically merge all list)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs = list(set(flatten(corpus_tokenized)))\n",
    "\n",
    "#2.2 assign id to all these vocabs\n",
    "word2index = {v: idx for idx, v in enumerate(vocabs)}\n",
    "\n",
    "#adding unknown word\n",
    "vocabs.append('<UNK>')\n",
    "word2index['<UNK>'] = len(vocabs) - 1\n",
    "\n",
    "voc_size = len(vocabs)\n",
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13113])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparing all_vocabs\n",
    "batch_size = 2\n",
    "\n",
    "def prepare_seqeunce(seq, word2index):\n",
    "    #map(fucntion, list of something)\n",
    "    #map will look at each of element in this list, and apply this function\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "all_vocabs = prepare_seqeunce(list(vocabs),word2index).expand(batch_size, voc_size)\n",
    "all_vocabs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = {v:k for k,v in word2index.items()}\n",
    "# index2word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 GloVe\n",
    "<img src =\"figures/glove.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Co-occurence Matrix X\n",
    "\n",
    "Count the occurrences of pair of words using window size of 1 (you can use 2, 3, 4, up to you)\n",
    "\n",
    "E.g., Dog loves to eat meal.\n",
    "\n",
    "['Dog','loves',1],['loves','to',1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Counter to first count stuffs\n",
    "from collections import Counter\n",
    "# print(corpus_tokenized)\n",
    "\n",
    "#count the frequency of each word\n",
    "#we somehow need this to claiclate the probability Pi\n",
    "X_i = Counter(flatten(corpus_tokenized)) #merge all list ... (flattten is a function I defines)\n",
    "# X_i['apple'] #get the probability of apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_grams = []\n",
    "cbows = []\n",
    "window_size = 2\n",
    "#for each corpus\n",
    "for sent in corpus_tokenized:\n",
    "    for i in range(1,len(sent)-window_size): #start from 2 to second last\n",
    "        context_word = []\n",
    "        # print(sent[i])\n",
    "        center_word = sent[i]\n",
    "        for j in range(window_size):\n",
    "            outside_word = [sent[i-j-1],sent[i+j+1]] #window_size adjustable\n",
    "            #here we want to create (banana, apple), (banana, fruit) append to some list\n",
    "            for o in outside_word:\n",
    "                context_word.append(o)\n",
    "                skip_grams.append((center_word,o))\n",
    "            cbows.append((context_word,center_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we have these occcurences, we can count, to make our co-occurence matrix!!!\n",
    "X_ik_skipgram = Counter(skip_grams)\n",
    "# X_ik_skipgram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Weighting function f\n",
    "\n",
    "GloVe includes a weighting function to scale down too frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting(w_i,w_j,X_ik): #we need w_i and w_j, because we can try its-co-occurrences, if it's too big, we scale it down\n",
    "    #check whether the co-occurrences between these two word exits??\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i,w_j)]\n",
    "    except:\n",
    "        x_ij = 1 #why one, so that the probability thingly won't break....\n",
    "    \n",
    "    #maximum co-occurrences; we follow the paper\n",
    "    x_max = 100\n",
    "    alpha = 0.75\n",
    "\n",
    "    #if the co-occurrences does not exceed x_max, cale it down based on some alpha\n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max)**alpha\n",
    "    else:\n",
    "        result = 1 #this is the maximum probability you can havve\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now apply this weighting to all possible pairs\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "X_ik = {} #for keeping the co-occurrences\n",
    "weighting_dic = {} #for keeping all the probability after passing through the weighting function\n",
    "\n",
    "for bigram in combinations_with_replacement(vocabs,2): #we need to also think its reverse\n",
    "    # print(bigram)\n",
    "    #if this bigram exists in X_ik_skipgrams\n",
    "    #we gonna add this to our c-occurence matrix\n",
    "    if X_ik_skipgram.get(bigram) is not None:\n",
    "        cooc = X_ik_skipgram[bigram] #get the co-occurrences\n",
    "        X_ik[bigram] = cooc + 1 #this is agian basically label smoothing.... (stability issue (especailly when divide something))\n",
    "        X_ik[(bigram[1],bigram[0])] = cooc + 1 #trick to get all pairs\n",
    "    else: #otherwise, do nothing\n",
    "        pass\n",
    "    #apply the weighting function using this co-occurrence matrix thingly\n",
    "    weighting_dic[bigram] = weighting(bigram[0],bigram[1],X_ik)\n",
    "    weighting_dic[(bigram[1],bigram[0])] = weighting(bigram[1],bigram[0],X_ik)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3. Prepare train data\n",
    "You move the window along, and create those tuples as we said in class\n",
    "\n",
    "\n",
    "<img src = \"figures/glove_weighting_func.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def random_batch(batch_size,word_sequence,skip_grams,X_ik,weighting_dic):\n",
    "    #loop through skipgram, and change it id because when sending model, it must number \n",
    "    skipg_grams_id = [(word2index[skip_gram[0]],word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
    "    #randomly pick 'batch_size' indexes\n",
    "    number_of_choices = len(skipg_grams_id)\n",
    "    random_index = np.random.choice(number_of_choices, batch_size, replace=False) #no repeating indexes among  these random indexes\n",
    "    \n",
    "    # print(random_index)\n",
    "    random_inputs = [] #xi, wi (in batches)\n",
    "    random_labels = [] #xj, wj (in batches)\n",
    "    random_coocs  = [] #xij (in batches)\n",
    "    random_weighting = [] #f(xij) (in batches)\n",
    "    #for each of the sample in these indexes\n",
    "    for i in random_index:\n",
    "        random_inputs.append([skipg_grams_id[i][0]]) #same reason why I put bracket here....\n",
    "        random_labels.append([skipg_grams_id[i][1]])\n",
    "\n",
    "        #get coocs\n",
    "        #first check whether it exists.....\n",
    "        pair = skip_grams[i] #e.g., ['banana','fruit']\n",
    "        try:\n",
    "            cooc = X_ik[pair]\n",
    "        except:\n",
    "            cooc = 1 #label smoothing\n",
    "\n",
    "        random_coocs.append([math.log(cooc)]) #1. why log, #2 why bracket -> size ==> (,1) #my neural network excepts (,1)\n",
    "        \n",
    "        #for weighting\n",
    "        weighting = weighting_dic[pair] #why not user try... maybe it does not exist\n",
    "        random_weighting.append(weighting)\n",
    "\n",
    "    return np.array(random_inputs),np.array(random_labels),np.array(random_coocs),np.array(random_weighting)\n",
    "        #return xi,xj\n",
    "        #return cooc Xij\n",
    "        #return weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2168],\n",
       "        [12614]]),\n",
       " array([[ 561],\n",
       "        [5275]]),\n",
       " array([[0.69314718],\n",
       "        [0.69314718]]),\n",
       " array([0.05318296, 0.05318296]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input, target, coocs, weightin = random_batch(batch_size,corpus_tokenized,skip_grams,X_ik,weighting_dic)\n",
    "input, target, coocs, weightin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model will accept three vectors - u_o, v_c, u_w\n",
    "#u_o - vectos for outside words\n",
    "#v_C - vector for center word\n",
    "#u_w - vectors of all vocabs\n",
    "\n",
    "class GloVe(nn.Module):\n",
    "    def __init__(self,voc_size, emb_size):\n",
    "        super(GloVe,self).__init__()\n",
    "        self.embedding_center_word = nn.Embedding(voc_size, emb_size) #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "        \n",
    "        self.bias_i = nn.Embedding(voc_size, 1)\n",
    "        self.bias_j = nn.Embedding(voc_size, 1)\n",
    "    def forward(self, center_words, outside_words, coocs, weighting):\n",
    "        #get the embedding of center_words and outside_words\n",
    "        center_embeds = self.embedding_center_word(center_words)\n",
    "        outside_embeds = self.embedding_outside_word(outside_words)\n",
    "\n",
    "        #create biases #create unique embedding (voc_size,1)\n",
    "        inner_product = center_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        bias_i = self.bias_i(center_words).squeeze(1) #center\n",
    "        bias_j = self.bias_j(outside_words).squeeze(1) #target\n",
    "        #do the product between wi and wj\n",
    "        loss = weighting * torch.pow(inner_product + bias_i + bias_j - coocs, 2)\n",
    "        \n",
    "        return torch.sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch_word2vec(batch_size, corpus, window_size=1,architecture='skipgram'):\n",
    "    skipgrams = []\n",
    "    cbows = []\n",
    "    #for each corpus\n",
    "    for sent in corpus_tokenized:\n",
    "        #for each sent ('apple', 'banana', 'fruit')\n",
    "        for i in range(window_size,len(sent)-window_size): #start from 2 to second last\n",
    "            context_word = []\n",
    "            # print(sent[i])\n",
    "            center_word = word2index[sent[i]]\n",
    "            for j in range(window_size):\n",
    "                outside_word = [word2index[sent[i-j-1]],word2index[sent[i+j+1]]] #window_size adjustable\n",
    "                #here we want to create (banana, apple), (banana, fruit) append to some list\n",
    "                for o in outside_word:\n",
    "                    context_word.append(o)\n",
    "                    skipgrams.append([center_word,o])\n",
    "                cbows.append([context_word,center_word])\n",
    "\n",
    "    if architecture == 'skipgram':\n",
    "        arch = skipgrams\n",
    "    else:\n",
    "        arch = cbows\n",
    "        \n",
    "    #only get a batch, not the entire lsit\n",
    "    random_index = np.random.choice(range(len(arch)),batch_size,replace=False)\n",
    "    #appending some list of inputs and labels\n",
    "    random_inputs, random_labels = [] , []\n",
    "    for index in random_index:\n",
    "        # print(arch[index])\n",
    "        random_inputs.append([arch[index][0]]) #center words, this will be as shape of (1,) -> (1,1) for modeling\n",
    "        random_labels.append([arch[index][1]])\n",
    "\n",
    "    return np.array(random_inputs),np.array(random_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model will accept three vectors - u_o, v_c, u_w\n",
    "#u_o - vectos for outside words\n",
    "#v_C - vector for center word\n",
    "#u_w - vectors of all vocabs\n",
    "\n",
    "class Skipgram(nn.Module):\n",
    "    def __init__(self,voc_size, emb_size):\n",
    "        super(Skipgram,self).__init__()\n",
    "        self.embedding_center_word = nn.Embedding(voc_size, emb_size) #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        #center_word, outside_word: (batch_size,1)\n",
    "        #all_vocabs : (batch_size, voc_size)\n",
    "        #convert them into embedding\n",
    "        center_word_embed = self.embedding_center_word(center_word)     #v_c (batch_size,1, emb_size)\n",
    "        outside_word_embed = self.embedding_outside_word(outside_word)  #u_o (batch_size,1, emb_size)\n",
    "        all_vocabs_embed = self.embedding_outside_word(all_vocabs)      #u_w (batch_size,voc_size, emb_size)\n",
    "        #bmm is basically @ or .dot but across batches (ie., ignore the batch dimension)\n",
    "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1,2)).squeeze(2)\n",
    "        #(batch_size,1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
    "        top_term_exp = torch.exp(top_term) #exp(uo vc)\n",
    "        #(batch_size, 1)\n",
    "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1,2)).squeeze(2)\n",
    "        #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) ===> (batch_size, voc_size)\n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term)) #sum exp(uw, vc)\n",
    "        #(batch_size, 1)\n",
    "        loss_fn = -torch.mean(torch.log(top_term_exp/lower_term_sum))\n",
    "        #(batc_size,1) / (batch_size,1) ==mena==> scalar\n",
    "\n",
    "        return loss_fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module): #same as skipgram\n",
    "    def __init__(self,voc_size, emb_size):\n",
    "        super(CBOW,self).__init__()\n",
    "        self.embedding_center_word = nn.Embedding(voc_size, emb_size) #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        #center_word, outside_word: (batch_size,1)\n",
    "        #all_vocabs : (batch_size, voc_size)\n",
    "        #convert them into embedding\n",
    "        center_word_embed = self.embedding_center_word(center_word)     #v_c (batch_size,1, emb_size)\n",
    "        outside_word_embed = self.embedding_outside_word(outside_word)  #u_o (batch_size,1, emb_size)\n",
    "        all_vocabs_embed = self.embedding_outside_word(all_vocabs)      #u_w (batch_size,voc_size, emb_size)\n",
    "        # print(center_word_embed.shape,outside_word_embed.shape,all_vocabs_embed.shape)\n",
    "        #bmm is basically @ or .dot but across batches (ie., ignore the batch dimension)\n",
    "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1,2)).squeeze(2)\n",
    "        #(batch_size,1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
    "        top_term_exp = torch.exp(top_term) #exp(uo vc)\n",
    "        #(batch_size, 1)\n",
    "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1,2)).squeeze(2)\n",
    "        #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) ===> (batch_size, voc_size)\n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term)) #sum exp(uw, vc)\n",
    "        #(batch_size, 1)\n",
    "        loss_fn = -torch.mean(torch.log(top_term_exp/lower_term_sum))\n",
    "        #(batc_size,1) / (batch_size,1) ==mena==> scalar\n",
    "        return loss_fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Negative Sampling\n",
    "\n",
    "A function to get negavtive samples, based o nthe current center and outsode words in the batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Unigram Distribution\n",
    "\n",
    "$$P(w)=U(w)^{3/4}/Z$$\n",
    "\n",
    "Defining the probability of sampling negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0.0001 #scaling up lower frequency terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count all the occurence of vocabs\n",
    "from collections import Counter\n",
    "\n",
    "word_count = Counter(flatten(corpus_tokenized))\n",
    "# word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def prepare_sequence(seq, word2index):\n",
    "    #map(fucntion, list of something)\n",
    "    #map will look at each of element in this list, and apply this function\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "#you don't want to pick samples = targets, basically negative samples\n",
    "#k = number of negative samples - how many? they found 10 is the best\n",
    "#will be run during training\n",
    "#after random_batch, \n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    #targets is already in id.....\n",
    "    #but the unigram_table is in word....\n",
    "    #1. get the batch size of this targets\n",
    "    batch_size = targets.shape[0]\n",
    "    neg_samples = []\n",
    "    #2. for each batch\n",
    "    for i in range(batch_size):\n",
    "        #randomly pick k negative words from unigram_table\n",
    "        target_index = targets[i].item()  #looping each of the batch....\n",
    "        nsample = []\n",
    "        while len(nsample) < k:\n",
    "            neg = random.choice(unigram_table)\n",
    "            #if this word == target, skip this word\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        #append this word to some list\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).reshape(1, -1))  #tensor[], tensor[]\n",
    "    return torch.cat(neg_samples)  #tensor[[], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model will accept three vectors - u_o, v_c, u_k\n",
    "#u_o - vectos for outside words\n",
    "#v_C - vector for center word\n",
    "#u_k - vectors for negative word\n",
    "\n",
    "class SkipgramNeg(nn.Module):\n",
    "    def __init__(self,voc_size, emb_size):\n",
    "        super(SkipgramNeg,self).__init__()\n",
    "        self.embedding_center_word = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "\n",
    "    def forward(self, center_words, outside_words, negative_words):\n",
    "        #center_words, outside_words  (batch_size,1)\n",
    "        #negative_words (batch_size,k) \n",
    "        center_embed    = self.embedding_center_word(center_words)      #(batch_size,1, emb_size)\n",
    "        outside_embed   = self.embedding_outside_word(outside_words)   #(batch_size,1, emb_size)\n",
    "        neg_embed       = self.embedding_outside_word(negative_words)      #(batch_size,k, emb_size)\n",
    "        \n",
    "        uovc            = outside_embed.bmm(center_embed.transpose(1,2)).squeeze(2)\n",
    "        ukvc            = -neg_embed.bmm(center_embed.transpose(1,2)).squeeze(2)\n",
    "        ukvc_sum        =  torch.sum(ukvc, 1).view(-1, 1) #(batch_size, 1)\n",
    "        loss = self.logsigmoid(uovc) + self.logsigmoid(ukvc_sum) #(batch_size,1)+(batch_size,1)\n",
    "        \n",
    "        return -torch.mean(loss) #scalar, loss should be scalar, to call backward()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = len(vocabs)\n",
    "batch_size = 2 #why? no reason\n",
    "emb_size = 50 #why? no reason; usually 50, 100, 300 but 2 so we can plot (50 can also plot, but need PCA)\n",
    "models = [Skipgram(voc_size,emb_size), CBOW(voc_size,emb_size), SkipgramNeg(voc_size, emb_size), GloVe(voc_size,emb_size)]\n",
    "models_name = ['Skipgram','CBOW','NEG','GloVe'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Skipgram\n",
      "Epoch : 100 | Loss : 24.663319 | Time : 1m 15s\n",
      "Epoch : 200 | Loss : 25.925415 | Time : 2m 31s\n",
      "Epoch : 300 | Loss : 48.776756 | Time : 3m 46s\n",
      "Epoch : 400 | Loss : 24.188061 | Time : 5m 4s\n",
      "Epoch : 500 | Loss : 22.145897 | Time : 6m 30s\n",
      "Model : CBOW\n",
      "Epoch : 100 | Loss : 32.855370 | Time : 1m 21s\n",
      "Epoch : 200 | Loss : 32.047951 | Time : 2m 47s\n",
      "Epoch : 300 | Loss : 24.753788 | Time : 4m 4s\n",
      "Epoch : 400 | Loss : 21.954782 | Time : 5m 26s\n",
      "Epoch : 500 | Loss : 26.298782 | Time : 6m 49s\n",
      "Model : NEG\n",
      "Epoch : 100 | Loss : 2722.873047 | Time : 1m 20s\n",
      "Epoch : 200 | Loss : 18.244280 | Time : 2m 43s\n",
      "Epoch : 300 | Loss : 7825.445312 | Time : 4m 3s\n",
      "Epoch : 400 | Loss : 3.962481 | Time : 5m 22s\n",
      "Epoch : 500 | Loss : 2829.480957 | Time : 6m 44s\n",
      "Model : GloVe\n",
      "Epoch : 100 | Loss : 2310.856201 | Time : 0m 11s\n",
      "Epoch : 200 | Loss : 264.488312 | Time : 0m 22s\n",
      "Epoch : 300 | Loss : 1713.151855 | Time : 0m 33s\n",
      "Epoch : 400 | Loss : 651.568420 | Time : 0m 44s\n",
      "Epoch : 500 | Loss : 2357.380371 | Time : 0m 55s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "num_epochs = 500\n",
    "for idx, model in enumerate(models):\n",
    "    criterion = nn.CrossEntropyLoss() #-log\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    print(f'Model : {models_name[idx]}')\n",
    "    #for epoch\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        #get random batch\n",
    "        if (idx == 0) or (idx == 2):\n",
    "            input_batch, label_batch = random_batch_word2vec(batch_size,corpus_tokenized,window_size=2,architecture='skipgram')\n",
    "            input_batch = torch.LongTensor(input_batch)\n",
    "            label_batch = torch.LongTensor(label_batch)\n",
    "            loss = model(input_batch,label_batch,all_vocabs)\n",
    "        if idx == 1:    \n",
    "            input_batch, label_batch = random_batch_word2vec(batch_size,corpus_tokenized,window_size=2,architecture='cbow')\n",
    "            input_batch = torch.LongTensor(input_batch).view(batch_size,window_size*2)\n",
    "            label_batch = torch.LongTensor(label_batch).view(-1,1)\n",
    "            loss = model(input_batch,label_batch,all_vocabs)\n",
    "        if idx == 3:\n",
    "            input, label, cooc, weightin = random_batch(batch_size,corpus_tokenized,skip_grams,X_ik,weighting_dic)\n",
    "            cooc_batch = torch.FloatTensor(cooc)\n",
    "            weightin_batch = torch.FloatTensor(weightin)\n",
    "            input_batch = torch.LongTensor(input)\n",
    "            label_batch = torch.LongTensor(label)\n",
    "            loss = model(input_batch,label_batch,cooc_batch,weightin_batch)\n",
    "\n",
    "        #backpropagate\n",
    "        loss.backward()\n",
    "        #update alpha\n",
    "        optimizer.step()\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        #print epoch loss\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch : {epoch+1} | Loss : {loss:.6f} | Time : {epoch_mins}m {epoch_secs}s')\n",
    "            \n",
    "    torch.save(model.state_dict(), \"./model/\"+models_name[idx]+\".pth\")\n",
    "    with open(\"./model/\"+models_name[idx]+\".pkl\",'wb') as f:\n",
    "        pickle.dump(model,f)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model : Skipgram\\nEpoch : 100 | Loss : 24.663319 | Time : 1m 15s\\nEpoch : 200 | Loss : 25.925415 | Time : 2m 31s\\nEpoch : 300 | Loss : 48.776756 | Time : 3m 46s\\nEpoch : 400 | Loss : 24.188061 | Time : 5m 4s\\nEpoch : 500 | Loss : 22.145897 | Time : 6m 30s\\nModel : CBOW\\nEpoch : 100 | Loss : 32.855370 | Time : 1m 21s\\nEpoch : 200 | Loss : 32.047951 | Time : 2m 47s\\nEpoch : 300 | Loss : 24.753788 | Time : 4m 4s\\nEpoch : 400 | Loss : 21.954782 | Time : 5m 26s\\nEpoch : 500 | Loss : 26.298782 | Time : 6m 49s\\nModel : NEG\\nEpoch : 100 | Loss : 2722.873047 | Time : 1m 20s\\nEpoch : 200 | Loss : 18.244280 | Time : 2m 43s\\nEpoch : 300 | Loss : 7825.445312 | Time : 4m 3s\\nEpoch : 400 | Loss : 3.962481 | Time : 5m 22s\\nEpoch : 500 | Loss : 2829.480957 | Time : 6m 44s\\nModel : GloVe\\nEpoch : 100 | Loss : 2310.856201 | Time : 0m 11s\\nEpoch : 200 | Loss : 264.488312 | Time : 0m 22s\\nEpoch : 300 | Loss : 1713.151855 | Time : 0m 33s\\nEpoch : 400 | Loss : 651.568420 | Time : 0m 44s\\nEpoch : 500 | Loss : 2357.380371 | Time : 0m 55s\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Model : Skipgram\n",
    "Epoch : 100 | Loss : 24.663319 | Time : 1m 15s\n",
    "Epoch : 200 | Loss : 25.925415 | Time : 2m 31s\n",
    "Epoch : 300 | Loss : 48.776756 | Time : 3m 46s\n",
    "Epoch : 400 | Loss : 24.188061 | Time : 5m 4s\n",
    "Epoch : 500 | Loss : 22.145897 | Time : 6m 30s\n",
    "Model : CBOW\n",
    "Epoch : 100 | Loss : 32.855370 | Time : 1m 21s\n",
    "Epoch : 200 | Loss : 32.047951 | Time : 2m 47s\n",
    "Epoch : 300 | Loss : 24.753788 | Time : 4m 4s\n",
    "Epoch : 400 | Loss : 21.954782 | Time : 5m 26s\n",
    "Epoch : 500 | Loss : 26.298782 | Time : 6m 49s\n",
    "Model : NEG\n",
    "Epoch : 100 | Loss : 2722.873047 | Time : 1m 20s\n",
    "Epoch : 200 | Loss : 18.244280 | Time : 2m 43s\n",
    "Epoch : 300 | Loss : 7825.445312 | Time : 4m 3s\n",
    "Epoch : 400 | Loss : 3.962481 | Time : 5m 22s\n",
    "Epoch : 500 | Loss : 2829.480957 | Time : 6m 44s\n",
    "Model : GloVe\n",
    "Epoch : 100 | Loss : 2310.856201 | Time : 0m 11s\n",
    "Epoch : 200 | Loss : 264.488312 | Time : 0m 22s\n",
    "Epoch : 300 | Loss : 1713.151855 | Time : 0m 33s\n",
    "Epoch : 400 | Loss : 651.568420 | Time : 0m 44s\n",
    "Epoch : 500 | Loss : 2357.380371 | Time : 0m 55s\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "import pickle\n",
    "\n",
    "with open('./model/Skipgram.pkl','rb') as f:\n",
    "    model_Skipgram = pickle.load(f)\n",
    "with open('./model/CBOW.pkl','rb') as f:\n",
    "    model_CBOW = pickle.load(f)\n",
    "with open('./model/NEG.pkl','rb') as f:\n",
    "    model_NEG = pickle.load(f)\n",
    "with open('./model/GloVe.pkl','rb') as f:\n",
    "    model_GloVe = pickle.load(f)\n",
    "\n",
    "load_models = [model_Skipgram,model_CBOW,model_NEG,model_GloVe]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plotting the embeddings\n",
    "\n",
    "Is really the related studd are close to each other, and vice versa.\n",
    "\n",
    "The most fun part: Will 'banana' closer to 'fruit' than 'cat'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find embedding of fruit, cat\n",
    "def get_embed(word,model):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except :\n",
    "        index = word2index['<UNK>'] #unknown\n",
    "    word = torch.LongTensor([index])\n",
    "    \n",
    "    embed =  (model.embedding_center_word(word)+model.embedding_outside_word(word))/2\n",
    "    return np.array(embed[0].detach().numpy())\n",
    "    # return embed[0][0].item(),embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot plot due to embeddding size is 50\n",
    "# #help me plot on maplotlib\n",
    "# plt.figure(figsize=(10,10))\n",
    "# for i, word in enumerate(vocabs[:100]):\n",
    "#     x,y = get_embed(word)\n",
    "#     plt.scatter(x,y)\n",
    "#     plt.annotate(word,xy=(x,y),xytext=(5,2),textcoords='offset points')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Cosine Similarity\n",
    "How do (from Scratch) calcualte cosine similarity?\n",
    "\n",
    "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
    "\n",
    "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
    "\n",
    "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy version\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Prediction \n",
    "- does the Work analogy task : a is b as c is to ______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19558, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing Set\n",
    "nlp = spacy.load('./en_core_web_sm/')\n",
    "text = open('./dataset/questions-words.txt',mode='r')\n",
    "df = pd.DataFrame(text.readlines())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 507, 5032, 5899, 8367, 8874, 9867, 10680, 12013, 13136, 14193, 15793, 17354, 18687]\n"
     ]
    }
   ],
   "source": [
    "#Check Header \n",
    "header = df[0].str.startswith(':')\n",
    "index_list = np.where(header)[0].tolist()\n",
    "print(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Header\n",
    "#format drop(index,inplace=True)\n",
    "# df.drop(index_list, inplace=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[8875:9867]\n",
    "df2 = df[9868:10680]\n",
    "df3 = df[10681:12013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3136, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum = pd.concat([df1,df2,df3],axis=0)\n",
    "df_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_col):\n",
    "    corpus = []\n",
    "    for item in df_col:\n",
    "        item = re.sub('[^A-Za-z0-9]+', ' ', str(item)) # remove special characters\n",
    "        item = item.lower() # lower all characters\n",
    "        item = item.split() # split data\n",
    "        corpus.append(' '.join(str(x) for x in item))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['amazing', 'amazingly', 'apparent', 'apparently'],\n",
       " ['amazing', 'amazingly', 'calm', 'calmly'],\n",
       " ['amazing', 'amazingly', 'cheerful', 'cheerfully'],\n",
       " ['amazing', 'amazingly', 'complete', 'completely'],\n",
       " ['amazing', 'amazingly', 'efficient', 'efficiently']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. tokenize\n",
    "#data cleaned\n",
    "corpus_test = clean_data(df1[0])\n",
    "#data tokenized\n",
    "corpus_tokenized_test = [sent.split(\" \") for sent in corpus_test]\n",
    "corpus_tokenized_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. numericalize (vocab)\n",
    "#2.1 get all the unique words\n",
    "#we want to flatten unit (basically merge all list)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs_test = list(set(flatten(corpus_tokenized_test)))\n",
    "\n",
    "#2.2 assign id to all these vocabs\n",
    "word2index_test = {v: idx for idx, v in enumerate(vocabs_test)}\n",
    "\n",
    "#adding unknown word\n",
    "vocabs_test.append('<UNK>')\n",
    "word2index_test['<UNK>'] = len(vocabs_test) - 1\n",
    "\n",
    "voc_size_test = len(vocabs_test)\n",
    "voc_size_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogy(a,b,c,model):\n",
    "    emb_a, emb_b, emb_c = get_embed(a,model),get_embed(b,model),get_embed(c,model)\n",
    "    vector = emb_b - emb_a + emb_c\n",
    "    # vector_norm = (vector ** 2).sum() ** (1 / 2)\n",
    "    # vector = vector / vector_norm\n",
    "    # print(vector.shape)\n",
    "    similarity = -1 \n",
    "    \n",
    "    for vocab in vocabs:\n",
    "        if vocab not in [a,b,c]: #ignore input words itself\n",
    "            current_sim = cos_sim(vector,get_embed(vocab,model))\n",
    "            if current_sim > similarity:\n",
    "                similarity = current_sim #update better one\n",
    "                d = (vocab, similarity)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cartels', 0.50138223)\n",
      "('1970', 0.51105267)\n",
      "('penalty', 0.4856296)\n",
      "('application', 0.5057244)\n"
     ]
    }
   ],
   "source": [
    "## 'usual', 'usually', 'serious'\n",
    "## 'amazing', 'amazingly', 'apparent'\n",
    "for each_model in load_models:\n",
    "    print(find_analogy('usual', 'usually', 'serious', each_model))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 4)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(corpus_tokenized_test, columns=[\"A\", \"B\", \"C\", \"D\"])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(data,model): #testing \n",
    "    corrects = 0\n",
    "    total = len(data)\n",
    "    for idx, row in data.iterrows():\n",
    "        # print(idx)\n",
    "        a, b, c, d = row['A'],row['B'],row['C'],row['D']\n",
    "        predict = find_analogy(a,b,c,model)[0] \n",
    "        if predict == d: \n",
    "            corrects +=1 \n",
    "    acc = corrects/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Skipgram : 0.0\n",
      "Model CBOW : 0.0\n",
      "Model NEG : 0.0\n",
      "Model GloVe : 0.0\n"
     ]
    }
   ],
   "source": [
    "for idx,each_model in enumerate(load_models):\n",
    "    print(f'Model {models_name[idx]} : {testing(data[:100],each_model)*100} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Try to find a correlation with just ONE similarity dataset (which humans judge how similar is two words.....)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set with according with Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "#you have to put this file in some python/gensim directory; just run it and it will inform where to put....\n",
    "glove_file = datapath('glove.6B.50d.txt')\n",
    "model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Set with according with Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plane</td>\n",
       "      <td>car</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>car</td>\n",
       "      <td>6.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>television</td>\n",
       "      <td>radio</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>rooster</td>\n",
       "      <td>voyage</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>noon</td>\n",
       "      <td>string</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>chord</td>\n",
       "      <td>smile</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>professor</td>\n",
       "      <td>cucumber</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>king</td>\n",
       "      <td>cabbage</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        x2      y\n",
       "0         tiger       cat   7.35\n",
       "1         tiger     tiger  10.00\n",
       "2         plane       car   5.77\n",
       "3         train       car   6.31\n",
       "4    television     radio   6.77\n",
       "..          ...       ...    ...\n",
       "198     rooster    voyage   0.62\n",
       "199        noon    string   0.54\n",
       "200       chord     smile   0.54\n",
       "201   professor  cucumber   0.31\n",
       "202        king   cabbage   0.23\n",
       "\n",
       "[203 rows x 3 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsim353 = open('./dataset/wordsim353_sim_rel/wordsim_similarity_goldstandard.txt',mode='r')\n",
    "df_wordsim353 = pd.DataFrame(wordsim353.readlines())\n",
    "#1. tokenize\n",
    "#data cleaned\n",
    "corpus_wordsim353 = clean_data(df_wordsim353[0])\n",
    "\n",
    "#data tokenized\n",
    "corpus_tokenized_wordsim353 = [sent.split(\" \") for sent in corpus_wordsim353]\n",
    "corpus_tokenized_wordsim353[:5]\n",
    "df_corpus_tokenized_wordsim353 = pd.DataFrame(corpus_tokenized_wordsim353,columns=['x1','x2','y'])\n",
    "df_corpus_tokenized_wordsim353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "corrects = 0\n",
    "total = len(data)\n",
    "for idx, row in data.iterrows():\n",
    "    # print(idx)\n",
    "    a, b, c, d = row['A'],row['B'],row['C'],row['D']\n",
    "    predict = model.most_similar(positive=[c, a], negative=[b])[0]\n",
    "    if predict == d: \n",
    "        corrects +=1 \n",
    "acc = corrects/total\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation  \n",
    "- Calculate a Spearman correlation coefficient with associated p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3126530612244898, 0.027062237809797725)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = get_embed('cat', models[0])\n",
    "dog = get_embed('dog', models[0])\n",
    "#Format : stats.spearmanr(a, b=None, axis=0, nan_policy='propagate', alternative='two-sided')[source]\n",
    "corr, pvalue = stats.spearmanr(cat, dog)\n",
    "corr, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_corr_model = dict()\n",
    "for idx, each_model in enumerate(load_models):\n",
    "    each_model.eval()\n",
    "    y_corr_list = []\n",
    "    for index in range(df_corpus_tokenized_wordsim353.shape[0]): \n",
    "        emb_x1 = get_embed(df_corpus_tokenized_wordsim353['x1'][idx], each_model)\n",
    "        emb_x2 = get_embed(df_corpus_tokenized_wordsim353['x2'][idx], each_model)\n",
    "        y_corr, y_pvalue = stats.spearmanr(emb_x1, emb_x2)\n",
    "        y_corr_list.append(y_corr)\n",
    "\n",
    "    y_corr_model[models_name[idx]] = y_corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : Skipgram MSE : 29.931\n",
      "Model : CBOW MSE : 29.931\n",
      "Model : NEG MSE : 14.750\n",
      "Model : GloVe MSE : 28.609\n",
      "Mean Y_true: 5.13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "#Format : mean_squared_error(y_true, y_pred)\n",
    "for idx, each_model in enumerate(load_models):\n",
    "    y_pred = [i*10 for i in y_corr_model[models_name[idx]]]\n",
    "    y_true = df_corpus_tokenized_wordsim353['y'].astype('float')\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mean = y_true.mean(axis=0)\n",
    "    print(f'Model : {models_name[idx]} MSE : {mse:0.3f}')\n",
    "print(f'Mean Y_true: {mean:0.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Section 1 :\n",
    "\n",
    "| Model    | Loss        | Time   | Accuracy |\n",
    "|----------|-------------|--------|----------|\n",
    "| Skipgram | 22.145897   | 6m 30s | 0        |\n",
    "| CBOW     | 26.298782   | 6m 49s | 0        |\n",
    "| NEG      | 2829.480957 | 6m 44s | 0        |\n",
    "| GloVe    | 2357.380371 | 55s    | 0        |\n",
    "\n",
    "Section 2 :\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [get_embed(vocab,model_GloVe) for vocab in vocabs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.184542</td>\n",
       "      <td>-1.263750</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.465577</td>\n",
       "      <td>-0.499853</td>\n",
       "      <td>slowly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.308581</td>\n",
       "      <td>-1.633303</td>\n",
       "      <td>apparent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.812553</td>\n",
       "      <td>-0.183444</td>\n",
       "      <td>calmly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.643000</td>\n",
       "      <td>-0.810940</td>\n",
       "      <td>efficiently</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y         word\n",
       "0 -2.184542 -1.263750        quick\n",
       "1 -1.465577 -0.499853       slowly\n",
       "2 -3.308581 -1.633303     apparent\n",
       "3  3.812553 -0.183444       calmly\n",
       "4 -1.643000 -0.810940  efficiently"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit(subset).transform(subset)\n",
    "reduced = pd.DataFrame(reduced,columns=['X','Y'])\n",
    "reduced['word'] = vocabs_test #adding columns\n",
    "reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x=reduced['X'],y=reduced['Y'])\n",
    "for idx, value in reduced.iterrows():\n",
    "    plt.annotate(reduced['word'][idx],value[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_col):\n",
    "    corpus = []\n",
    "    for item in df_col:\n",
    "        # item = re.sub('[^A-Za-z0-9]+', ' ', str(item)) # remove special characters\n",
    "        item = item.lower() # lower all characters\n",
    "        item = item.split() # split data\n",
    "        corpus.append(' '.join(str(x) for x in item))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
