{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LSTM_model import *\n",
    "import torch\n",
    "import pytreebank\n",
    "import spacy\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "#Load GPU\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Load Data\n",
    "train = pytreebank.import_tree_corpus(\"./sentiment/train.txt\")\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "def seperate(dataset): #Use All nodes\n",
    "    seperation = []\n",
    "    for data in dataset:\n",
    "        for label, text in data.to_labeled_lines():\n",
    "            seperation.append((label,text))\n",
    "    return seperation\n",
    "\n",
    "train_sep = seperate(train)\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "\n",
    "def yield_tokens(data_iter): #data_iter, e.g., train\n",
    "    for _, text in data_iter: \n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_sep), specials=['<unk>','<pad>','<bos>','<eos>'], special_first = True)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "pad_ix = vocab['<pad>']\n",
    "\n",
    "#hyper-parameter\n",
    "input_dim  = len(vocab)\n",
    "hid_dim    = 256\n",
    "emb_dim    = 300         \n",
    "output_dim = 5\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.5\n",
    "\n",
    "model = LSTM(input_dim, emb_dim, hid_dim, output_dim, num_layers, bidirectional, dropout, pad_ix).to(device)\n",
    "save_path = f'models/LSTM_TreeBank.pt'\n",
    "model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reddit crawler\n",
    "import praw\n",
    "your_client_id='ElyKc6o3du1IMb5LP2HYjg'\n",
    "your_client_secret='YimfVn3bTLyVFu_XkJuLxrNkR3vHAQ'\n",
    "your_user_name='guntsv'\n",
    "\n",
    "reddit = praw.Reddit(client_id=your_client_id,\n",
    "                     client_secret=your_client_secret,\n",
    "                     user_agent=your_user_name,\n",
    "                     check_for_async=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit.subreddit('iphone')\n",
    "topics = [*subreddit.top(limit=None)] # top posts all time\n",
    "print(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you can cook on it\n"
     ]
    }
   ],
   "source": [
    "#Check Title\n",
    "for topic in topics:\n",
    "    print(topic.title) # headline\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Now you can cook on it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just got my first iPhone for Christmas!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple CarPlay volume control UI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wait I’ve seen this one before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How rotation lock should be</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title\n",
       "0                   Now you can cook on it\n",
       "1  Just got my first iPhone for Christmas!\n",
       "2          Apple CarPlay volume control UI\n",
       "3           Wait I’ve seen this one before\n",
       "4              How rotation lock should be"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "title = [n.title for n in topics]\n",
    "df_topics = pd.DataFrame({\"title\": title})\n",
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(test_str_list):\n",
    "    result = list()\n",
    "    for test_str in test_str_list:\n",
    "        text = torch.tensor(text_pipeline(test_str)).to(device).reshape(1, -1)\n",
    "        # text_list = [x.item() for x in text]\n",
    "        text_length = torch.tensor([text.size(1)]).to(dtype=torch.int64)\n",
    "        output = model(text, text_length).squeeze(1)\n",
    "        predicted = torch.max(output.data, 1)[1] #.detach().cpu().numpy()\n",
    "        result.append((test_str, predicted))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Now you can cook on it', tensor([2], device='cuda:2')),\n",
       " ('Just got my first iPhone for Christmas!', tensor([3], device='cuda:2')),\n",
       " ('Apple CarPlay volume control UI', tensor([2], device='cuda:2')),\n",
       " ('Wait I’ve seen this one before', tensor([2], device='cuda:2')),\n",
       " ('How rotation lock should be', tensor([2], device='cuda:2'))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(df_topics['title'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
