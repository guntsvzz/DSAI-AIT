{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch, torchdata, torchtext\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import random, math, time\n",
    "from torch.autograd import Variable\n",
    "import operator\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#make our work comparable if restarted the kernel\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ETL: Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment this if you are not using our department puffer\n",
    "# import os\n",
    "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A certain king had a beautiful garden, and in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some men are born to good luck: all they do or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There was once an old castle, that stood in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An honest farmer had once an ass that had been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A shepherd had a faithful dog, called Sultan, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  A certain king had a beautiful garden, and in ...\n",
       "1  Some men are born to good luck: all they do or...\n",
       "2  There was once an old castle, that stood in th...\n",
       "3  An honest farmer had once an ass that had been...\n",
       "4  A shepherd had a faithful dog, called Sultan, ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_grimm = pd.read_csv('./grimms_fairytales.csv')\n",
    "df_grimm.drop(['Unnamed: 0','Title'],axis=1,inplace=True)\n",
    "df_grimm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A certain king had a beautiful garden, and in the garden stood a tree\\nwhich bore golden apples. These apples were always counted, and about\\nthe time when they began to grow ripe it was found that every night one\\nof them was gone. The king became very angry at this, and ordered the\\ngardener to keep watch all night under the tree. The gardener set his\\neldest son to watch; but about twelve o’clock he fell asleep, and in\\nthe morning another of the apples was missing. Then the second son was\\nordered to watch; and at midnight he too fell asleep, and in the morning\\nanother apple was gone. Then the third son offered to keep watch; but\\nthe gardener at first would not let him, for fear some harm should come\\nto him: however, at last he consented, and the young man laid himself\\nunder the tree to watch. As the clock struck twelve he heard a rustling\\nnoise in the air, and a bird came flying that was of pure gold; and as\\nit was snapping at one of the apples with its beak, the gardener’s son\\njumped up and shot an arrow at it. But the arrow did the bird no harm;\\nonly it dropped a golden feather from its tail, and then flew away.\\nThe golden feather was brought to the king in the morning, and all the\\ncouncil was called together. Everyone agreed that it was worth more than\\nall the wealth of the kingdom: but the king said, ‘One feather is of no\\nuse to me, I must have the whole bird.’\\n\\nThen the gardener’s eldest son set out and thought to find the golden\\nbird very easily; and when he had gone but a little way, he came to a\\nwood, and by the side of the wood he saw a fox sitting; so he took his\\nbow and made ready to shoot at it. Then the fox said, ‘Do not shoot me,\\nfor I will give you good counsel; I know what your business is, and\\nthat you want to find the golden bird. You will reach a village in the\\nevening; and when you get there, you will see two inns opposite to each\\nother, one of which is very pleasant and beautiful to look at: go not in\\nthere, but rest for the night in the other, though it may appear to you\\nto be very poor and mean.’ But the son thought to himself, ‘What can\\nsuch a beast as this know about the matter?’ So he shot his arrow at\\nthe fox; but he missed it, and it set up its tail above its back and\\nran into the wood. Then he went his way, and in the evening came to\\nthe village where the two inns were; and in one of these were people\\nsinging, and dancing, and feasting; but the other looked very dirty,\\nand poor. ‘I should be very silly,’ said he, ‘if I went to that shabby\\nhouse, and left this charming place’; so he went into the smart house,\\nand ate and drank at his ease, and forgot the bird, and his country too.\\n\\nTime passed on; and as the eldest son did not come back, and no tidings\\nwere heard of him, the second son set out, and the same thing happened\\nto him. He met the fox, who gave him the good advice: but when he came\\nto the two inns, his eldest brother was standing at the window where\\nthe merrymaking was, and called to him to come in; and he could not\\nwithstand the temptation, but went in, and forgot the golden bird and\\nhis country in the same manner.\\n\\nTime passed on again, and the youngest son too wished to set out into\\nthe wide world to seek for the golden bird; but his father would not\\nlisten to it for a long while, for he was very fond of his son, and\\nwas afraid that some ill luck might happen to him also, and prevent his\\ncoming back. However, at last it was agreed he should go, for he would\\nnot rest at home; and as he came to the wood, he met the fox, and heard\\nthe same good counsel. But he was thankful to the fox, and did not\\nattempt his life as his brothers had done; so the fox said, ‘Sit upon my\\ntail, and you will travel faster.’ So he sat down, and the fox began to\\nrun, and away they went over stock and stone so quick that their hair\\nwhistled in the wind.\\n\\nWhen they came to the village, the son followed the fox’s counsel, and\\nwithout looking about him went to the shabby inn and rested there all\\nnight at his ease. In the morning came the fox again and met him as he\\nwas beginning his journey, and said, ‘Go straight forward, till you come\\nto a castle, before which lie a whole troop of soldiers fast asleep and\\nsnoring: take no notice of them, but go into the castle and pass on and\\non till you come to a room, where the golden bird sits in a wooden cage;\\nclose by it stands a beautiful golden cage; but do not try to take the\\nbird out of the shabby cage and put it into the handsome one, otherwise\\nyou will repent it.’ Then the fox stretched out his tail again, and the\\nyoung man sat himself down, and away they went over stock and stone till\\ntheir hair whistled in the wind.\\n\\nBefore the castle gate all was as the fox had said: so the son went in\\nand found the chamber where the golden bird hung in a wooden cage, and\\nbelow stood the golden cage, and the three golden apples that had been\\nlost were lying close by it. Then thought he to himself, ‘It will be a\\nvery droll thing to bring away such a fine bird in this shabby cage’; so\\nhe opened the door and took hold of it and put it into the golden cage.\\nBut the bird set up such a loud scream that all the soldiers awoke, and\\nthey took him prisoner and carried him before the king. The next morning\\nthe court sat to judge him; and when all was heard, it sentenced him to\\ndie, unless he should bring the king the golden horse which could run as\\nswiftly as the wind; and if he did this, he was to have the golden bird\\ngiven him for his own.\\n\\nSo he set out once more on his journey, sighing, and in great despair,\\nwhen on a sudden his friend the fox met him, and said, ‘You see now\\nwhat has happened on account of your not listening to my counsel. I will\\nstill, however, tell you how to find the golden horse, if you will do as\\nI bid you. You must go straight on till you come to the castle where the\\nhorse stands in his stall: by his side will lie the groom fast asleep\\nand snoring: take away the horse quietly, but be sure to put the old\\nleathern saddle upon him, and not the golden one that is close by it.’\\nThen the son sat down on the fox’s tail, and away they went over stock\\nand stone till their hair whistled in the wind.\\n\\nAll went right, and the groom lay snoring with his hand upon the golden\\nsaddle. But when the son looked at the horse, he thought it a great pity\\nto put the leathern saddle upon it. ‘I will give him the good one,’\\nsaid he; ‘I am sure he deserves it.’ As he took up the golden saddle the\\ngroom awoke and cried out so loud, that all the guards ran in and took\\nhim prisoner, and in the morning he was again brought before the court\\nto be judged, and was sentenced to die. But it was agreed, that, if he\\ncould bring thither the beautiful princess, he should live, and have the\\nbird and the horse given him for his own.\\n\\nThen he went his way very sorrowful; but the old fox came and said, ‘Why\\ndid not you listen to me? If you had, you would have carried away\\nboth the bird and the horse; yet will I once more give you counsel. Go\\nstraight on, and in the evening you will arrive at a castle. At twelve\\no’clock at night the princess goes to the bathing-house: go up to her\\nand give her a kiss, and she will let you lead her away; but take care\\nyou do not suffer her to go and take leave of her father and mother.’\\nThen the fox stretched out his tail, and so away they went over stock\\nand stone till their hair whistled again.\\n\\nAs they came to the castle, all was as the fox had said, and at twelve\\no’clock the young man met the princess going to the bath and gave her the\\nkiss, and she agreed to run away with him, but begged with many tears\\nthat he would let her take leave of her father. At first he refused,\\nbut she wept still more and more, and fell at his feet, till at last\\nhe consented; but the moment she came to her father’s house the guards\\nawoke and he was taken prisoner again.\\n\\nThen he was brought before the king, and the king said, ‘You shall never\\nhave my daughter unless in eight days you dig away the hill that stops\\nthe view from my window.’ Now this hill was so big that the whole world\\ncould not take it away: and when he had worked for seven days, and had\\ndone very little, the fox came and said. ‘Lie down and go to sleep; I\\nwill work for you.’ And in the morning he awoke and the hill was gone;\\nso he went merrily to the king, and told him that now that it was\\nremoved he must give him the princess.\\n\\nThen the king was obliged to keep his word, and away went the young man\\nand the princess; and the fox came and said to him, ‘We will have all\\nthree, the princess, the horse, and the bird.’ ‘Ah!’ said the young man,\\n‘that would be a great thing, but how can you contrive it?’\\n\\n‘If you will only listen,’ said the fox, ‘it can be done. When you come\\nto the king, and he asks for the beautiful princess, you must say, “Here\\nshe is!” Then he will be very joyful; and you will mount the golden\\nhorse that they are to give you, and put out your hand to take leave of\\nthem; but shake hands with the princess last. Then lift her quickly on\\nto the horse behind you; clap your spurs to his side, and gallop away as\\nfast as you can.’\\n\\nAll went right: then the fox said, ‘When you come to the castle where\\nthe bird is, I will stay with the princess at the door, and you will\\nride in and speak to the king; and when he sees that it is the right\\nhorse, he will bring out the bird; but you must sit still, and say that\\nyou want to look at it, to see whether it is the true golden bird; and\\nwhen you get it into your hand, ride away.’\\n\\nThis, too, happened as the fox said; they carried off the bird, the\\nprincess mounted again, and they rode on to a great wood. Then the fox\\ncame, and said, ‘Pray kill me, and cut off my head and my feet.’ But the\\nyoung man refused to do it: so the fox said, ‘I will at any rate give\\nyou good counsel: beware of two things; ransom no one from the gallows,\\nand sit down by the side of no river.’ Then away he went. ‘Well,’\\nthought the young man, ‘it is no hard matter to keep that advice.’\\n\\nHe rode on with the princess, till at last he came to the village where\\nhe had left his two brothers. And there he heard a great noise and\\nuproar; and when he asked what was the matter, the people said, ‘Two men\\nare going to be hanged.’ As he came nearer, he saw that the two men were\\nhis brothers, who had turned robbers; so he said, ‘Cannot they in any\\nway be saved?’ But the people said ‘No,’ unless he would bestow all his\\nmoney upon the rascals and buy their liberty. Then he did not stay to\\nthink about the matter, but paid what was asked, and his brothers were\\ngiven up, and went on with him towards their home.\\n\\nAnd as they came to the wood where the fox first met them, it was so\\ncool and pleasant that the two brothers said, ‘Let us sit down by the\\nside of the river, and rest a while, to eat and drink.’ So he said,\\n‘Yes,’ and forgot the fox’s counsel, and sat down on the side of the\\nriver; and while he suspected nothing, they came behind, and threw him\\ndown the bank, and took the princess, the horse, and the bird, and went\\nhome to the king their master, and said. ‘All this have we won by our\\nlabour.’ Then there was great rejoicing made; but the horse would not\\neat, the bird would not sing, and the princess wept.\\n\\nThe youngest son fell to the bottom of the river’s bed: luckily it was\\nnearly dry, but his bones were almost broken, and the bank was so steep\\nthat he could find no way to get out. Then the old fox came once more,\\nand scolded him for not following his advice; otherwise no evil would\\nhave befallen him: ‘Yet,’ said he, ‘I cannot leave you here, so lay hold\\nof my tail and hold fast.’ Then he pulled him out of the river, and said\\nto him, as he got upon the bank, ‘Your brothers have set watch to kill\\nyou, if they find you in the kingdom.’ So he dressed himself as a poor\\nman, and came secretly to the king’s court, and was scarcely within the\\ndoors when the horse began to eat, and the bird to sing, and the princess\\nleft off weeping. Then he went to the king, and told him all his\\nbrothers’ roguery; and they were seized and punished, and he had the\\nprincess given to him again; and after the king’s death he was heir to\\nhis kingdom.\\n\\nA long while after, he went to walk one day in the wood, and the old fox\\nmet him, and besought him with tears in his eyes to kill him, and cut\\noff his head and feet. And at last he did so, and in a moment the\\nfox was changed into a man, and turned out to be the brother of the\\nprincess, who had been lost a great many many years.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grimm.iloc[0]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grimm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grimm.Text = df_grimm.Text.replace('\\n', ' ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A certain king had a beautiful garden, and in the garden stood a tree which bore golden apples. These apples were always counted, and about the time when they began to grow ripe it was found that every night one of them was gone. The king became very angry at this, and ordered the gardener to keep watch all night under the tree. The gardener set his eldest son to watch; but about twelve o’clock he fell asleep, and in the morning another of the apples was missing. Then the second son was ordered to watch; and at midnight he too fell asleep, and in the morning another apple was gone. Then the third son offered to keep watch; but the gardener at first would not let him, for fear some harm should come to him: however, at last he consented, and the young man laid himself under the tree to watch. As the clock struck twelve he heard a rustling noise in the air, and a bird came flying that was of pure gold; and as it was snapping at one of the apples with its beak, the gardener’s son jumped up and shot an arrow at it. But the arrow did the bird no harm; only it dropped a golden feather from its tail, and then flew away. The golden feather was brought to the king in the morning, and all the council was called together. Everyone agreed that it was worth more than all the wealth of the kingdom: but the king said, ‘One feather is of no use to me, I must have the whole bird.’  Then the gardener’s eldest son set out and thought to find the golden bird very easily; and when he had gone but a little way, he came to a wood, and by the side of the wood he saw a fox sitting; so he took his bow and made ready to shoot at it. Then the fox said, ‘Do not shoot me, for I will give you good counsel; I know what your business is, and that you want to find the golden bird. You will reach a village in the evening; and when you get there, you will see two inns opposite to each other, one of which is very pleasant and beautiful to look at: go not in there, but rest for the night in the other, though it may appear to you to be very poor and mean.’ But the son thought to himself, ‘What can such a beast as this know about the matter?’ So he shot his arrow at the fox; but he missed it, and it set up its tail above its back and ran into the wood. Then he went his way, and in the evening came to the village where the two inns were; and in one of these were people singing, and dancing, and feasting; but the other looked very dirty, and poor. ‘I should be very silly,’ said he, ‘if I went to that shabby house, and left this charming place’; so he went into the smart house, and ate and drank at his ease, and forgot the bird, and his country too.  Time passed on; and as the eldest son did not come back, and no tidings were heard of him, the second son set out, and the same thing happened to him. He met the fox, who gave him the good advice: but when he came to the two inns, his eldest brother was standing at the window where the merrymaking was, and called to him to come in; and he could not withstand the temptation, but went in, and forgot the golden bird and his country in the same manner.  Time passed on again, and the youngest son too wished to set out into the wide world to seek for the golden bird; but his father would not listen to it for a long while, for he was very fond of his son, and was afraid that some ill luck might happen to him also, and prevent his coming back. However, at last it was agreed he should go, for he would not rest at home; and as he came to the wood, he met the fox, and heard the same good counsel. But he was thankful to the fox, and did not attempt his life as his brothers had done; so the fox said, ‘Sit upon my tail, and you will travel faster.’ So he sat down, and the fox began to run, and away they went over stock and stone so quick that their hair whistled in the wind.  When they came to the village, the son followed the fox’s counsel, and without looking about him went to the shabby inn and rested there all night at his ease. In the morning came the fox again and met him as he was beginning his journey, and said, ‘Go straight forward, till you come to a castle, before which lie a whole troop of soldiers fast asleep and snoring: take no notice of them, but go into the castle and pass on and on till you come to a room, where the golden bird sits in a wooden cage; close by it stands a beautiful golden cage; but do not try to take the bird out of the shabby cage and put it into the handsome one, otherwise you will repent it.’ Then the fox stretched out his tail again, and the young man sat himself down, and away they went over stock and stone till their hair whistled in the wind.  Before the castle gate all was as the fox had said: so the son went in and found the chamber where the golden bird hung in a wooden cage, and below stood the golden cage, and the three golden apples that had been lost were lying close by it. Then thought he to himself, ‘It will be a very droll thing to bring away such a fine bird in this shabby cage’; so he opened the door and took hold of it and put it into the golden cage. But the bird set up such a loud scream that all the soldiers awoke, and they took him prisoner and carried him before the king. The next morning the court sat to judge him; and when all was heard, it sentenced him to die, unless he should bring the king the golden horse which could run as swiftly as the wind; and if he did this, he was to have the golden bird given him for his own.  So he set out once more on his journey, sighing, and in great despair, when on a sudden his friend the fox met him, and said, ‘You see now what has happened on account of your not listening to my counsel. I will still, however, tell you how to find the golden horse, if you will do as I bid you. You must go straight on till you come to the castle where the horse stands in his stall: by his side will lie the groom fast asleep and snoring: take away the horse quietly, but be sure to put the old leathern saddle upon him, and not the golden one that is close by it.’ Then the son sat down on the fox’s tail, and away they went over stock and stone till their hair whistled in the wind.  All went right, and the groom lay snoring with his hand upon the golden saddle. But when the son looked at the horse, he thought it a great pity to put the leathern saddle upon it. ‘I will give him the good one,’ said he; ‘I am sure he deserves it.’ As he took up the golden saddle the groom awoke and cried out so loud, that all the guards ran in and took him prisoner, and in the morning he was again brought before the court to be judged, and was sentenced to die. But it was agreed, that, if he could bring thither the beautiful princess, he should live, and have the bird and the horse given him for his own.  Then he went his way very sorrowful; but the old fox came and said, ‘Why did not you listen to me? If you had, you would have carried away both the bird and the horse; yet will I once more give you counsel. Go straight on, and in the evening you will arrive at a castle. At twelve o’clock at night the princess goes to the bathing-house: go up to her and give her a kiss, and she will let you lead her away; but take care you do not suffer her to go and take leave of her father and mother.’ Then the fox stretched out his tail, and so away they went over stock and stone till their hair whistled again.  As they came to the castle, all was as the fox had said, and at twelve o’clock the young man met the princess going to the bath and gave her the kiss, and she agreed to run away with him, but begged with many tears that he would let her take leave of her father. At first he refused, but she wept still more and more, and fell at his feet, till at last he consented; but the moment she came to her father’s house the guards awoke and he was taken prisoner again.  Then he was brought before the king, and the king said, ‘You shall never have my daughter unless in eight days you dig away the hill that stops the view from my window.’ Now this hill was so big that the whole world could not take it away: and when he had worked for seven days, and had done very little, the fox came and said. ‘Lie down and go to sleep; I will work for you.’ And in the morning he awoke and the hill was gone; so he went merrily to the king, and told him that now that it was removed he must give him the princess.  Then the king was obliged to keep his word, and away went the young man and the princess; and the fox came and said to him, ‘We will have all three, the princess, the horse, and the bird.’ ‘Ah!’ said the young man, ‘that would be a great thing, but how can you contrive it?’  ‘If you will only listen,’ said the fox, ‘it can be done. When you come to the king, and he asks for the beautiful princess, you must say, “Here she is!” Then he will be very joyful; and you will mount the golden horse that they are to give you, and put out your hand to take leave of them; but shake hands with the princess last. Then lift her quickly on to the horse behind you; clap your spurs to his side, and gallop away as fast as you can.’  All went right: then the fox said, ‘When you come to the castle where the bird is, I will stay with the princess at the door, and you will ride in and speak to the king; and when he sees that it is the right horse, he will bring out the bird; but you must sit still, and say that you want to look at it, to see whether it is the true golden bird; and when you get it into your hand, ride away.’  This, too, happened as the fox said; they carried off the bird, the princess mounted again, and they rode on to a great wood. Then the fox came, and said, ‘Pray kill me, and cut off my head and my feet.’ But the young man refused to do it: so the fox said, ‘I will at any rate give you good counsel: beware of two things; ransom no one from the gallows, and sit down by the side of no river.’ Then away he went. ‘Well,’ thought the young man, ‘it is no hard matter to keep that advice.’  He rode on with the princess, till at last he came to the village where he had left his two brothers. And there he heard a great noise and uproar; and when he asked what was the matter, the people said, ‘Two men are going to be hanged.’ As he came nearer, he saw that the two men were his brothers, who had turned robbers; so he said, ‘Cannot they in any way be saved?’ But the people said ‘No,’ unless he would bestow all his money upon the rascals and buy their liberty. Then he did not stay to think about the matter, but paid what was asked, and his brothers were given up, and went on with him towards their home.  And as they came to the wood where the fox first met them, it was so cool and pleasant that the two brothers said, ‘Let us sit down by the side of the river, and rest a while, to eat and drink.’ So he said, ‘Yes,’ and forgot the fox’s counsel, and sat down on the side of the river; and while he suspected nothing, they came behind, and threw him down the bank, and took the princess, the horse, and the bird, and went home to the king their master, and said. ‘All this have we won by our labour.’ Then there was great rejoicing made; but the horse would not eat, the bird would not sing, and the princess wept.  The youngest son fell to the bottom of the river’s bed: luckily it was nearly dry, but his bones were almost broken, and the bank was so steep that he could find no way to get out. Then the old fox came once more, and scolded him for not following his advice; otherwise no evil would have befallen him: ‘Yet,’ said he, ‘I cannot leave you here, so lay hold of my tail and hold fast.’ Then he pulled him out of the river, and said to him, as he got upon the bank, ‘Your brothers have set watch to kill you, if they find you in the kingdom.’ So he dressed himself as a poor man, and came secretly to the king’s court, and was scarcely within the doors when the horse began to eat, and the bird to sing, and the princess left off weeping. Then he went to the king, and told him all his brothers’ roguery; and they were seized and punished, and he had the princess given to him again; and after the king’s death he was heir to his kingdom.  A long while after, he went to walk one day in the wood, and the old fox met him, and besought him with tears in his eyes to kill him, and cut off his head and feet. And at last he did so, and in a moment the fox was changed into a man, and turned out to be the brother of the princess, who had been lost a great many many years.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grimm.Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storys = df_grimm.Text.values.tolist()\n",
    "len(storys)  # 63 storys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3595"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grim_line = []\n",
    "for text in storys:\n",
    "    for line in text.split('.'):\n",
    "        line = line.strip().lower().replace('\\n', ' ')\n",
    "        grim_line.append(line)\n",
    "len(grim_line) #lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a certain king had a beautiful garden, and in the garden stood a tree which bore golden apples',\n",
       " 'these apples were always counted, and about the time when they began to grow ripe it was found that every night one of them was gone',\n",
       " 'the king became very angry at this, and ordered the gardener to keep watch all night under the tree',\n",
       " 'the gardener set his eldest son to watch; but about twelve o’clock he fell asleep, and in the morning another of the apples was missing',\n",
       " 'then the second son was ordered to watch; and at midnight he too fell asleep, and in the morning another apple was gone',\n",
       " 'then the third son offered to keep watch; but the gardener at first would not let him, for fear some harm should come to him: however, at last he consented, and the young man laid himself under the tree to watch',\n",
       " 'as the clock struck twelve he heard a rustling noise in the air, and a bird came flying that was of pure gold; and as it was snapping at one of the apples with its beak, the gardener’s son jumped up and shot an arrow at it',\n",
       " 'but the arrow did the bird no harm; only it dropped a golden feather from its tail, and then flew away',\n",
       " 'the golden feather was brought to the king in the morning, and all the council was called together',\n",
       " 'everyone agreed that it was worth more than all the wealth of the kingdom: but the king said, ‘one feather is of no use to me, i must have the whole bird']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of line\n",
    "grim_line[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# assume `df` is your Pandas dataframe\n",
    "# split into train and test/validation\n",
    "ds_train, ds_valid = train_test_split(storys, test_size=0.2, random_state=555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train),len(ds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['content'],\n",
       "        num_rows: 13\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "raw_datasets_train = Dataset.from_pandas(pd.DataFrame(data = {'content': ds_train}))\n",
    "raw_datasets_valid = Dataset.from_pandas(pd.DataFrame(data = {'content': ds_valid}))\n",
    "\n",
    "#remove .shuffle if you want to train the whole dataset....\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        'train':raw_datasets_train,\n",
    "        'valid':raw_datasets_valid\n",
    "    }\n",
    ")\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTENT: There was once upon a time an old goat who had seven little kids, and loved them with all the love of a mother for her children. One day she wanted to go into the forest and fetch some food. So she called all seven to her and said: ‘Dear children, I have to go into the forest, be on your guard against the wolf; if he comes in, he will devour you all--skin, hair, and everything. The wretch often disguises himself, but you will know him at once by his rough voice and his black feet.’ The kids said: ‘Dear mother, we will take good care of ourselves; you may go away without any anxiety.’ Then the old one bleated, and went on her way with an easy mind.  It was not long before someone knocked at the house-door and called: ‘Open the door, dear children; your mother is here, and has brought something back with her for each of you.’ But the little kids knew that it was the wolf, by the rough voice. ‘We will not open the door,’ cried they, ‘you are not our mother. She has a soft, pleasant voice, but your voice is rough; you are the wolf!’ Then the wolf went away to a shopkeeper and bought himself a great lump of chalk, ate this and made his voice soft with it. Then he came back, knocked at the door of the house, and called: ‘Open the door, dear children, your mother is here and has brought something back with her for each of you.’ But the wolf had laid his black paws against the window, and the children saw them and cried: ‘We will not open the door, our mother has not black feet like you: you are the wolf!’ Then the wolf ran to a baker and said: ‘I have hurt my feet, rub some dough over them for me.’ And when the baker had rubbed his feet over, he ran to the miller and said: ‘Strew some white meal over my feet for me.’ The miller thought to himself: ‘The wolf wants to deceive someone,’ and refused; but the wolf said: ‘If you will not do it, I will devour you.’ Then the miller was afraid, and made his paws white for him. Truly, this is the way of mankind.  So now the wretch went for the third time to the house-door, knocked at it and said: ‘Open the door for me, children, your dear little mother has come home, and has brought every one of you something back from the forest with her.’ The little kids cried: ‘First show us your paws that we may know if you are our dear little mother.’ Then he put his paws in through the window and when the kids saw that they were white, they believed that all he said was true, and opened the door. But who should come in but the wolf! They were terrified and wanted to hide themselves. One sprang under the table, the second into the bed, the third into the stove, the fourth into the kitchen, the fifth into the cupboard, the sixth under the washing-bowl, and the seventh into the clock-case. But the wolf found them all, and used no great ceremony; one after the other he swallowed them down his throat. The youngest, who was in the clock-case, was the only one he did not find. When the wolf had satisfied his appetite he took himself off, laid himself down under a tree in the green meadow outside, and began to sleep. Soon afterwards the old goat came home again from the forest. Ah! what a sight she saw there! The house-door stood wide open. The table, chairs, and benches were thrown down, the washing-bowl lay broken to pieces, and the quilts and pillows were pulled off the bed. She sought her children, but they were nowhere to be found. She called them one after another by name, but no one answered. At last, when she came to the youngest, a soft voice cried: ‘Dear mother, I am in the clock-case.’ She took the kid out, and it told her that the wolf had come and had eaten all the others. Then you may imagine how she wept over her poor children.  At length in her grief she went out, and the youngest kid ran with her. When they came to the meadow, there lay the wolf by the tree and snored so loud that the branches shook. She looked at him on every side and saw that something was moving and struggling in his gorged belly. ‘Ah, heavens,’ she said, ‘is it possible that my poor children whom he has swallowed down for his supper, can be still alive?’ Then the kid had to run home and fetch scissors, and a needle and thread, and the goat cut open the monster’s stomach, and hardly had she made one cut, than one little kid thrust its head out, and when she had cut farther, all six sprang out one after another, and were all still alive, and had suffered no injury whatever, for in his greediness the monster had swallowed them down whole. What rejoicing there was! They embraced their dear mother, and jumped like a tailor at his wedding. The mother, however, said: ‘Now go and look for some big stones, and we will fill the wicked beast’s stomach with them while he is still asleep.’ Then the seven kids dragged the stones thither with all speed, and put as many of them into this stomach as they could get in; and the mother sewed him up again in the greatest haste, so that he was not aware of anything and never once stirred.  When the wolf at length had had his fill of sleep, he got on his legs, and as the stones in his stomach made him very thirsty, he wanted to go to a well to drink. But when he began to walk and to move about, the stones in his stomach knocked against each other and rattled. Then cried he:   ‘What rumbles and tumbles   Against my poor bones?   I thought ‘twas six kids,   But it feels like big stones.’  And when he got to the well and stooped over the water to drink, the heavy stones made him fall in, and he drowned miserably. When the seven kids saw that, they came running to the spot and cried aloud: ‘The wolf is dead! The wolf is dead!’ and danced for joy round about the well with their mother.\n"
     ]
    }
   ],
   "source": [
    "for key in raw_datasets[\"train\"][0]:\n",
    "    print(f\"{key.upper()}: {raw_datasets['train'][0][key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 2\n",
      "tensor([[ 1858,   373,  1752,  ...,   511,  2802,    13],\n",
      "        [ 1858,   373,  1752,  ..., 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.padding_side = \"right\" # \"left\" or \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "outputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:2][\"content\"], \n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    )\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(outputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 2\n",
      "Input chunk lengths: [180, 180]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# tokenizer.padding_side = \"right\" # \"left\" or \"right\"\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "context_length = 180\n",
    "outputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:2][\"content\"], \n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707aa5f0e28b403593709e6e426ce2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d384ad4493b644be84a03399b0eb56dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 13\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(element):\n",
    "\n",
    "    outputs = tokenizer(\n",
    "        element[\"content\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "        \n",
    "    # outputs = tokenizer(\n",
    "    #     element[\"content\"], \n",
    "    #     return_tensors=\"pt\",\n",
    "    #     padding=True,\n",
    "    # )\n",
    "    \n",
    "    input_batch = []\n",
    "    for input_ids in outputs[\"input_ids\"]:\n",
    "        input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "# raw_datasets_ = Dataset.from_pandas(pd.DataFrame(data=raw_datasets_train))\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "\n",
    "Our first step is to freshly initialize a GPT-2 model. We’ll use the same configuration for our model as for the small GPT-2 model, so we load the pretrained configuration, make sure that the tokenizer size matches the model vocabulary size and pass the bos and eos (beginning and end of sequence) token IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "context_length  = 180\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that configuration, we can load a new model. Note that this is the first time we don’t use the `from_pretrained()` function, since we’re actually initializing a model ourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.4M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword has not single token: Snow White\n",
      "Keyword has not single token: Catherine \n",
      "Keyword has not single token: Cinderella\n",
      "Keyword has not single token: Elsie\n",
      "Keyword has not single token: Hans\n",
      "Keyword has not single token: Hansel\n",
      "Keyword has not single token: Rapunzel\n"
     ]
    }
   ],
   "source": [
    "keytoken_ids = []\n",
    "for keyword in [\n",
    "    \"Snow White\",\n",
    "    \"Catherine \",\n",
    "    \"Cinderella\",\n",
    "    \"Elsie\",\n",
    "    \"Hans\",\n",
    "    \"Hansel\",\n",
    "    \"Rapunzel\"\n",
    "]:\n",
    "    ids = tokenizer([keyword]).input_ids[0]\n",
    "    if len(ids) == 1:\n",
    "        keytoken_ids.append(ids[0])\n",
    "    else:\n",
    "        print(f\"Keyword has not single token: {keyword}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "\n",
    "Great, that seems to work nicely! We can now write a custom loss function that takes the input sequence, the logits, and the key tokens we just selected as inputs. First we need to align the logits and inputs: the input sequence shifted by one to the right forms the labels, since the next token is the label for the current token. We can achieve this by starting the labels from the second token of the input sequence, since the model does not make a prediction for the first token anyway. Then we cut off the last logit, as we don’t have a label for the token that follows the full input sequence. With that we can compute the loss per sample and count the occurrences of all keywords in each sample. Finally, we calculate the weighted average over all samples using the occurrences as weights. Since we don’t want to throw away all the samples that have no keywords, we add 1 to the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "\n",
    "def keytoken_weighted_loss(inputs, logits, keytoken_ids, alpha=1.0):\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_labels = inputs[..., 1:].contiguous()\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    # Calculate per-token loss\n",
    "    loss_fct = CrossEntropyLoss(reduce=False) #change to reduction=None\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    # Resize and average loss per sample\n",
    "    loss_per_sample = loss.view(shift_logits.size(0), shift_logits.size(1)).mean(axis=1)\n",
    "    # Calculate and scale weighting\n",
    "    # weights = torch.stack([(inputs == kt).float() for kt in keytoken_ids]).sum(\n",
    "    #     axis=[0, 2]\n",
    "    # )\n",
    "    # weights = alpha * (1.0 + weights)\n",
    "    # Calculate weighted average\n",
    "    # weighted_loss = (loss_per_sample * weights).mean()\n",
    "    weighted_loss = loss_per_sample.mean()\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=8, shuffle=True)\n",
    "eval_dataloader  = DataLoader(tokenized_datasets[\"valid\"], batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 180])\n"
     ]
    }
   ],
   "source": [
    "for train in train_dataloader:\n",
    "    print(train['input_ids'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Next, we group the parameters so that the optimizer knows which ones will get an additional weight decay. Usually, all bias and LayerNorm weights terms are exempt from this; here’s how we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.1\n",
    "\n",
    "def get_grouped_params(model, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
    "    params_with_wd, params_without_wd = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if any(nd in n for nd in no_decay):\n",
    "            params_without_wd.append(p)\n",
    "        else:\n",
    "            params_with_wd.append(p)\n",
    "    return [\n",
    "        {\"params\": params_with_wd, \"weight_decay\": weight_decay},\n",
    "        {\"params\": params_without_wd, \"weight_decay\": 0.0},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to evaluate the model regularly on the validation set during training, let’s write a function for that as well. It just runs through the evaluation dataloader and gathers all the losses across processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in tqdm(enumerate(eval_dataloader)):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs = model(batch[\"input_ids\"].to(device), labels=batch[\"input_ids\"].to(device))\n",
    "            outputs.loss = outputs.loss.reshape(1)\n",
    "        losses.append(accelerator.gather(outputs.loss))        \n",
    "    loss = torch.mean(torch.cat(losses))\n",
    "    try:\n",
    "        perplexity = torch.exp(loss)\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    return loss.item(), perplexity.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `evaluate()` function we can report loss and perplexity at regular intervals. Next, we redefine our model to make sure we train from scratch again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define our optimizer, using the function from before to split the parameters for weight decay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(get_grouped_params(model), lr=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerator\n",
    "\n",
    "Now let’s prepare the model, optimizer, and dataloaders so we can start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator(mixed_precision='fp16')\n",
    "\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have sent our `train_dataloader` to `accelerator.prepare()`, we can use its length to compute the number of training steps. Remember that we should always do this after preparing the dataloader, as that method will change its length. We use a classic linear schedule from the learning rate to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 1\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=1_000,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repository\n",
    "\n",
    "Lastly, to push our model to the Hub, we will need to create a `Repository` object in a working folder. First log in to the Hugging Face Hub, if you aren’t logged in already. We’ll determine the repository name from the model ID we want to give our model (feel free to replace the repo_name with your own choice; it just needs to contain your username, which is what the function `get_full_repo_name()` does):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to C:\\Users\\Guntsv\\.huggingface\\token\n",
      "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
      "\n",
      "git config --global credential.helper store\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git config --global credential.helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'guntsv/grim-gpt2-accelerate'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"grim-gpt2-accelerate\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can clone that repository in a local folder. If it already exists, this local folder should be an existing clone of the repository we are working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guntsv\\Documents\\GitHub\\DSAI-AIT-2022\\Course\\Natural Language Understanding\\Assignment\\09 - LM using Huggingface\\grim-gpt2-accelerate is already a clone of https://huggingface.co/guntsv/grim-gpt2-accelerate. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "output_dir = \"grim-gpt2-accelerate\"\n",
    "repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now upload anything we save in `output_dir` by calling the `repo.push_to_hub()` method. This will help us upload the intermediate models at the end of each epoch.\n",
    "\n",
    "## 4. Training\n",
    "\n",
    "Before we train, let’s run a quick test to see if the evaluation function works properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3049d82cad4141259910a062e2cdf33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10.94241714477539, 56523.8046875)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are very high values for loss and perplexity, but that’s not surprising as we haven’t trained the model yet. With that, we have everything prepared to write the core part of the training script: the training loop. In the training loop we iterate over the dataloader and pass the batches to the model. With the logits, we can then evaluate our custom loss function. We scale the loss by the number of gradient accumulation steps so as not to create larger losses when aggregating more steps. Before we optimize, we also clip the gradients for better convergence. Finally, every few steps we evaluate the model on the evaluation set with our new `evaluate()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970f9a009d9b469d82a0f72d3d2950fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'steps': 0, 'loss/train': 21.988143920898438}\n",
      "2\n",
      "{'steps': 0, 'loss/train': 21.983495712280273}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5a6319b6ac4a0ebaf5c626ec49e714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 10.94241714477539, 'perplexity': 56523.8046875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (7) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{'steps': 1, 'loss/train': 21.908294677734375}\n",
      "4\n",
      "{'steps': 1, 'loss/train': 21.904491424560547}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3318108862ea44f19cf6469e5bdfc602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 10.905723571777344, 'perplexity': 54487.3359375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (8) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'steps': 2, 'loss/train': 21.87574005126953}\n",
      "6\n",
      "{'steps': 2, 'loss/train': 21.909610748291016}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc5275a7eab47ef8f093fa30fb85c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss/eval': 10.83304214477539, 'perplexity': 50667.609375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (9) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "{'steps': 3, 'loss/train': 21.86929702758789}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "gradient_accumulation_steps = 2\n",
    "eval_steps = 1\n",
    "\n",
    "model.train()\n",
    "completed_steps = 0\n",
    "for epoch in range(num_train_epochs):\n",
    "    for step, batch in tqdm(enumerate(train_dataloader, start=1), total=num_training_steps):\n",
    "        print(step)\n",
    "        logits = model(batch[\"input_ids\"]).logits\n",
    "        loss = keytoken_weighted_loss(batch[\"input_ids\"], logits, keytoken_ids)\n",
    "\n",
    "        if step % 1 == 0:\n",
    "            accelerator.print(\n",
    "                {\n",
    "                    \"steps\": completed_steps,\n",
    "                    \"loss/train\": loss.item() * gradient_accumulation_steps,\n",
    "                }\n",
    "            )\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        # print(loss)\n",
    "        accelerator.backward(loss) #instance of optimize.backward()\n",
    "\n",
    "        if step % gradient_accumulation_steps == 0:\n",
    "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            completed_steps += 1\n",
    "            \n",
    "        if (step % (eval_steps * gradient_accumulation_steps)) == 0:\n",
    "            eval_loss, perplexity = evaluate()\n",
    "            accelerator.print({\"loss/eval\": eval_loss, \"perplexity\": perplexity})\n",
    "            model.train()\n",
    "            #save your model\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "            if accelerator.is_main_process:\n",
    "                tokenizer.save_pretrained(output_dir)\n",
    "                repo.push_to_hub(\n",
    "                    commit_message=f\"Training in progress step {step}\", blocking=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inference\n",
    "\n",
    "Now is the moment of truth: let’s see how well the trained model actually works! We can see in the logs that the loss went down steadily, but to put the model to the test let’s take a look at how well it works on some prompts. To do that we’ll wrap the model in a text generation pipeline, and we’ll put it on the GPU for fast generations if there is one available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "checkpoints = \"guntsv/grim-gpt2-accelerate\"\n",
    "pipe = pipeline(\"text-generation\", max_length=100, pad_token_id=0, model=checkpoints) #eos_token_id=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cinderella is going to tolest MIDIdll Grain,,, MIDI,kids,,,,,,, Wiki, escape,,,,iken,,sureAlert vil,,,,,,, Clin,,,,OR, certainty,,chapter,,, Clin,,,, curv,,,,,,,,,,,,,,,,,,,,,,. malt the,,,,, �,,,, curv'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"cinderella is going to\"\n",
    "# print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])\n",
    "pipe(txt, num_return_sequences=1)[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# # add the EOS token as PAD token to avoid warnings\n",
    "checkpoints = \"guntsv/grim-gpt2-accelerate\"\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n",
    "model = GPT2LMHeadModel.from_pretrained(checkpoints, pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode context the generation is conditioned on\n",
    "# input_ids = tokenizer.encode('Alice and Red Queen live at AIT University in Thai', return_tensors='pt')\n",
    "input_ids = tokenizer.encode(\"cinderella is going to\", return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate beam search and early_stopping\n",
    "beam_output = model.generate(\n",
    "    input_ids, \n",
    "    max_length=50, \n",
    "    num_beams=4, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
