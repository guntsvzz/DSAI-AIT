{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec (Negative Sampling) \n",
    "\n",
    "2 things we need to add\n",
    "- how to smaple the negative smaples\n",
    "- the process of gerring the negative samples\n",
    "\n",
    "1 thing we need to change : model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.23.4', '1.13.1+cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the sentences / corpus \n",
    "#corpus is define as set of document\n",
    "#document is basically a nuch of sentence(s)\n",
    "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\", \"grape apple apple\", \n",
    "          \"dog cat animal\", \"cat dog animal\", \"cat animal dog\", \"fish dog dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['grape', 'apple', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'dog', 'animal'],\n",
       " ['cat', 'animal', 'dog'],\n",
       " ['fish', 'dog', 'dog']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. tokenize\n",
    "#usually you use spaCy/ NLTK to tokenize (but we gonna do this later on, we gonna have spaCy)\n",
    "corpus_tokenized = [sent.split(\" \") for sent in corpus]\n",
    "corpus_tokenized #we called each of this as 'tokens' NOT words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. numericalize (vocab)\n",
    "\n",
    "#2.1 get all the unique words\n",
    "#we want to flatten unit (basically merge all list)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs = list(set(flatten(corpus_tokenized))) #vocabs is a term degining all unique words your system know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 0,\n",
       " 'animal': 1,\n",
       " 'cat': 2,\n",
       " 'apple': 3,\n",
       " 'fruit': 4,\n",
       " 'banana': 5,\n",
       " 'grape': 6,\n",
       " 'fish': 7}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.2 assign id to all these vocabs\n",
    "word2index = {v: idx for idx, v in enumerate(vocabs)}\n",
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add <UNK>, which is a very normal token exits in the world\n",
    "vocabs.append('<UNK>') #chaky, can it be ##UNK, or UNKKKKK, or anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have a way to know what is the id of <UNK>\n",
    "word2index['<UNK>'] = 6 #usually <UNK> is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'dog',\n",
       " 1: 'animal',\n",
       " 2: 'cat',\n",
       " 3: 'apple',\n",
       " 4: 'fruit',\n",
       " 5: 'banana',\n",
       " 6: '<UNK>',\n",
       " 7: 'fish'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create index2word dictionary\n",
    "# index2word = {idx: v for idx, v in enumerate(vocabs)}\n",
    "# index2word\n",
    "\n",
    "# for key,value in word2index.items():\n",
    "#     print(key,value)\n",
    "\n",
    "index2word = {v:k for k,v in word2index.items()}\n",
    "index2word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare train data\n",
    "You move the window along, and create those tuples as we said in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['banana', 'apple'],\n",
       " ['banana', 'fruit'],\n",
       " ['apple', 'banana'],\n",
       " ['apple', 'fruit'],\n",
       " ['fruit', 'banana'],\n",
       " ['fruit', 'apple'],\n",
       " ['apple', 'grape'],\n",
       " ['apple', 'apple'],\n",
       " ['cat', 'dog'],\n",
       " ['cat', 'animal'],\n",
       " ['dog', 'cat'],\n",
       " ['dog', 'animal'],\n",
       " ['animal', 'cat'],\n",
       " ['animal', 'dog'],\n",
       " ['dog', 'fish'],\n",
       " ['dog', 'dog']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move along the corpus\n",
    "#to fit with our corus, we gonna use window_size = 1\n",
    "skipgrams =[]\n",
    "#for each corpus\n",
    "for sent in corpus_tokenized:\n",
    "    #for each sent ('apple', 'banana', 'fruit')\n",
    "    for i in range(1,len(sent)-1): #start from 1 to second last\n",
    "        # print(sent[i])\n",
    "        center_word = sent[i]\n",
    "        outside_word = [sent[i-1],sent[i+1]] #window_size =1\n",
    "        #here we want to create (banana, apple), (banana, fruit) append to some list\n",
    "        for o in outside_word:\n",
    "            skipgrams.append([center_word,o])\n",
    "skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = [  'apple banana fruit','banana apple fruit','banana fruit apple',\n",
    "#             'dog cat animal', 'cat dog animal', 'cat animal dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make what we have made into a fucntion (batch function)\n",
    "#return a batches of data, e.g., = 2 --> ['banana', 'apple'],['banana','fruit']\n",
    "#also i want these batches ti be id, NOT token --> [5,4]\n",
    "\n",
    "def random_batch(batch_size, corpus):\n",
    "    skipgrams =[]\n",
    "    #for each corpus\n",
    "    for sent in corpus_tokenized:\n",
    "        #for each sent ('apple', 'banana', 'fruit')\n",
    "        for i in range(1,len(sent)-1): #start from 1 to second last\n",
    "            # print(sent[i])\n",
    "            center_word = word2index[sent[i]]\n",
    "            outside_word = [word2index[sent[i-1]],word2index[sent[i+1]]] #window_size =1\n",
    "            #here we want to create (banana, apple), (banana, fruit) append to some list\n",
    "            for o in outside_word:\n",
    "                skipgrams.append([center_word,o])\n",
    "    #only get a batch, mot the entire lsit\n",
    "    random_index = np.random.choice(range(len(skipgrams)),batch_size,replace=False)\n",
    "    \n",
    "    #appending some list of inputs and labels\n",
    "    random_inputs, random_labels = [] , []\n",
    "    for index in random_index:\n",
    "        random_inputs.append([skipgrams[index][0]]) #center words, this will be as shape of (1,) -> (1,1) for modeling\n",
    "        random_labels.append([skipgrams[index][1]])\n",
    "\n",
    "    return np.array(random_inputs),np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "label.shape=(10, 1)\n"
     ]
    }
   ],
   "source": [
    "input,label = random_batch(10, corpus_tokenized)\n",
    "\n",
    "print(f'{input.shape}')\n",
    "print(f'{label.shape=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unigram Distribution\n",
    "\n",
    "$$P(w)=U(w)^{3/4}/Z$$\n",
    "\n",
    "Defining the probability of sampling negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basically create a distribution of all the words you have in your vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0.0001 #scaling up lower frequency terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'apple': 5,\n",
       "         'banana': 3,\n",
       "         'fruit': 3,\n",
       "         'grape': 1,\n",
       "         'dog': 5,\n",
       "         'cat': 3,\n",
       "         'animal': 3,\n",
       "         'fish': 1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count all the occurence of vocabs\n",
    "from collections import Counter\n",
    "\n",
    "word_count = Counter(flatten(corpus_tokenized))\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_total_words = sum([c for w, c in word_count.items()])\n",
    "num_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'dog': 3083,\n",
       "         'animal': 2102,\n",
       "         'cat': 2102,\n",
       "         'apple': 3083,\n",
       "         'fruit': 2102,\n",
       "         'banana': 2102,\n",
       "         'grape': 922,\n",
       "         'fish': 922})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_table = []\n",
    "\n",
    "for v in vocabs:\n",
    "    uw = word_count[v]/num_total_words\n",
    "    uw_alpha = uw ** 0.75\n",
    "    uw_alpha_dividebyz = int(uw_alpha/z)\n",
    "    # print('Vocab :',v)\n",
    "    # print('distribution :', uw_alpha_dividebyz)\n",
    "    unigram_table.extend([v] * uw_alpha_dividebyz)\n",
    "\n",
    "Counter(unigram_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Negative Sampling\n",
    "\n",
    "A function to get negavtive samples, based o nthe current center and outsode words in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    #map(fucntion, list of something)\n",
    "    #map will look at each of element in this list, and apply this function\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#you don't want to pick samples = targets, basically negative samples\n",
    "#k = number of negative samples - how many? they found 10 is the best\n",
    "#will be run during training\n",
    "#after random_batch, \n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    #targets is already in id.....\n",
    "    #but the unigram_table is in word....\n",
    "    #1. get the batch size of this targets\n",
    "    batch_size = targets.shape[0]\n",
    "    neg_samples = []\n",
    "    #2. for each batch\n",
    "    for i in range(batch_size):\n",
    "        #randomly pick k negative words from unigram_table\n",
    "        target_index = targets[i].item()  #looping each of the batch....\n",
    "        nsample = []\n",
    "        while len(nsample) < k:\n",
    "            neg = random.choice(unigram_table)\n",
    "            #if this word == target, skip this word\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        #append this word to some list\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).reshape(1, -1))  #tensor[], tensor[]\n",
    "    return torch.cat(neg_samples)  #tensor[[], []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our negative Sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3],\n",
       "        [1]]),\n",
       " array([[5],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input_batch, label_batch = random_batch(batch_size,corpus_tokenized)\n",
    "\n",
    "input_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = torch.LongTensor(input_batch)\n",
    "label_batch  = torch.LongTensor(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neg = 2 # in the real code, we gonna use 10 (like in the paper)\n",
    "neg_samples = negative_sampling(label_batch, unigram_table, num_neg)\n",
    "# neg_samples[0].shape\n",
    "neg_samples.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5],\n",
       "        [0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model\n",
    "\n",
    "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model will accept three vectors - u_o, v_c, u_k\n",
    "#u_o - vectos for outside words\n",
    "#v_C - vector for center word\n",
    "#u_k - vectors for negative word\n",
    "\n",
    "class SkipgramNeg(nn.Module):\n",
    "    def __init__(self,voc_size, emb_size):\n",
    "        super(SkipgramNeg,self).__init__()\n",
    "        self.embedding_center_word = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "\n",
    "    def forward(self, center_words, outside_words, negative_words):\n",
    "        #center_words, outside_words  (batch_size,1)\n",
    "        #negative_words (batch_size,k) \n",
    "        center_embed    = self.embedding_center_word(center_words)      #(batch_size,1, emb_size)\n",
    "        outside_embed   = self.embedding_outside_word(outside_words)   #(batch_size,1, emb_size)\n",
    "        neg_embed       = self.embedding_outside_word(negative_words)      #(batch_size,k, emb_size)\n",
    "        \n",
    "        uovc            = outside_embed.bmm(center_embed.transpose(1,2)).squeeze(2)\n",
    "        ukvc            = -neg_embed.bmm(center_embed.transpose(1,2)).squeeze(2)\n",
    "        ukvc_sum        =  torch.sum(ukvc, 1).view(-1, 1) #(batch_size, 1)\n",
    "        loss = self.logsigmoid(uovc) + self.logsigmoid(ukvc_sum) #(batch_size,1)+(batch_size,1)\n",
    "        \n",
    "        return -torch.mean(loss) #scalar, loss should be scalar, to call backward()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = random_batch(batch_size, corpus_tokenized)\n",
    "input_tensor = torch.LongTensor(input)\n",
    "label_tensor  = torch.LongTensor(label) #longTensor menas integer......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape,label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 2 #usually, this can be 50, 100, or 300\n",
    "voc_size = len(vocabs)\n",
    "model = SkipgramNeg(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tensor = negative_sampling(label_tensor, unigram_table, 5)\n",
    "neg_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should give one number\n",
    "loss = model(input_tensor, label_tensor, neg_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5937, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = len(vocabs)\n",
    "voc_size\n",
    "\n",
    "batch_size = 2 #why? no reason\n",
    "emb_size = 2 #why? no reason; usually 50,100, 300 but 2 so we can plot (50 can also plot, but need PCA)\n",
    "model = SkipgramNeg(voc_size,emb_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #-log\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Loss 0.923760 | Time : ?\n",
      "Epoch 2000 | Loss 0.606125 | Time : ?\n",
      "Epoch 3000 | Loss 0.459829 | Time : ?\n",
      "Epoch 4000 | Loss 0.183600 | Time : ?\n",
      "Epoch 5000 | Loss 0.184393 | Time : ?\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000\n",
    "#for epoch\n",
    "for epoch in range(num_epochs):\n",
    "    #get random batch\n",
    "    input_batch, label_batch = random_batch(batch_size,corpus)\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    label_batch = torch.LongTensor(label_batch)\n",
    "    neg_batch = negative_sampling(label_tensor, unigram_table, 5)\n",
    "    \n",
    "    #loss = model\n",
    "    loss = model(input_batch,label_batch,neg_batch)\n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f'Epoch {epoch+1} | Loss {loss:.6f} | Time : ?')\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1]) torch.Size([2, 1]) torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(input_batch.shape,label_batch.shape,neg_batch.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plotting the embeddings\n",
    "\n",
    "Is really the related studd are close to each other, and vice versa.\n",
    "\n",
    "The most fun part: Will 'banana' closer to 'fruit' than 'cat'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'animal', 'cat', 'apple', 'fruit', 'banana', 'grape', 'fish', '<UNK>']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana = torch.LongTensor([word2index['banana']])\n",
    "banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7115, 0.0233]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana_center_embed = model.embedding_center_word(banana)\n",
    "banana_outside_embed = model.embedding_outside_word(banana)\n",
    "banana_embed = (banana_center_embed+banana_outside_embed)/2\n",
    "banana_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.2000017166137695, -0.5560286045074463)\n",
      "(-2.8268682956695557, 0.8387230038642883)\n",
      "(1.0081284046173096, -1.5003467798233032)\n"
     ]
    }
   ],
   "source": [
    "#find embedding of fruit, cat\n",
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except :\n",
    "        index = word2index['<UNK>'] #unknown\n",
    "    word = torch.LongTensor([index])\n",
    "    \n",
    "    embed =  (model.embedding_center_word(word)+model.embedding_outside_word(word))/2\n",
    "    return embed[0][0].item(),embed[0][1].item()\n",
    "    \n",
    "print(get_embed('fruit'))\n",
    "print(get_embed('cat'))\n",
    "print(get_embed('chaky'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#help me plot fruit cat banana on maplotlib\n",
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]):\n",
    "    x,y = get_embed(word)\n",
    "    plt.scatter(x,y)\n",
    "    plt.annotate(word,xy=(x,y),xytext=(5,2),textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cosine Similarity\n",
    "How do (from Scratch) calcualte cosine similarity?\n",
    "\n",
    "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
    "\n",
    "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
    "\n",
    "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'animal', 'cat', 'apple', 'fruit', 'banana', 'grape', 'fish', '<UNK>']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try similarity between first and second, and second and third\n",
    "cat          = get_embed('cat')\n",
    "fruit        = get_embed('fruit')\n",
    "animal       = get_embed('animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat vs. fruit:  -0.9877318352503154\n",
      "cat vs. animal:  0.9675721165825377\n",
      "cat vs. cat:  1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "#numpy version\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim\n",
    "    \n",
    "print(f\"cat vs. fruit: \",cos_sim(cat, fruit))\n",
    "print(f\"cat vs. animal: \",cos_sim(cat, animal))\n",
    "print(f\"cat vs. cat: \",cos_sim(cat, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat vs. fruit:  -0.9877318352503155\n",
      "cat vs. animal:  0.9675721165825377\n",
      "cat vs. cat:  1\n"
     ]
    }
   ],
   "source": [
    "#scipy version\n",
    "from scipy import spatial\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
    "    return cos_sim\n",
    "\n",
    "print(f\"cat vs. fruit: \",cos_sim(cat, fruit))\n",
    "print(f\"cat vs. animal: \",cos_sim(cat, animal))\n",
    "print(f\"cat vs. cat: \",cos_sim(cat, cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
