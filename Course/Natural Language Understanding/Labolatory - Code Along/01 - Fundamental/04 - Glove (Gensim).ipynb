{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe : Global Vectors for Word Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the sentences / corpus \n",
    "#corpus is define as set of document\n",
    "#document is basically a nuch of sentence(s)\n",
    "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\", \n",
    "          \"dog cat animal\", \"cat dog animal\", \"cat animal dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'dog', 'animal'],\n",
       " ['cat', 'animal', 'dog']]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. tokenize\n",
    "#usually you use spaCy/ NLTK to tokenize (but we gonna do this later on, we gonna have spaCy)\n",
    "corpus_tokenized = [sent.split(\" \") for sent in corpus]\n",
    "corpus_tokenized #we called each of this as 'tokens' NOT words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'cat', 'apple', 'animal', 'fruit', 'banana']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. numericalize (vocab)\n",
    "\n",
    "#2.1 get all the unique words\n",
    "#we want to flatten unit (basically merge all list)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs = list(set(flatten(corpus_tokenized))) #vocabs is a term degining all unique words your system know\n",
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 0, 'cat': 1, 'apple': 2, 'animal': 3, 'fruit': 4, 'banana': 5}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.2 assign id to all these vocabs\n",
    "word2index = {v: idx for idx, v in enumerate(vocabs)}\n",
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add <UNK>, which is a very normal token exits in the world\n",
    "vocabs.append('<UNK>') #chaky, can it be ##UNK, or UNKKKKK, or anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have a way to know what is the id of <UNK>\n",
    "word2index['<UNK>'] = 6 #usually <UNK> is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'dog',\n",
       " 1: 'cat',\n",
       " 2: 'apple',\n",
       " 3: 'animal',\n",
       " 4: 'fruit',\n",
       " 5: 'banana',\n",
       " 6: '<UNK>'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create index2word dictionary\n",
    "# index2word = {idx: v for idx, v in enumerate(vocabs)}\n",
    "# index2word\n",
    "\n",
    "# for key,value in word2index.items():\n",
    "#     print(key,value)\n",
    "\n",
    "index2word = {v:k for k,v in word2index.items()}\n",
    "index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'cat', 'apple', 'animal', 'fruit', 'banana', '<UNK>']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Co-occurence Matrix X\n",
    "\n",
    "Count the occurrences of pair of words using window size of 1 (you can use 2, 3, 4, up to you)\n",
    "\n",
    "E.g., Dog loves to eat meal.\n",
    "\n",
    "['Dog','loves',1],['loves','to',1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apple', 'banana', 'fruit'], ['banana', 'apple', 'fruit'], ['banana', 'fruit', 'apple'], ['dog', 'cat', 'animal'], ['cat', 'dog', 'animal'], ['cat', 'animal', 'dog']]\n"
     ]
    }
   ],
   "source": [
    "#use Counter to first count stuffs\n",
    "from collections import Counter\n",
    "print(corpus_tokenized)\n",
    "\n",
    "#count the frequency of each word\n",
    "#we somehow need this to claiclate the probability Pi\n",
    "X_i = Counter(flatten(corpus_tokenized)) #merge all list ... (flattten is a function I defines)\n",
    "# X_i['apple'] #get the probability of apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defome a skipgram of window size 1\n",
    "skip_grams = []\n",
    "#loop thriugh each corpus\n",
    "for sent in corpus_tokenized:\n",
    "    #loop through each word from i to n-1 (because 0 and n has no context window)\n",
    "    for idx,i in enumerate(range(1, len(sent)-1)):\n",
    "        # print(sent[i])\n",
    "        target = sent[i] #center word\n",
    "        context = [sent[i-1],sent[i+1]]\n",
    "        #append(i,i+1) and append(i,i-1)\n",
    "        for c in context:\n",
    "            skip_grams.append((target,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'dog', 'animal'],\n",
       " ['cat', 'animal', 'dog']]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('banana', 'apple'),\n",
       " ('banana', 'fruit'),\n",
       " ('apple', 'banana'),\n",
       " ('apple', 'fruit'),\n",
       " ('fruit', 'banana'),\n",
       " ('fruit', 'apple'),\n",
       " ('cat', 'dog'),\n",
       " ('cat', 'animal'),\n",
       " ('dog', 'cat'),\n",
       " ('dog', 'animal'),\n",
       " ('animal', 'cat'),\n",
       " ('animal', 'dog')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('banana', 'apple'): 1,\n",
       "         ('banana', 'fruit'): 1,\n",
       "         ('apple', 'banana'): 1,\n",
       "         ('apple', 'fruit'): 1,\n",
       "         ('fruit', 'banana'): 1,\n",
       "         ('fruit', 'apple'): 1,\n",
       "         ('cat', 'dog'): 1,\n",
       "         ('cat', 'animal'): 1,\n",
       "         ('dog', 'cat'): 1,\n",
       "         ('dog', 'animal'): 1,\n",
       "         ('animal', 'cat'): 1,\n",
       "         ('animal', 'dog'): 1})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#since we have these occcurences, we can count, to make our co-occurence matrix!!!\n",
    "X_ik_skipgram = Counter(skip_grams)\n",
    "X_ik_skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ik_skipgram[('banana','animal')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weighting function f\n",
    "\n",
    "GloVe includes a weighting function to scale down too frequent words.\n",
    "\n",
    "<img src = \"figures/glove_weighting_func.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting(w_i,w_j,X_ik): #we need w_i and w_j, because we can try its-co-occurrences, if it's too big, we scale it down\n",
    "    #check whether the co-occurrences between these two word exits??\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i,w_j)]\n",
    "    except:\n",
    "        x_ij = 1 #why one, so that the probability thingly won't break....\n",
    "    \n",
    "    #maximum co-occurrences; we follow the paper\n",
    "    x_max = 100\n",
    "    alpha = 0.75\n",
    "\n",
    "    #if the co-occurrences does not exceed x_max, cale it down based on some alpha\n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max)**alpha\n",
    "    else:\n",
    "        result = 1 #this is the maximum probability you can havve\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03162277660168379\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w_i = 'banana'\n",
    "w_j = 'fruit'\n",
    "w_j2 = 'chaky'\n",
    "\n",
    "print(weighting(w_i,w_j, X_ik_skipgram)) #scale from 1 to 0.0316\n",
    "print(weighting(w_i,w_j2, X_ik_skipgram))  #the paper says that f(0) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ik_skipgram.get(('banana','fruit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now apply this weighting to all possible pairs\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "X_ik = {} #for keeping the co-occurrences\n",
    "weighting_dic = {} #for keeping all the probability after passing through the weighting function\n",
    "\n",
    "for bigram in combinations_with_replacement(vocabs,2): #we need to also think its reverse\n",
    "    # print(bigram)\n",
    "    #if this bigram exists in X_ik_skipgrams\n",
    "    #we gonna add this to our c-occurence matrix\n",
    "    if X_ik_skipgram.get(bigram) is not None:\n",
    "        cooc = X_ik_skipgram[bigram] #get the co-occurrences\n",
    "        X_ik[bigram] = cooc + 1 #this is agian basically label smoothing.... (stability issue (especailly when divide something))\n",
    "        X_ik[(bigram[1],bigram[0])] = cooc + 1 #trick to get all pairs\n",
    "    else: #otherwise, do nothing\n",
    "        pass\n",
    "    #apply the weighting function using this co-occurrence matrix thingly\n",
    "    weighting_dic[bigram] = weighting(bigram[0],bigram[1],X_ik)\n",
    "    weighting_dic[(bigram[1],bigram[0])] = weighting(bigram[1],bigram[0],X_ik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_ik_skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('dog', 'cat'): 2,\n",
       " ('cat', 'dog'): 2,\n",
       " ('dog', 'animal'): 2,\n",
       " ('animal', 'dog'): 2,\n",
       " ('cat', 'animal'): 2,\n",
       " ('animal', 'cat'): 2,\n",
       " ('apple', 'fruit'): 2,\n",
       " ('fruit', 'apple'): 2,\n",
       " ('apple', 'banana'): 2,\n",
       " ('banana', 'apple'): 2,\n",
       " ('fruit', 'banana'): 2,\n",
       " ('banana', 'fruit'): 2}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighting_dic #give small probability to never-occured is called 'label smoothing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare train data\n",
    "You move the window along, and create those tuples as we said in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'fruit']\n",
      "['banana', 'apple', 'fruit']\n",
      "['banana', 'fruit', 'apple']\n",
      "['dog', 'cat', 'animal']\n",
      "['cat', 'dog', 'animal']\n",
      "['cat', 'animal', 'dog']\n"
     ]
    }
   ],
   "source": [
    "for c in corpus_tokenized:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def random_batch(batch_size,word_sequence,skip_grams,X_ik,weighting_dic):\n",
    "    #loop through skipgram, and change it id because when sending model, it must number \n",
    "    skipg_grams_id = [(word2index[skip_gram[0]],word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
    "    #randomly pick 'batch_size' indexes\n",
    "    number_of_choices = len(skipg_grams_id)\n",
    "    random_index = np.random.choice(number_of_choices, batch_size, replace=False) #no repeating indexes among  these random indexes\n",
    "    \n",
    "    # print(random_index)\n",
    "    random_inputs = [] #xi, wi (in batches)\n",
    "    random_labels = [] #xj, wj (in batches)\n",
    "    random_coocs  = [] #xij (in batches)\n",
    "    random_weighting = [] #f(xij) (in batches)\n",
    "    #for each of the sample in these indexes\n",
    "    for i in random_index:\n",
    "        random_inputs.append([skipg_grams_id[i][0]]) #same reason why I put bracket here....\n",
    "        random_labels.append([skipg_grams_id[i][1]])\n",
    "\n",
    "        #get coocs\n",
    "        #first check whether it exists.....\n",
    "        pair = skip_grams[i] #e.g., ['banana','fruit']\n",
    "        try:\n",
    "            cooc = X_ik[pair]\n",
    "        except:\n",
    "            cooc = 1 #label smoothing\n",
    "\n",
    "        random_coocs.append([math.log(cooc)]) #1. why log, #2 why bracket -> size ==> (,1) #my neural network excepts (,1)\n",
    "        \n",
    "        #for weighting\n",
    "        weighting = weighting_dic[pair] #why not user try... maybe it does not exist\n",
    "        random_weighting.append(weighting)\n",
    "\n",
    "    return np.array(random_inputs),np.array(random_labels),np.array(random_coocs),np.array(random_weighting)\n",
    "        #return xi,xj\n",
    "        #return cooc Xij\n",
    "        #return weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "input,target,coocs,weightin = random_batch(batch_size,corpus_tokenized,skip_grams,X_ik,weighting_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [1]]),\n",
       " array([[3],\n",
       "        [0]]),\n",
       " array([[0.69314718],\n",
       "        [0.69314718]]),\n",
       " array([0.05318296, 0.05318296]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input,target,coocs,weightin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model\n",
    "\n",
    "<img src =\"figures/glove.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model will accept three vectors - u_o, v_c, u_w\n",
    "#u_o - vectos for outside words\n",
    "#v_C - vector for center word\n",
    "#u_w - vectors of all vocabs\n",
    "\n",
    "class GloVe(nn.Module):\n",
    "    def __init__(self,voc_size, emb_size):\n",
    "        super(GloVe,self).__init__()\n",
    "        self.embedding_center_word = nn.Embedding(voc_size, emb_size) #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "        \n",
    "        self.bias_i = nn.Embedding(voc_size, 1)\n",
    "        self.bias_j = nn.Embedding(voc_size, 1)\n",
    "    def forward(self, center_words, outside_words, coocs, weighting):\n",
    "        #get the embedding of center_words and outside_words\n",
    "        center_embeds = self.embedding_center_word(center_words)\n",
    "        outside_embeds = self.embedding_outside_word(outside_words)\n",
    "\n",
    "        #create biases #create unique embedding (voc_size,1)\n",
    "        inner_product = center_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        bias_i = self.bias_i(center_words).squeeze(1) #center\n",
    "        bias_j = self.bias_j(outside_words).squeeze(1) #target\n",
    "        #do the product between wi and wj\n",
    "        loss = weighting * torch.pow(inner_product + bias_i + bias_j - coocs, 2)\n",
    "        \n",
    "        return torch.sum(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = len(vocabs)\n",
    "batch_size = 2 #why? no reason\n",
    "emb_size = 2 #why? no reason; usually 50,100, 300 but 2 so we can plot (50 can also plot, but need PCA)\n",
    "model = GloVe(voc_size,emb_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #-log\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Loss 0.214300 | Time : 0m 1s\n",
      "Epoch 2000 | Loss 0.280225 | Time : 0m 2s\n",
      "Epoch 3000 | Loss 0.372769 | Time : 0m 3s\n",
      "Epoch 4000 | Loss 0.194346 | Time : 0m 4s\n",
      "Epoch 5000 | Loss 0.014336 | Time : 0m 5s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 5000\n",
    "#for epoch\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    #get random batch\n",
    "    input, label, cooc, weightin = random_batch(batch_size,corpus_tokenized,skip_grams,X_ik,weighting_dic)\n",
    "    input_batch = torch.LongTensor(input)\n",
    "    label_batch = torch.LongTensor(label)\n",
    "    cooc_batch = torch.FloatTensor(cooc)\n",
    "    weightin_batch = torch.FloatTensor(weightin)\n",
    "\n",
    "    # print(input_batch.shape,label_batch.shape,cooc_batch.shape,weightin_batch.shape)\n",
    "\n",
    "    #loss = model\n",
    "    loss = model(input_batch,label_batch,cooc_batch,weightin_batch)\n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f'Epoch {epoch+1} | Loss {loss:.6f} | Time : {epoch_mins}m {epoch_secs}s')\n",
    "\n",
    "    # break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plotting the embeddings\n",
    "\n",
    "Is really the related studd are close to each other, and vice versa.\n",
    "\n",
    "The most fun part: Will 'banana' closer to 'fruit' than 'cat'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'cat', 'apple', 'animal', 'fruit', 'banana', '<UNK>']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana = torch.LongTensor([word2index['banana']])\n",
    "banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9475, -0.4210]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana_center_embed = model.embedding_center_word(banana)\n",
    "banana_outside_embed = model.embedding_outside_word(banana)\n",
    "banana_embed = (banana_center_embed+banana_outside_embed)/2\n",
    "banana_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5415963530540466, -0.8694401979446411)\n",
      "(1.169964075088501, -0.2155483216047287)\n",
      "(0.08862864971160889, -0.7112876176834106)\n"
     ]
    }
   ],
   "source": [
    "#find embedding of fruit, cat\n",
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except :\n",
    "        index = word2index['<UNK>'] #unknown\n",
    "    word = torch.LongTensor([index])\n",
    "    \n",
    "    embed =  (model.embedding_center_word(word)+model.embedding_outside_word(word))/2\n",
    "    return embed[0][0].item(),embed[0][1].item()\n",
    "    \n",
    "print(get_embed('fruit'))\n",
    "print(get_embed('cat'))\n",
    "print(get_embed('chaky'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#help me plot fruit cat banana on maplotlib\n",
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]):\n",
    "    x,y = get_embed(word)\n",
    "    plt.scatter(x,y)\n",
    "    plt.annotate(word,xy=(x,y),xytext=(5,2),textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cosine Similarity\n",
    "How do (from Scratch) calcualte cosine similarity?\n",
    "\n",
    "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
    "\n",
    "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
    "\n",
    "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'cat', 'apple', 'animal', 'fruit', 'banana', '<UNK>']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try similarity between first and second, and second and third\n",
    "cat          = get_embed('cat')\n",
    "fruit        = get_embed('fruit')\n",
    "animal       = get_embed('animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat vs. fruit:  0.6737693589475293\n",
      "cat vs. animal:  0.21782850466145842\n",
      "cat vs. cat:  1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "#numpy version\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
    "    return cos_sim\n",
    "    \n",
    "print(f\"cat vs. fruit: \",cos_sim(cat, fruit))\n",
    "print(f\"cat vs. animal: \",cos_sim(cat, animal))\n",
    "print(f\"cat vs. cat: \",cos_sim(cat, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat vs. fruit:  0.6737693589475292\n",
      "cat vs. animal:  0.2178285046614583\n",
      "cat vs. cat:  1\n"
     ]
    }
   ],
   "source": [
    "#scipy version\n",
    "from scipy import spatial\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
    "    return cos_sim\n",
    "\n",
    "print(f\"cat vs. fruit: \",cos_sim(cat, fruit))\n",
    "print(f\"cat vs. animal: \",cos_sim(cat, animal))\n",
    "print(f\"cat vs. cat: \",cos_sim(cat, cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
