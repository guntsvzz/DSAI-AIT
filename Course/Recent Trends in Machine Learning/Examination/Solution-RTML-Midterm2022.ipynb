{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTML Midterm With Solution 2022\n",
    "\n",
    "## Question 1 (20 points)\n",
    "\n",
    "In Labs 04 and 05, you developed your own PyTorch implementations of YOLOv4 and YOLOR.\n",
    "Download the image at http://www.cs.ait.ac.th/~mdailey/ait-orientation.jpg and run it\n",
    "through your YOLOv4 and YOLOR models. Provide your source code to load the model, image,\n",
    "get the result, and display the result here. Display the resulting bounding boxes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run YOLOv4 on one image:\n",
    "\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "from darknet import MyDarknet\n",
    "from util import load_classes, prep_image, non_max_suppression, write_dets\n",
    "\n",
    "num_classes = 80\n",
    "classes = load_classes(\"data/coco.names\")\n",
    "\n",
    "print(\"Loading network.....\")\n",
    "model = MyDarknet('cfg/yolov4.cfg')\n",
    "model.load_weights('yolov4.weights')\n",
    "\n",
    "model.net_info[\"height\"] = 608\n",
    "model.net_info[\"width\"] = 608\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "img = cv2.imread('ait-orientation.jpg')\n",
    "img_tensor = prep_image(img, 608).cuda()\n",
    "img_dim = (img.shape[1], img.shape[0])\n",
    "prep_img_dim = (img_tensor.shape[3], img_tensor.shape[2])\n",
    "predictions = model(img_tensor, True)\n",
    "predictions = non_max_suppression(predictions, conf_thres=0.4, iou_thres=0.5)[0]\n",
    "print(predictions.shape)\n",
    "\n",
    "print(img_dim, prep_img_dim)\n",
    "scaling_factor = max(img_dim) / max(prep_img_dim)\n",
    "print(scaling_factor)\n",
    "pad = ((prep_img_dim[1] - img_dim[1] / scaling_factor) / 2.0)\n",
    "print(pad)\n",
    "predictions[:,1:5] = predictions[:,1:5] - pad\n",
    "predictions[:,1:5] *= scaling_factor\n",
    "\n",
    "colors = pkl.load(open(\"pallete\", \"rb\"))\n",
    "for i in range(predictions.shape[0]):\n",
    "  write_dets(torch.cat((torch.zeros((1)).cuda(), predictions[i,:]), 0), [img], colors, classes)\n",
    "cv2.imwrite('ait-orientation-det.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the following result:\n",
    "\n",
    "<img src=ait-orientation-det.jpg>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for YOLOR needs just a few changes:\n",
    "\n",
    "...\n",
    "\n",
    "model = MyDarknet('cfg/yolor_p6.cfg')\n",
    "model.load_state_dict(torch.load('yolor_p6.pt')['model'])\n",
    "\n",
    "...\n",
    "\n",
    "model.net_info[\"height\"] = 1280\n",
    "model.net_info[\"width\"] = 1280\n",
    "\n",
    "...\n",
    "\n",
    "img_tensor = prep_image(img, 1280).cuda()\n",
    "\n",
    "...\n",
    "\n",
    "cv2.imwrite('ait-orientation-det-yolor.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave the following results:\n",
    "\n",
    "<img src=ait-orientation-det-yolor.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 points)\n",
    "\n",
    "In Labs 02-03, you became familiar with different image classification models and the\n",
    "technique of retraining/fine-tuning a pre-trained model on a new dataset. Let's create\n",
    "a ResNet model for classifying images in the CIFAR100 dataset.\n",
    "   \n",
    "First, create dataset objects for the CIFAR100 training and test sets. You'll find\n",
    "documentation at [the torchvision datasets page](https://pytorch.org/vision/stable/datasets.html).\n",
    "To use the already-downloaded dataset on puffer/gourami/guppy, use the following dataset location:\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR100('/home/fidji/mdailey/Datasets/CIFAR100', train=True)\n",
    "\n",
    "Write some code to get one of the samples from the dataset object. Show your code here, and display\n",
    "the image print its attributes here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to extract a sample from the dataset\n",
    "\n",
    "import torchvision\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR100('/datasets/CIFAR100', train=True)\n",
    "val_dataset = torchvision.datasets.CIFAR100('/datasets/CIFAR100', train=False)\n",
    "\n",
    "(img, img_class) = train_dataset[0]\n",
    "\n",
    "img.save('cifar100-train-0.png')\n",
    "print('Image class:', img_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is the following:\n",
    "\n",
    "<img src=cifar100-train-0.png width=200>\n",
    "\n",
    "and the class for this image is 19 (\"cattle\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (20 points)\n",
    "\n",
    "Next, create data loaders for the training dataset and validation dataset (no need to use the test set).\n",
    "Use a batch size of 4 and appropriate transforms for the training and validation sets.\n",
    "\n",
    "Put your code to create the data loaders, sample one minibatch from the training set, and output the\n",
    "shapes of the tensors comprising the minibatch here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create dataloaders, sample a minibatch, and print out tensor shape here\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.Resize(36),\n",
    "  torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "  torchvision.transforms.RandomCrop(32),\n",
    "  torchvision.transforms.ToTensor(),\n",
    "  torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.Resize(36),\n",
    "  torchvision.transforms.CenterCrop(32),\n",
    "  torchvision.transforms.ToTensor(),\n",
    "  torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR100('/datasets/CIFAR100', train=True, transform=train_transform)\n",
    "val_dataset = torchvision.datasets.CIFAR100('/datasets/CIFAR100', train=False, transform=val_transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "(imgs, labels) = iter(train_dataloader).next()\n",
    "\n",
    "print('Image tensor batch shape:', imgs.shape, 'labels shape:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got output\n",
    "\n",
    "    Image tensor batch shape: torch.Size([4, 3, 32, 32]) labels shape: torch.Size([4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 points)\n",
    "\n",
    "Next, create a ResNet-50 model with pretrained weights from ImageNet using the [torchvision ResNet class](https://pytorch.org/vision/stable/models.html#id10).\n",
    "Remove the classification layer and replace it with a layer appropriate for identification in CIFAR100. Show that your resulting model can process a minibatch\n",
    "from your validation dataloader and output (incorrect) identities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create a ResNet 50 model, remove classification layer, replace with a CIFAR100 identity layer, and run in evaluation model on a validation minibatch\n",
    "\n",
    "model = torchvision.models.resnet50(pretrained=True).eval()\n",
    "model.fc = torch.nn.Linear(2048, 100, bias=True)\n",
    "\n",
    "(val_imgs, val_labels) = iter(val_dataloader).next()\n",
    "\n",
    "output = model(val_imgs)\n",
    "_, pred = torch.max(output, 1)\n",
    "\n",
    "print('First validation minibatch targets', val_labels, 'predictions', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is\n",
    "\n",
    "    First validation minibatch targets tensor([49, 33, 72, 51]) predictions tensor([48, 77, 74, 74])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Next, write a training function, create an optimizer and loss function, and show training loss and validation loss for one epoch.\n",
    "\n",
    "Show the new ouptut identities for the validation minibatch used in Question 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for training and validation for one epoch optimizer, loss function, and new result on validation minibatch\n",
    "\n",
    "def val(model, loader, criterion):\n",
    "  running_loss = 0\n",
    "  running_corrects = 0\n",
    "  running_n = 0\n",
    "  model.eval()\n",
    "  it = 0\n",
    "  for (imgs, labels) in iter(loader):\n",
    "    outputs = model(imgs.to(device))\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    loss = criterion(outputs, labels.to(device))\n",
    "    running_loss += loss.item()\n",
    "    running_n += imgs.shape[0]\n",
    "    corrects = (preds.detach().to('cpu') == labels).sum().item()\n",
    "    running_corrects += corrects\n",
    "    running_n += imgs.shape[0]\n",
    "    if it % 100 == 0:\n",
    "      print('Iter', it, 'loss', running_loss / running_n, 'acc', running_corrects / running_n)\n",
    "    it += 1\n",
    "  return running_loss / running_n, running_corrects / running_n\n",
    "\n",
    "def train(model, loader, criterion, optimizer):\n",
    "  running_loss = 0\n",
    "  running_corrects = 0\n",
    "  running_n = 0\n",
    "  model.train()\n",
    "  it = 0\n",
    "  for (imgs, labels) in iter(loader):\n",
    "    model.zero_grad()\n",
    "    outputs = model(imgs.to(device))\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    loss = criterion(outputs, labels.to(device))\n",
    "    running_loss += loss.item()\n",
    "    running_n += imgs.shape[0]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    corrects = (preds.detach().to('cpu') == labels).sum().item()\n",
    "    running_corrects += corrects\n",
    "    running_n += imgs.shape[0]\n",
    "    if it % 100 == 0:\n",
    "      print('Iter', it, 'loss', running_loss / running_n, 'acc', running_corrects / running_n)\n",
    "    it += 1\n",
    "  return running_loss / running_n, running_corrects / running_n\n",
    "\n",
    "(val_imgs, val_labels) = iter(val_dataloader).next()\n",
    "output = model(val_imgs.to(device))\n",
    "_, pred = torch.max(output, 1)\n",
    "print('Val predictions before:', pred.detach().cpu())\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n",
    "val_loss, val_acc = val(model, val_dataloader, criterion)\n",
    "print('Initial val loss', val_loss, ' val accuracy', val_acc)\n",
    "train_loss, train_acc = train(model, train_dataloader, criterion, optimizer)\n",
    "print('Epoch 0: train loss', train_loss, 'train accuracy', train_acc)\n",
    "val_loss, val_acc = val(model, val_dataloader, criterion)\n",
    "print('Epoch 0: val loss', val_loss, 'val accuracy', val_acc)\n",
    "\n",
    "(val_imgs, val_labels) = iter(val_dataloader).next()\n",
    "output = model(val_imgs.to(device))\n",
    "_, pred = torch.max(output, 1)\n",
    "print('First validation minibatch targets', val_labels, 'predictions after 1 epoch of training', pred.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get the output\n",
    "\n",
    "    Val predictions before: tensor([79, 93, 98, 49])\n",
    "    Epoch 0: val_loss 0.5976760782122612 accuracy 0\n",
    "    Epoch 0: train_loss 0.5824451119947434 accuracy 0.00855\n",
    "    Epoch 1: val_loss 0.8617366856455803 accuracy 0.0102\n",
    "    First validation minibatch targets tensor([49, 33, 72, 51]) predictions after epoch of training tensor([47, 64, 59, 19])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (10 points)\n",
    "\n",
    "Explain how you could use the model you just created as a classifier model in a Control GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Control GAN utilizes three models, a generator, a discriminator, and a classifier. The generator receives noise and a class. The discriminator receives real or generated inputs without the class and has to classify them as real or fake. The classifier receives generated or real samples and has to classify them. If we used the ResNet50 model as the classifier, it would be very strong from the beginning and should give the generator good feedback for learning to generate samples that are correctly classified according to the conditional input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
