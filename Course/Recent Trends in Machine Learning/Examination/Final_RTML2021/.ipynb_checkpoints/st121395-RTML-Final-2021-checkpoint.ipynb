{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTML Final 2021\n",
    "\n",
    "In this exam, we'll have some practical exercises using RNNs and some short answer questions regarding the Transformer/attention\n",
    "and reinforcement learning.\n",
    "\n",
    "Consider the AGNews text classification dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label frequencies: {3: 30000, 4: 30000, 2: 30000, 1: 30000}\n",
      "A few token frequencies: [('to', 106677), ('of', 71936), ('in', 65826), ('and', 62758), ('on', 47538)]\n",
      "Label meanings: 1: World news, 2: Sports news, 3: Business news, 4: Sci/Tech news\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "train_iter = AG_NEWS(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "\n",
    "def clean(line):\n",
    "    line = line.replace('\\\\', ' ')\n",
    "    line = line.replace(',', '')\n",
    "    line = line.replace('.', '')\n",
    "    line = line.replace('-', '')\n",
    "    line = line.replace(':', '')\n",
    "    line = line.replace(';', '')\n",
    "    line = line.replace(\"'\", '')\n",
    "    line = line.replace('(', '')\n",
    "    line = line.replace(')', '')\n",
    "    line = line.replace(' a ', '')\n",
    "    line = line.replace(' an ', '')\n",
    "    line = line.replace(' the ', '')\n",
    "    return line\n",
    "\n",
    "labels = {}\n",
    "for (label, line) in train_iter:\n",
    "    if label in labels:\n",
    "        labels[label] += 1\n",
    "    else:\n",
    "        labels[label] = 1\n",
    "    counter.update(tokenizer(clean(line)))\n",
    "\n",
    "vocab = Vocab(counter, min_freq=1)\n",
    "\n",
    "print('Label frequencies:', labels)\n",
    "print('A few token frequencies:', vocab.freqs.most_common(5))\n",
    "print('Label meanings: 1: World news, 2: Sports news, 3: Business news, 4: Sci/Tech news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can get a sequence of tokens for a sentence with the cleaner, tokenizer, and vocabulary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make pipelines for processing a news story and a label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(clean(x)) if not token in stop_words and token in most_common]\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to create dataloaders for the training and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, length_list = [], [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        length_list.append(processed_text.shape[0])\n",
    "        text_list.append(processed_text)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = pad_sequence(text_list, padding_value=0)\n",
    "    length_list = torch.tensor(length_list, dtype=torch.int64)\n",
    "    return label_list, text_list, length_list\n",
    "\n",
    "train_iter = AG_NEWS(split='train')\n",
    "train_dataset = list(train_iter)\n",
    "test_iter = AG_NEWS(split='test')\n",
    "test_dataset = list(test_iter)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to get a batch from one of these dataloaders. The first entry is a 1D tensor of labels for the batch\n",
    "(8 values between 0 and 3), then a 2D tensor representing the stories with dimension T x B (number of tokens x batch size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels : tensor([0])\n",
      "Text sequence :  torch.Size([15, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "batch = next(enumerate(train_dataloader))\n",
    "labels, seq = batch\n",
    "# print(labels)\n",
    "print(\"Labels :\",seq[0])\n",
    "print(\"Text sequence : \", seq[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToIndex(word):\n",
    "    if word in most_common:\n",
    "        return most_common.index(word) + 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, 1000)\n",
    "    for li, word in enumerate(line):\n",
    "        if word not in most_common:\n",
    "            tensor[li][0][0] = 1\n",
    "        else:\n",
    "            tensor[li][0][wordToIndex(word)] = 1\n",
    "    return tensor\n",
    "\n",
    "def batchtotensor(batch):\n",
    "    seq = batch\n",
    "    labels = seq[0]\n",
    "#     print(seq[1][1])\n",
    "    batch_text = torch.transpose(seq[1][1], 1, 0).to(device).tolist()\n",
    "\n",
    "    len_text = len(batch_text[0])\n",
    "    tensor = torch.zeros(len_text, batch_size, 1000)\n",
    "\n",
    "    for i, text in enumerate(batch_text):\n",
    "        tensor = lineToTensor(text)\n",
    "    return tensor, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converted to the shape we want for our RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1, 1000])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tensor, labels = batchtotensor(batch)\n",
    "print(tensor.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1, 10 points\n",
    "\n",
    "The vocabulary currently is too large for a simple one-hot embedding. Let's reduce the vocabulary size\n",
    "so that we can use one-hot.\n",
    "- First, add a step that removes tokens from a list of \"stop words\" to the `text_pipeline` function.\n",
    "- You probably want to remove punctuation ('.', ',', '-', etc.) and articles (\"a\", \"the\").\n",
    "\n",
    "- Once you've removed stop words, modify the vocabulary to include only the most frequent 1000 tokens (including 0 for an unknown/infrequent word).\n",
    "\n",
    "Write your revised code in the cell below and output the 999 top words with their frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(line):\n",
    "    line = line.replace('\\\\', ' ')\n",
    "    line = line.replace(',', '')\n",
    "    line = line.replace('.', '')\n",
    "    line = line.replace('-', '')\n",
    "    line = line.replace(':', '')\n",
    "    line = line.replace(';', '')\n",
    "    line = line.replace(\"'\", '')\n",
    "    line = line.replace('(', '')\n",
    "    line = line.replace(')', '')\n",
    "    line = line.replace(' a ', '')\n",
    "    line = line.replace(' an ', '')\n",
    "    line = line.replace(' the ', '')\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 106677), ('of', 71936), ('in', 65826), ('and', 62758), ('on', 47538), ('for', 37312), ('#39s', 30833), ('the', 26017), ('that', 24695), ('its', 22724), ('is', 19782), ('as', 19502), ('said', 19393), ('it', 19257), ('with', 18645), ('has', 18360), ('at', 17424), ('reuters', 17229), ('ap', 16141), ('by', 16013), ('new', 15895), ('us', 15888), ('his', 14934), ('will', 14532), ('from', 12630), ('was', 12249), ('their', 10524), ('have', 10501), ('after', 10321), ('be', 10300), ('a', 9525), ('are', 9407), ('more', 8777), ('up', 8623), ('he', 8610), ('two', 8369), ('this', 8152), ('but', 7896), ('over', 7521), ('monday', 7325), ('wednesday', 7285), ('tuesday', 7185), ('oil', 7095), ('thursday', 7085), ('one', 6908), ('friday', 6596), ('not', 6595), ('out', 6470), ('they', 6193), ('inc', 6109), ('york', 6101), ('#39', 6038), ('who', 6008), ('yesterday', 5890), ('were', 5709), ('?', 5699), ('iraq', 5664), ('president', 5635), ('microsoft', 5499), ('last', 5404), ('no', 5366), ('million', 5314), ('than', 5307), ('been', 5133), ('against', 4931), ('first', 4929), ('says', 4853), ('could', 4828), ('prices', 4827), ('about', 4801), ('would', 4774), ('years', 4758), ('had', 4715), ('three', 4679), ('corp', 4628), ('sunday', 4569), ('may', 4543), ('afp', 4518), ('today', 4481), ('people', 4453), ('which', 4433), ('company', 4409), ('percent', 4401), ('security', 4324), ('game', 4319), ('world', 4266), ('quot', 4187), ('week', 4183), ('group', 4132), ('time', 4120), ('year', 4081), ('software', 4007), ('into', 3849), ('saturday', 3842), ('when', 3823), ('back', 3801), ('some', 3740), ('or', 3715), ('sales', 3657), ('minister', 3655), ('night', 3626), ('can', 3529), ('win', 3522), ('china', 3485), ('government', 3371), ('billion', 3287), ('team', 3265), ('business', 3219), ('officials', 3207), ('killed', 3166), ('next', 3133), ('stocks', 3130), ('news', 3108), ('plans', 3081), ('off', 3049), ('profit', 3039), ('washington', 3039), ('victory', 3035), ('bush', 3034), ('2004', 3032), ('states', 3032), ('all', 3031), ('down', 2974), ('state', 2974), ('four', 2902), ('service', 2876), ('market', 2871), ('internet', 2859), ('other', 2857), ('deal', 2847), ('talks', 2824), ('season', 2823), ('cup', 2810), ('chief', 2802), ('open', 2794), ('united', 2770), ('court', 2768), ('former', 2753), ('announced', 2746), ('you', 2708), ('home', 2705), ('record', 2670), ('set', 2638), ('shares', 2618), ('technology', 2614), ('search', 2587), ('league', 2585), ('report', 2582), ('city', 2577), ('#39t', 2573), ('top', 2537), ('international', 2531), ('online', 2516), ('another', 2514), ('&ltb&gt&lt/b&gt', 2514), ('if', 2512), ('computer', 2500), ('just', 2481), ('now', 2467), ('according', 2465), ('day', 2456), ('prime', 2454), ('network', 2423), ('bank', 2398), ('research', 2397), ('google', 2377), ('ibm', 2359), ('least', 2356), ('what', 2355), ('india', 2350), ('police', 2344), ('2', 2334), ('most', 2301), ('space', 2299), ('music', 2293), ('10', 2290), ('leader', 2285), ('coach', 2262), ('lead', 2232), ('games', 2226), ('maker', 2224), ('london', 2201), ('still', 2193), ('japan', 2189), ('south', 2166), ('companies', 2153), ('there', 2148), ('american', 2147), ('five', 2136), ('european', 2136), ('expected', 2135), ('reported', 2133), ('them', 2131), ('growth', 2128), ('british', 2126), ('help', 2120), ('high', 2113), ('her', 2109), ('baghdad', 2104), ('mobile', 2095), ('say', 2093), ('iraqi', 2080), ('services', 2074), ('sports', 2057), ('data', 2040), ('giant', 2032), ('&lta', 2029), ('un', 2026), ('take', 2025), ('earnings', 2021), ('election', 1998), ('red', 1991), ('bid', 1983), ('plan', 1982), ('before', 1979), ('john', 1976), ('co', 1965), ('make', 1960), ('largest', 1946), ('san', 1946), ('wireless', 1944), ('get', 1931), ('web', 1930), ('while', 1926), ('system', 1921), ('trade', 1907), ('quarter', 1897), ('months', 1893), ('national', 1893), ('being', 1893), ('higher', 1892), ('agreed', 1889), ('phone', 1883), ('1', 1879), ('australia', 1872), ('cut', 1871), ('series', 1865), ('industry', 1860), ('union', 1856), ('nuclear', 1853), ('early', 1836), ('north', 1814), ('href=http//wwwinvestorreuterscom/fullquoteaspx', 1813), ('days', 1811), ('him', 1806), ('gold', 1804), ('many', 1803), ('sox', 1802), ('so', 1786), ('players', 1783), ('troops', 1783), ('month', 1779), ('made', 1748), ('weeks', 1744), ('buy', 1739), ('again', 1733), ('military', 1731), ('federal', 1724), ('major', 1722), ('stock', 1720), ('investors', 1715), ('test', 1706), ('executive', 1701), ('dollar', 1700), ('because', 1700), ('users', 1698), ('intel', 1698), ('jobs', 1692), ('apple', 1691), ('rose', 1686), ('england', 1677), ('left', 1677), ('between', 1674), ('windows', 1659), ('loss', 1652), ('ahead', 1652), ('reports', 1652), ('war', 1648), ('end', 1646), ('second', 1646), ('points', 1643), ('since', 1637), ('attack', 1633), ('oracle', 1632), ('official', 1628), ('press', 1626), ('hit', 1624), ('forces', 1622), ('update', 1620), ('russia', 1603), ('iran', 1590), ('your', 1582), ('general', 1581), ('start', 1578), ('even', 1576), ('six', 1575), ('firm', 1562), ('go', 1561), ('big', 1561), ('part', 1560), ('i', 1532), ('football', 1529), ('ago', 1529), ('play', 1526), ('economic', 1525), ('pay', 1521), ('found', 1514), ('palestinian', 1514), ('rise', 1507), ('drug', 1506), ('air', 1502), ('peoplesoft', 1499), ('israeli', 1493), ('nations', 1489), ('should', 1489), ('how', 1472), ('work', 1471), ('europe', 1469), ('pakistan', 1469), ('street', 1465), ('peace', 1462), ('an', 1455), ('final', 1454), ('workers', 1453), ('won', 1453), ('20', 1451), ('global', 1449), ('held', 1448), ('canadian', 1445), ('under', 1440), ('only', 1436), ('released', 1424), ('gaza', 1421), ('much', 1417), ('systems', 1413), ('attacks', 1412), ('foreign', 1408), ('price', 1400), ('leaders', 1397), ('wins', 1392), ('power', 1379), ('fell', 1376), ('title', 1376), ('offer', 1373), ('round', 1366), ('francisco', 1365), ('2005', 1349), ('any', 1342), ('crude', 1341), ('scientists', 1341), ('free', 1338), ('move', 1335), ('athens', 1333), ('through', 1332), ('tokyo', 1331), ('run', 1330), ('russian', 1328), ('championship', 1327), ('america', 1317), ('eu', 1317), ('support', 1316), ('head', 1310), ('pc', 1310), ('car', 1308), ('olympic', 1301), ('video', 1300), ('nearly', 1295), ('israel', 1291), ('do', 1290), ('nasa', 1290), ('also', 1287), ('man', 1283), ('media', 1280), ('way', 1279), ('seven', 1278), ('quote', 1278), ('presidential', 1275), ('financial', 1269), ('like', 1266), ('bomb', 1264), ('charges', 1262), ('strong', 1262), ('agency', 1259), ('11', 1257), ('october', 1257), ('boston', 1251), ('including', 1250), ('wall', 1248), ('biggest', 1247), ('demand', 1246), ('use', 1243), ('linux', 1243), ('west', 1241), ('september', 1239), ('kerry', 1237), ('used', 1237), ('player', 1237), ('version', 1234), ('public', 1231), ('where', 1230), ('contract', 1230), ('close', 1229), ('sun', 1229), ('lower', 1229), ('hurricane', 1228), ('case', 1228), ('commission', 1224), ('darfur', 1222), ('products', 1218), ('economy', 1217), ('per', 1217), ('might', 1211), ('life', 1209), ('beat', 1207), ('several', 1206), ('here', 1206), ('consumer', 1201), ('fall', 1200), ('digital', 1195), ('france', 1191), ('rival', 1190), ('third', 1183), ('return', 1177), ('share', 1169), ('3', 1169), ('house', 1166), ('customers', 1165), ('french', 1163), ('both', 1163), ('trial', 1163), ('despite', 1157), ('korea', 1157), ('militants', 1157), ('called', 1156), ('amp', 1153), ('program', 1149), ('arafat', 1149), ('due', 1146), ('florida', 1140), ('costs', 1135), ('manager', 1133), ('center', 1131), ('away', 1129), ('pm', 1129), ('australian', 1126), ('st', 1125), ('release', 1124), ('put', 1123), ('dead', 1123), ('keep', 1123), ('killing', 1121), ('strike', 1118), ('elections', 1117), ('profile', 1117), ('management', 1116), ('cuts', 1115), ('champion', 1114), ('sony', 1111), ('bill', 1103), ('party', 1097), ('forfirst', 1092), ('uk', 1092), ('results', 1090), ('michael', 1090), ('30', 1086), ('straight', 1085), ('office', 1084), ('site', 1084), ('hostage', 1082), ('vote', 1080), ('energy', 1080), ('army', 1080), ('job', 1077), ('she', 1076), ('late', 1075), ('well', 1069), ('campaign', 1069), ('hopes', 1069), ('near', 1068), ('conference', 1066), ('fans', 1064), ('gets', 1061), ('4', 1061), ('claims', 1060), ('defense', 1059), ('interest', 1054), ('death', 1054), ('november', 1053), ('angeles', 1045), ('likely', 1039), ('12', 1039), ('give', 1038), ('ceo', 1037), ('show', 1036), ('we', 1035), ('quarterly', 1035), ('net', 1034), ('email', 1031), ('chip', 1027), ('own', 1026), ('britain', 1025), ('race', 1025), ('rates', 1021), ('board', 1021), ('face', 1019), ('such', 1016), ('force', 1016), ('right', 1014), ('sell', 1013), ('stores', 1011), ('thirdquarter', 1010), ('long', 1009), ('good', 1009), ('takes', 1008), ('key', 1008), ('canada', 1008), ('baseball', 1002), ('california', 1001), ('chicago', 1000), ('judge', 993), ('15', 993), ('eight', 993), ('political', 989), ('health', 989), ('giants', 989), ('tv', 988), ('too', 987), ('department', 986), ('battle', 984), ('capital', 979), ('sudan', 975), ('meeting', 975), ('chairman', 975), ('during', 972), ('line', 968), ('phones', 967), ('look', 963), ('server', 963), ('violence', 963), ('rebels', 961), ('tax', 960), ('decision', 960), ('mark', 960), ('study', 959), ('japanese', 957), ('launch', 957), ('come', 956), ('unit', 956), ('profits', 955), ('williams', 953), ('trading', 951), ('oct', 950), ('going', 947), ('central', 946), ('hits', 944), ('place', 940), ('revenue', 939), ('control', 939), ('men', 939), ('aid', 938), ('fight', 934), ('germany', 931), ('action', 930), ('soldiers', 930), ('star', 929), ('thousands', 929), ('communications', 926), ('yahoo', 925), ('seen', 924), ('exchange', 924), ('times', 923), ('history', 923), ('information', 921), ('southern', 920), ('without', 920), ('east', 918), ('lost', 916), ('running', 914), ('number', 913), ('region', 913), ('amid', 912), ('future', 911), ('those', 909), ('calls', 909), ('rate', 908), ('half', 908), ('grand', 908), ('yankees', 907), ('operating', 905), ('18', 904), ('increase', 903), ('airlines', 902), ('real', 901), ('match', 900), ('warned', 896), ('august', 893), ('women', 892), ('took', 889), ('meet', 888), ('access', 886), ('tech', 884), ('los', 884), ('recent', 883), ('david', 881), ('ready', 880), ('reserve', 878), ('did', 875), ('texas', 873), ('yet', 873), ('less', 872), ('nov', 872), ('production', 871), ('morning', 870), ('markets', 863), ('source', 859), ('low', 858), ('saying', 857), ('scored', 857), ('agreement', 856), ('must', 856), ('school', 855), ('engine', 849), ('whether', 849), ('soon', 848), ('radio', 848), ('champions', 848), ('secretary', 848), ('chinese', 847), ('14', 847), ('!', 846), ('accused', 846), ('makes', 845), ('told', 845), ('northern', 844), ('13', 842), ('5', 840), ('afghanistan', 840), ('bankruptcy', 839), ('medal', 837), ('paris', 837), ('stadium', 836), ('concerns', 835), ('forecast', 834), ('making', 833), ('cash', 833), ('wants', 833), ('desktop', 830), ('cell', 829), ('latest', 828), ('gains', 827), ('television', 826), ('gas', 824), ('died', 818), ('fuel', 818), ('injured', 818), ('field', 816), ('efforts', 816), ('better', 815), ('blair', 815), ('rally', 813), ('coast', 812), ('stake', 812), ('came', 810), ('boost', 809), ('almost', 809), ('takeover', 809), ('trying', 808), ('members', 808), ('association', 808), ('showed', 806), ('analysts', 806), ('led', 805), ('networks', 805), ('country', 805), ('change', 804), ('hold', 804), ('countries', 804), ('16', 803), ('helped', 802), ('call', 800), ('nine', 800), ('store', 799), ('africa', 799), ('outlook', 798), ('7', 796), ('airways', 794), ('little', 793), ('around', 792), ('begin', 792), ('ipod', 791), ('leading', 790), ('drop', 789), ('computers', 789), ('spain', 789), ('past', 788), ('teams', 784), ('earlier', 783), ('ever', 783), ('station', 782), ('using', 782), ('17', 781), ('council', 781), ('money', 780), ('tour', 778), ('afghan', 778), ('continue', 777), ('probe', 777), ('looking', 776), ('best', 776), ('charged', 773), ('21', 772), ('ltd', 772), ('german', 772), ('division', 771), ('shot', 770), ('arsenal', 770), ('enough', 766), ('corporate', 765), ('spending', 763), ('fund', 763), ('others', 762), ('fire', 762), ('law', 761), ('george', 760), ('indian', 759), ('offering', 758), ('executives', 758), ('see', 758), ('hours', 756), ('administration', 756), ('club', 753), ('yards', 751), ('taking', 749), ('americans', 747), ('terror', 747), ('each', 747), ('began', 747), ('already', 746), ('paul', 746), ('finally', 746), ('authorities', 743), ('rules', 743), ('african', 740), ('human', 740), ('retail', 739), ('25', 739), ('manchester', 739), ('aimed', 736), ('fears', 736), ('consumers', 736), ('beijing', 735), ('old', 734), ('arrested', 734), ('supply', 732), ('investment', 729), ('step', 728), ('flight', 726), ('opposition', 726), ('insurance', 724), ('weapons', 722), ('houston', 722), ('product', 720), ('rights', 720), ('al', 716), ('researchers', 714), ('far', 713), ('yasser', 712), ('competition', 711), ('food', 710), ('devices', 709), ('toronto', 708), ('small', 707), ('legal', 704), ('operations', 703), ('madrid', 703), ('sept', 702), ('sees', 701), ('infirst', 700), ('target', 699), ('stop', 699), ('quarterback', 698), ('sharon', 698), ('offers', 697), ('electronics', 696), ('behind', 696), ('cisco', 696), ('among', 693), ('personal', 692), ('dell', 691), ('bay', 691), ('local', 691), ('performance', 688), ('firms', 688), ('pressure', 688), ('kills', 688), ('retailer', 686), ('once', 684), ('then', 682), ('fighting', 682), ('yukos', 682), ('find', 681), ('problems', 681), ('blue', 680), ('university', 679), ('following', 679), ('rivals', 678), ('soccer', 678), ('ended', 675), ('possible', 675), ('100', 673), ('continued', 673), ('white', 672), ('fraud', 672), ('family', 669), ('drive', 668), ('policy', 668), ('basketball', 668), ('ivan', 668), ('19', 666), ('chips', 666), ('6', 664), ('jones', 664), ('rising', 664), ('senior', 661), ('kill', 661), ('working', 660), ('went', 659), ('children', 659), ('calif', 658), ('designed', 657), ('sale', 655), ('shows', 655), ('focus', 654), ('groups', 654), ('tony', 652), ('push', 651), ('charge', 651), ('moscow', 649), ('injury', 649), ('businesses', 647), ('development', 646), ('try', 646), ('signs', 646), ('list', 645), ('sign', 644), ('starting', 644), ('need', 643), ('park', 643), ('staff', 643), ('weekend', 642), ('never', 642), ('want', 641), ('failed', 641), ('xp', 639), ('hope', 638), ('delta', 637), ('regulators', 635), ('blast', 635), ('bowl', 635), ('expectations', 634), ('winning', 634), ('cp', 634), ('hundreds', 633), ('visit', 632), ('college', 632), ('issues', 630), ('every', 629), ('asian', 628), ('sites', 627), ('black', 626), ('dollars', 626), ('seeks', 625), ('ban', 625), ('suicide', 625), ('available', 624), ('got', 624), ('taken', 624), ('experts', 623), ('until', 623), ('defeat', 623), ('24', 622), ('cost', 621), ('satellite', 621), ('sold', 621), ('further', 620), ('threat', 619), ('davis', 618), ('olympics', 616), ('green', 615), ('side', 615), ('palestinians', 615), ('debt', 615), ('missing', 614), ('ruling', 614), ('coming', 612), ('ofyear', 612), ('singh', 612), ('64', 611), ('hard', 610), ('getting', 610), ('guard', 610), ('employees', 609), ('fourth', 608), ('known', 607), ('officer', 607), ('cricket', 607), ('najaf', 606), ('losses', 606), ('storage', 605), ('miami', 605), ('career', 604), ('raised', 603), ('rebel', 603), ('launches', 602), ('holiday', 601), ('crisis', 601), ('singapore', 600), ('8', 599), ('#151', 597), ('reach', 597), ('louis', 596), ('runs', 596), ('asia', 595), ('closer', 594), ('nba', 592), ('selling', 591), ('lines', 591), ('nokia', 591), ('december', 591), ('turn', 590), ('storm', 590), ('johnson', 590), ('prison', 589), ('walmart', 589), ('looks', 588), ('fallujah', 588), ('labor', 587), ('western', 586), ('goes', 586), ('congress', 586), ('rises', 585), ('suspected', 585), ('captain', 585), ('mission', 584), ('technologies', 584), ('warning', 583), ('applications', 583), ('airline', 583), ('strip', 580), ('boeing', 579), ('hostages', 579), ('does', 578), ('9', 578), ('above', 576), ('short', 575), ('within', 575), ('terrorism', 572), ('winter', 572), ('water', 571), ('amd', 570), ('mike', 570), ('track', 570), ('decided', 570), ('putin', 569), ('warns', 568), ('worth', 567), ('faces', 566), ('named', 566), ('woods', 566), ('italy', 566), ('growing', 565), ('medical', 565), ('ireland', 565), ('drugs', 564), ('italian', 564), ('vs', 562), ('gave', 561), ('point', 560), ('heart', 560), ('goal', 560), ('bonds', 559), ('equipment', 558), ('private', 557), ('merger', 557), ('our', 556), ('finance', 556), ('muslim', 556), ('debate', 556), ('sets', 555), ('disney', 555), ('steve', 554), ('insurgents', 553), ('challenge', 552), ('launched', 552), ('later', 551), ('sources', 551), ('based', 550), ('order', 549), ('survey', 548)]\n"
     ]
    }
   ],
   "source": [
    "print((vocab.freqs.most_common(999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = []\n",
    "for i in vocab.freqs.most_common(1000):\n",
    "    most_common.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(clean(x)) if not token in stop_words and token in most_common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[299, 46, 924]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab[token] for token in tokenizer(clean('Bangkok, or The Big Mango, is one of the great cities of Asia')) if not token in stop_words and token in most_common]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2, 30 points\n",
    "\n",
    "Next, let's build a simple RNN for classification of the AGNews dataset. Use a one-hot embedding of the vocabulary\n",
    "entries and the basic RNN from Lab 10. Use the lengths tensor (the third element in the batch returned by the dataloaders)\n",
    "to determine which output to apply the loss to.\n",
    "\n",
    "Place your training code below, and plot the training and test accuracy as a\n",
    "function of epoch. Finally, output a confusion matrix for the test set.\n",
    "\n",
    "*Do not spend a lot of time on the training! A few minutes is enough. The point is to show that the model is\n",
    "learning, not to get the best possible performance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToIndex(word):\n",
    "    if word in most_common:\n",
    "        return most_common.index(word) + 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, 1000)\n",
    "    for li, word in enumerate(line):\n",
    "        if word not in most_common:\n",
    "            tensor[li][0][0] = 1\n",
    "        else:\n",
    "            tensor[li][0][wordToIndex(word)] = 1\n",
    "    return tensor\n",
    "\n",
    "def batchtotensor(batch):\n",
    "    seq = batch\n",
    "    labels = seq[0]\n",
    "#     print(seq[1][1])\n",
    "    batch_text = torch.transpose(seq[1][1], 1, 0).to(device).tolist()\n",
    "\n",
    "    len_text = len(batch_text[0])\n",
    "    tensor = torch.zeros(len_text, batch_size, 1000)\n",
    "\n",
    "    for i, text in enumerate(batch_text):\n",
    "        tensor = lineToTensor(text)\n",
    "    return tensor, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size): # (n_letters, n_hidden, n_categories)\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # A bit more efficient than normal Softmax\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        \n",
    "        a = self.i2h(combined)\n",
    "        hidden = torch.tanh(a) # added tanh to the hidden state\n",
    "        \n",
    "        o = self.h2o(hidden)\n",
    " # added softmax to the output\n",
    "        # hidden = self.i2h(combined)\n",
    "        # output = self.i2o(combined)\n",
    "        # output = self.softmax(output)\n",
    "        return o, hidden\n",
    "\n",
    "    def initHidden(self, batch_size = 1):\n",
    "        return torch.zeros(batch_size, self.hidden_size) # BATCH SIZE!!!\n",
    "    \n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden(line_tensor.shape[1]).to(device)\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 128\n",
    "\n",
    "rnn = RNN(1000, n_hidden, 4)\n",
    "rnn = rnn.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.005 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "num_epoch = 10\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "start = time.time()\n",
    "rnn = rnn.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "\n",
    "learning_rate = 0.005 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test loss : tensor(0.1019, device='cuda:0')\n",
      "Train loss : tensor(-0.0424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test loss : tensor(0.1019, device='cuda:0')\n",
      "Train loss : tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test loss : tensor(0.1019, device='cuda:0')\n",
      "Train loss : tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Test loss : tensor(0.1019, device='cuda:0')\n",
      "Train loss : "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2aacf2225228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train loss :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    356\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss= []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for batch in enumerate(train_dataloader):\n",
    "        tensor, labels = batchtotensor(batch)\n",
    "        tensor = tensor.to(device)\n",
    "        labels = torch.Tensor([labels]).to(device).long()\n",
    "        \n",
    "        hidden = rnn.initHidden(tensor.shape[1]).to(device)\n",
    "        rnn.zero_grad()\n",
    "        for i in range(tensor.size()[0]):\n",
    "            output, hidden = rnn(tensor[i], hidden)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        print(\"Train loss :\", loss)\n",
    "        train_loss.append(loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in enumerate(test_dataloader):\n",
    "                tensor, labels = batchtotensor(batch)\n",
    "                tensor = tensor.to(device)\n",
    "                labels = torch.Tensor([labels]).to(device).long()\n",
    "\n",
    "                hidden = rnn.initHidden(tensor.shape[1]).to(device)\n",
    "                rnn.zero_grad()\n",
    "                for i in range(tensor.size()[0]):\n",
    "                    output, hidden = rnn(tensor[i], hidden)\n",
    "\n",
    "                loss = criterion(output, labels)\n",
    "                print(\"Test loss :\", loss)\n",
    "                test_loss.append(loss)\n",
    "                break # test only 1 batch for quick training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-204b9d12c9e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'randomTrainingExample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e1bc930132b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Go through a bunch of examples and record which are correctly guessed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_confusion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomTrainingExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mguess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguess_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategoryFromOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'randomTrainingExample' is not defined"
     ]
    }
   ],
   "source": [
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(4, 4)\n",
    "n_confusion = 10000\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden().to('cuda:1')\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output = evaluate(line_tensor.to('cuda:1'))\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = all_categories.index(category)\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3, 10 points\n",
    "\n",
    "Next, replace the SRNN from Question 2 with a single-layer LSTM. Give the same output (training and testing accuracy as a function of epoch, as well as confusion\n",
    "matrix for the test set). Comment on the differences you observe between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTMCell(1, 16)\n",
    "        self.linear = nn.Linear(16,4)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        h_t = torch.zeros(input_.size(0), 51, dtype=torch.double)\n",
    "        c_t = torch.zeros(input_.size(0), 51, dtype=torch.double)\n",
    "        h_t, c_t = self.lstm1(input_, (h_t, c_t))\n",
    "        output = self.softmax(self.linear(h_t))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model = LSTM()\n",
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005 \n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist_loss = []\n",
    "val_hist_loss = []\n",
    "for i in range(EPOCH):\n",
    "    print('EPOCH: ', i)\n",
    "    for (_, seq) in enumerate(train_dataloader):\n",
    "        labels = seq[0].to(device)\n",
    "        seq = torch.transpose(seq[1], 1, 0).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(seq)\n",
    "        loss = criterion(out, labels)\n",
    "        print('Train loss:', loss.item())\n",
    "        train_hist_loss.append(loss)\n",
    "        loss.backward()\n",
    "\n",
    "#     optimizer.step()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         pred = seq(test_input)\n",
    "#         loss = criterion(pred, test_target)\n",
    "#         print('Test loss:', loss.item())\n",
    "#         y = pred.detach().numpy()\n",
    "#         val_hist_loss.append(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(4, 4)\n",
    "n_confusion = 10000\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(line_tensor):\n",
    "    hidden = rnn.initHidden().to('cuda:1')\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output = evaluate(line_tensor.to('cuda:1'))\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = all_categories.index(category)\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4, 10 points\n",
    "\n",
    "Explain how you could use the Transformer model to perform the same task you explored in Questions 2 and 3.\n",
    "How would attention be useful for this text classification task? Give a precise and detailed answer. Be sure to discuss what\n",
    "parts of the original Transformer you would use and what you would have to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In transformer, with the attention mechanism there are global dependencies between the input and output, This means that it is possible for one word to be connected to every words equally (with the set of key and values of compatibility or connnectivity between every word), without worrying about the long term dependency ot sequential computation problem, so it would be very beneficial for the this text classification task because the model can consider the whole sentence all together then clasify it. As this is just a classification task not a translating task I think we can remove the positional encoding part from the original Transformer as we no longer need the information about the positions of the words but we only need the content. Our output will only be the class of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5, 10 points\n",
    "\n",
    "In Lab 13, you implemented a DQN model for tic-tac-toe. You method learned to play against a fairly dumb `expert_action` opponent, however.  Also,\n",
    "DQN has proven to be less stable than other methods such as Double DQN, also discussed in Lab 13.\n",
    "\n",
    "Explain below how you would apply double DQN and self-play to improve your tic-tac-toe agent.\n",
    "Provide pseudocode for the algorithm below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('ddqn.png')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Double DQN, we have 2 DQN models the current model and the target model and we have two different action-value functions, Q and Q.\n",
    "We update the parameters of target network based on the parameters of ther current network per several iterations.\n",
    "First we use the current network to make an action then we calculate the loss between the Q value of the curretn network and the target network. This way train 1 model but move it forward one step in time so the model at the previous time step can learn from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6, 30 points\n",
    "\n",
    "Based on your existing DQN implementation, implement the double DQN and self-play training method\n",
    "you just described. After some training (don't spend too much time on training -- again, we just want to see that the model can\n",
    "learn), show the result you playing a game against your learned agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from collections import deque\n",
    "from tqdm import trange\n",
    "\n",
    "# Select GPU or CPU as device\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(episode, rewards, losses):\n",
    "    # clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('episode %s. reward: %s' % (episode, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)   \n",
    "    plt.show() \n",
    "\n",
    "\n",
    "def gen_eps_by_episode(epsilon_start, epsilon_final, epsilon_decay):\n",
    "    eps_by_episode = lambda episode: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * episode / epsilon_decay)\n",
    "    return eps_by_episode\n",
    "\n",
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 500\n",
    "eps_by_episode = gen_eps_by_episode(epsilon_start, epsilon_final, epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        # Add batch index dimension to state representations\n",
    "        state = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_state, n_action):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=n_state, out_features=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=10, out_features=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=10, out_features=n_action))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        # Get an epsilon greedy action for given state\n",
    "        if random.random() > epsilon: # Use argmax_a Q(s,a)\n",
    "            state = autograd.Variable(torch.Tensor(state).unsqueeze(0)).to(device)\n",
    "#             print(state.shape)\n",
    "            q_value = self.forward(state)\n",
    "            q_value = q_value.cpu()\n",
    "#             print(q_value.shape)\n",
    "            action = q_value.max(1)[1].item()            \n",
    "        else: # get random action\n",
    "#             action = random.randrange(env.action_space.n)\n",
    "            action = random.randrange(9)\n",
    "        return action\n",
    "    \n",
    "    def get_q_value(self, state):\n",
    "        state = autograd.Variable(torch.Tensor(state).unsqueeze(0)).to(device)\n",
    "#             print(state.shape)\n",
    "        q_value = self.forward(state)\n",
    "        q_value = q_value.cpu()\n",
    "#             print(q_value.shape)\n",
    "        action = q_value.max(1)[1].item() \n",
    "        \n",
    "        return q_value, action\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_td_loss_DoubleDQN(current_model, target_model, batch_size, gamma=0.99):     # from input only a model, you must input 2 models: current_model, and target_model\n",
    "    # get data from replay mode\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    # convert to tensors\n",
    "    # Autograd automatically supports Tensors with requires_grad set to True.\n",
    "    state      = autograd.Variable(torch.FloatTensor(np.float32(state))).to(device)\n",
    "    next_state = autograd.Variable(torch.FloatTensor(np.float32(next_state)), volatile=True).to(device)\n",
    "    action     = autograd.Variable(torch.LongTensor(action)).to(device)\n",
    "    reward     = autograd.Variable(torch.FloatTensor(reward)).to(device)\n",
    "    done       = autograd.Variable(torch.FloatTensor(done)).to(device)\n",
    "\n",
    "    # calculate q-values and next q-values from deeplearning\n",
    "    q_values      = current_model(state)\n",
    "    next_q_values = current_model(next_state)\n",
    "    # double DQN add here\n",
    "    next_q_state_values = target_model(next_state)\n",
    "    ############################################################\n",
    "\n",
    "    # get q-value from propagated action in each step\n",
    "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    # double DQN different here\n",
    "    next_q_value     = next_q_state_values.gather(1, torch.max(next_q_values, 1)[1].unsqueeze(1)).squeeze(1)\n",
    "    ############################################################################\n",
    "    # calculate expected q-value from q-function\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "    \n",
    "    # calculate loss value\n",
    "    loss = (q_value - autograd.Variable(expected_q_value.data)).pow(2).mean()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DoubleDQN(env, current_model, target_model, eps_by_episode, optimizer, replay_buffer, episodes = 10000, batch_size=32, gamma = 0.99):\n",
    "    losses = []\n",
    "    all_rewards = []\n",
    "    episode_reward = 0\n",
    "\n",
    "    obs = env.reset()\n",
    "    state = env.reset()\n",
    "    state = state.reshape(27)\n",
    "    tot_reward = 0\n",
    "    \n",
    "    tr = trange(episodes+1, desc='Agent training', leave=True)\n",
    "    for episode in tr:\n",
    "        tr.set_description(\"Agent training (episode{}) Avg Reward {}\".format(episode+1,tot_reward/(episode+1)))\n",
    "        tr.refresh() \n",
    "\n",
    "        # get action with q-values\n",
    "        epsilon = eps_by_episode(episode)\n",
    "        action = current_model.act(state, epsilon)\n",
    "        \n",
    "        # input action into state\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state = next_state.reshape(27)\n",
    "        \n",
    "        # save data into buffer\n",
    "        replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "        tot_reward += reward\n",
    "        \n",
    "        state = next_state\n",
    "        obs = next_obs\n",
    "        episode_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            state = get_state2(obs)\n",
    "            all_rewards.append(episode_reward)\n",
    "            episode_reward = 0\n",
    "            \n",
    "        if len(replay_buffer) > batch_size:\n",
    "            loss = compute_td_loss_DoubleDQN(current_model, target_model, batch_size, gamma)    #######\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        if episode % 500 == 0: # update target_model weight. The '500' is hyperparameter, you can change it as you want\n",
    "            update_target(current_model, target_model)\n",
    "            \n",
    "    plot(episode, all_rewards, losses)  \n",
    "    return current_model, target_model, all_rewards, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from collections import deque\n",
    "from tqdm import trange\n",
    "from games.abstract_game import AbstractGame\n",
    "\n",
    "game_name = 'tictactoe'\n",
    "game_module = importlib.import_module(\"games.\" + game_name) \n",
    "\n",
    "env = game_module.Game()\n",
    "\n",
    "model = DQN(27, 9).to(device)\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "replay_buffer = ReplayBuffer(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
