{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n",
      "available GPU(s): 4\n",
      "0: {'name': 'NVIDIA GeForce RTX 2080 Ti', 'capability': [7, 5], 'total_momory': 10.76, 'sm_count': 68}\n",
      "1: {'name': 'NVIDIA GeForce RTX 2080 Ti', 'capability': [7, 5], 'total_momory': 10.76, 'sm_count': 68}\n",
      "2: {'name': 'NVIDIA GeForce RTX 2080 Ti', 'capability': [7, 5], 'total_momory': 10.76, 'sm_count': 68}\n",
      "3: {'name': 'NVIDIA GeForce RTX 2080 Ti', 'capability': [7, 5], 'total_momory': 10.76, 'sm_count': 68}\n",
      "\n",
      "device: cuda\n",
      "loading annotations into memory...\n",
      "Done (t=0.94s)\n",
      "creating index...\n",
      "index created!\n",
      "Namespace(ckpt_path='/root/lab05/Simple-MaskRCNN/maskrcnn_coco-10.pth', data_dir='/root/Datasets/coco', dataset='coco', iters=3, results='/root/lab05/Simple-MaskRCNN/maskrcnn_results.pth', use_cuda=True)\n",
      "\n",
      "evaluating...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 150.3, total: 131.7, model: 105.2\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      "accumulate: 0.2s\n",
      "{'bbox AP': 24.9, 'mask AP': 21.0}\n",
      "\n",
      "Total time of this evaluation: 4.5 s, speed: 6.7 imgs/s\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import pytorch_mask_rcnn as pmr\n",
    "    \n",
    "    \n",
    "def main(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.use_cuda else \"cpu\")\n",
    "    cuda = device.type == \"cuda\"\n",
    "    if cuda: pmr.get_gpu_prop(show=True)\n",
    "    print(\"\\ndevice: {}\".format(device))\n",
    "    \n",
    "    d_test = pmr.datasets(args.dataset, args.data_dir, \"val2017\", train=True) # VOC 2012. set train=True for eval\n",
    "    #d_test = pmr.datasets(args.dataset, args.data_dir, \"val2017\", train=True) # COCO 2017\n",
    "\n",
    "    print(args)\n",
    "    num_classes = max(d_test.classes) + 1\n",
    "    model = pmr.maskrcnn_resnet50(False, num_classes).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(args.ckpt_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    #print(checkpoint[\"eval_info\"])\n",
    "    del checkpoint\n",
    "    if cuda: torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\nevaluating...\\n\")\n",
    "    \n",
    "    B = time.time()\n",
    "    eval_output, iter_eval = pmr.evaluate(model, d_test, device, args)\n",
    "    B = time.time() - B\n",
    "    \n",
    "    print(eval_output.get_AP())\n",
    "    if iter_eval is not None:\n",
    "        print(\"\\nTotal time of this evaluation: {:.1f} s, speed: {:.1f} imgs/s\".format(B, 1 / iter_eval))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--dataset\", default=\"coco\")\n",
    "    parser.add_argument(\"--data-dir\", default=\"/root/Datasets/coco\")\n",
    "    parser.add_argument(\"--ckpt-path\", default=\"/root/lab05/Simple-MaskRCNN/maskrcnn_coco-10.pth\")\n",
    "    parser.add_argument(\"--iters\", type=int, default=3) # number of iterations, minus means the entire dataset\n",
    "    args = parser.parse_args([]) # [] is needed if you're using Jupyter Notebook.\n",
    "    \n",
    "    args.use_cuda = True\n",
    "    args.results = os.path.join(os.path.dirname(args.ckpt_path), \"maskrcnn_results.pth\")\n",
    "    \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
