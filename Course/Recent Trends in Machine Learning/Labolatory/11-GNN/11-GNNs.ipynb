{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTML Lab 11: GNNs\n",
    "\n",
    "Today we explore GNNs, in particular [Graph Convolutional Networks by Kipf and Welling (2017)](https://arxiv.org/abs/1609.02907).\n",
    "\n",
    "In this lab, we will develop Graph Neural Networks (GNN).\n",
    "\n",
    "Some references:\n",
    "- [PyTorch Geometric tutorial for GCN](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html)\n",
    "- [Graph Neural Networks: A review of methods and applications](arxiv.org/ftp/arxiv/papers/1812/1812.08434.pdf)\n",
    "- [A Gentle Introduction to Graph Neural Networks (Basics, DeepWalk, and GraphSage)](https://towardsdatascience.com/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3)\n",
    "- [Hands-on Graph Neural Networks with PyTorch & PyTorch Geometric](towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8)\n",
    "- [Graph Neural Network (GNN): What It Is and How to Use It](https://builtin.com/data-science/gnn)\n",
    "- [An Introduction to Graph Neural Network(GNN) For Analysing Structured Data](https://towardsdatascience.com/an-introduction-to-graph-neural-network-gnn-for-analysing-structured-data-afce79f4cfdc)\n",
    "\n",
    "## What are GNNs?\n",
    "\n",
    "Graph neural networks (GNNs) were first introduced in 2009,\n",
    "[cite](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1015.7227&rep=rep1&type=pdf).\n",
    "A GNN is a neural model that can be applied directly to graphs without prior knowledge of each component.\n",
    "GNN provides a convenient method for performing node-, edge-, and graph-level prediction tasks.\n",
    "\n",
    "GNNs have recently received a lot of attention because of their\n",
    "ability to analyze graph structured data such as a set of objects and their relationships.\n",
    "\n",
    "In order to incorporate graph-structured information, in a data processing step,\n",
    "the underlying graph structure is encoded using the topological relationships between the nodes of the graph.\n",
    "Graph models include recursive neural networks and Markov chains, which are commonly used to solve graph and node-focused problems.\n",
    "\n",
    "## Graphs\n",
    "\n",
    "A graph $G=(V,E)$ is a data structure made up of two parts: a set of *vertices* ($V$) and a set of *edges* ($E$).\n",
    "A graph is a mathematical structure that is used to examine the pair-wise relationship between objects and entities.\n",
    "Edges can be either *directed* or *undirected*, depending on whether there exist directional dependencies between the vertices.\n",
    "Here's an example graph:\n",
    "\n",
    "<img src=\"img/GNNSimpleGraph.webp\" title=\"A simple Graph\" style=\"width: 150px;\" />\n",
    "\n",
    "Besides the set notation mentioned above,\n",
    "a graph is often represented by an adjacency matrix $A$.\n",
    "If a graph has $N$ nodes, then $A \\in \\mathbb{R}^{N\\times N}$.\n",
    "Mathematically, the graph's adjacency matrix has a value of 1 at element $(i,j)$ only when there is an edge\n",
    "from node $i$ to node $j$;\n",
    "otherwise the value should be zero. Here's an example for the a directed graph in which the edges have directionality:\n",
    "\n",
    "<img src=\"img/AdjacencyMatrix.PNG\" title=\"Adjacency matrix\" style=\"width: 600px;\" />\n",
    "\n",
    "Another matrix, the *feature matrix* $X$ is sometimes provided to describe the nodes in the graph.\n",
    "If each node has $C$ features, then $X \\in \\mathbff{R}^{N \\times C}$.\n",
    "\n",
    "<img src=\"img/FeatureMatrix.PNG\" title=\"Feature matrix\" style=\"width: 600px;\" />\n",
    "\n",
    "Interestingly, we can perform the multiplication $H = AX$. Each row $i$ of the result matrix $H$\n",
    "is the summation of the features of all nodes $j$ connected to node $i$.\n",
    "\n",
    "<img src=\"img/multiMatrix.PNG\" title=\"Summation matrix\" style=\"width: 600px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs represent non-Euclidean data\n",
    "\n",
    "A graph cannot be represented in a Euclidean coordinate system.\n",
    "This makes graph data more difficult to interpret than other types of data such as waves, images, and time-series signals.\n",
    "These types of data can all be represented in a 2D or 3D space.\n",
    "Another issue is that different looking graphs can have the same\n",
    "intrinsic structure. For example the following two graphs have the same adjacency matrix:\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"img/GraphA.webp\" title=\"A\" style=\"width: 150px;\" /> </td>\n",
    "<td> <img src=\"img/GraphB.webp\" title=\"B\" style=\"width: 150px;\" /> </td>\n",
    "</tr></table>\n",
    "\n",
    "We could also renumber the nodes. That would change the adjacency matrix but the graph would actually intrinsically be the same.\n",
    "Finally, large graphs are not easy to visualize. How about this one?\n",
    "\n",
    "<img src=\"img/circuitnetlist.webp\" title=\"B\" style=\"width: 300px;\" />\n",
    "\n",
    "## Graphs are natural representations of some kinds of data\n",
    "\n",
    "Despire these difficulties, graphs are ideal natural representations of relationships and interactions between entities, such\n",
    "as relationships between people in a social context (social network analysis or SNA).\n",
    "\n",
    "## Traditional graph analysis algorithms\n",
    "\n",
    "Computer scientists have studied graphs for a long time. There are existing graph algorithms for\n",
    "1. Search (depth first search and breadth first search)\n",
    "2. Shortest path finding (Dijkstra’s algorithm)\n",
    "3. Spanning-tree finding (Prim’s algorithm)\n",
    "4. Clustering (k-Means, etc.)\n",
    "\n",
    "However, here, we are interested in performing machine learning over graph structures. These are\n",
    "relatively new algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic graph neural networks\n",
    "\n",
    "A GNN is a type of neural network that operates directly on\n",
    "graph structures. Node classification is one common application of GNNs.\n",
    "In a node classification problem, each node has a label, and we want to predict\n",
    "the label of each node without using the ground truth.\n",
    "\n",
    "RNNs and CNNs can be thought of as GNNs.\n",
    "There are several other GNNs attracing attention today:\n",
    "1. Graph convolutional networks (GCNs)\n",
    "2. Graph attention networks (GATs)\n",
    "\n",
    "Here we'll give the idea of the simplest form of GNN using message passing.\n",
    "\n",
    "### GNN message passing\n",
    "\n",
    "Each node $i$ in a node classification problem is\n",
    "identified by feature vector $x_i$ and associated with a ground truth label\n",
    "$y_i$. The goal is to use the labeled nodes in a partially labeled graph $G$ to predict the labels of the unlabeled nodes.\n",
    "We may have multiple layers of processing in which we transform\n",
    "$x_i$ to a hidden representation $h_i$ containing\n",
    "information about node $i$'s neighbors. That is,\n",
    "\n",
    "$$h_i=f(x_i,x_{co[i]},h_{ne[i]},x_{ne[i]}),$$\n",
    "\n",
    "where $x_{co[i]}$ refers to the features of the edges connecting with node $i$, $h_{ne[i]}$ refers to the hidden representations\n",
    "of node $i$'s neighboring nodes, and $x_{ne[i]}$ refers to the features of node\n",
    "$i$'s neighboring nodes.\n",
    "\n",
    "It turns out that if $f()$ is simple enough,\n",
    "we can use the Banach fixed point theorem to rewrite the above equation as an iteratively updated process that\n",
    "gives a unique solution for the $h_i$. This iterative operation is also known as *message passing* or *neighborhood aggregation*.\n",
    "Concatenating the $x_i$ and $h_i$ we can write $f$ as\n",
    "an operation $F$ over matrices:\n",
    "$$H^{t+1}=F(H^t,X).$$\n",
    "\n",
    "### Output\n",
    "\n",
    "The output of the GNN depends on the hidden representations $h_i$ as well\n",
    "as (considering a \"skip\" connection) the feature vectors $x_i$.\n",
    "This can be implemented by a function $g$:\n",
    "\n",
    "$$o_i=g(h_i,x_i)$$\n",
    "\n",
    "Both $f$ and $g$ can be implemented by feed-forward fully-connected neural networks. \n",
    "\n",
    "### Loss function\n",
    "\n",
    "Depending on the type of inference being performed, we may use L1, L2, or cross entropy loss at the output.\n",
    "Any of these loss functions can be optimized using gradient descent.\n",
    "\n",
    "### Improvements to the basic GNN\n",
    "\n",
    "There are many variations on the basic GNN idea. Among the most successful approaches, Kipf and Welling's (2017) GCN\n",
    "uses a first-order approximation to message passing using a simplified form of graph spectral convolutions that are\n",
    "stacked into multiple layers in order to accomplish the transformation of\n",
    "the input features to obtain hidden layer representations that incororate information from neighboring nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepWalk\n",
    "\n",
    "Reference: http://www.perozzi.net/publications/14_kdd_deepwalk.pdf\n",
    "\n",
    "DeepWalk was\n",
    "the first algorithm to perform unsupervised node embedding learning.\n",
    "It is trained similarly to a word embedding model.\n",
    "The motivation is that the distribution of nodes in a graph under a random walk of the nodes and\n",
    "words in a corpus both follow a power law, as illustrated by the figure in the paper:\n",
    "\n",
    "<img src=\"img/deepwalk.webp\" title=\"http://www.perozzi.net/publications/14_kdd_deepwalk.pdf\" style=\"width: 800px;\" />\n",
    "\n",
    "The algorithm involves two steps:\n",
    "\n",
    "1. Perform random walks on nodes in the graph to generate node sequences\n",
    "2. Run a skip-gram algorithm to learn an embedding of each node based on the node sequences generated in step 1\n",
    "\n",
    "At each time step of the random walk, the next node is sampled uniformly from the neighbors of the previous node. Each sequence is then truncated into\n",
    "sub-sequences of length $2|w| + 1$, where $w$ denotes the window size in the skip-gram method.\n",
    "\n",
    "The skip-gram method is explained well in [this article from Towards Data Science](https://towardsdatascience.com/word-embedding-with-word2vec-and-fasttext-a209c1d3e12c).\n",
    "\n",
    "A hierarchical softmax is performed to reduce the cost of the softmax over the large number of nodes.\n",
    "In an ordinary softmax, we must compute $e^{x_k}$ for every index $k$:\n",
    "\n",
    "$$softmax(x)_i = \\frac{e^{x_i}}{\\sum_{k=1}^K e^{x_k}}$$\n",
    "\n",
    "The computation time is $O(|V|)$. Hierarchical softmax imposes a binary tree over the vertices.\n",
    "Each inner node contains a binary classifier that determines which path to take. To compute the probability of a given vertex $v_k$, we simply add\n",
    "the probabilities of each sub-path from the root node to the leaf $v_k$. Because the probability of each node's children sums to one,\n",
    "the property that the sum of the probability of all vertices equals one remains valid in the hierarchical softmax.\n",
    "As the longest path for an element, the computation time is now reduced to $O(\\log|V|)$.\n",
    "\n",
    "<img src=\"img/HierarchicalSoftmax.webp\" title=\"http://www.perozzi.net/publications/14_kdd_deepwalk.pdf\" style=\"width: 500px;\" />\n",
    "\n",
    "After training a DeepWalk GNN, the model has learned a good representation of each node, as shown in the figure below. In the input graph, different colors represent different labels. We can see in the output graph (embedding with two dimensions) that nodes with the same labels are clustered together, whereas most nodes with different labels are properly separated.\n",
    "\n",
    "<img src=\"img/Deepwalkresult.webp\" title=\"http://www.perozzi.net/publications/14_kdd_deepwalk.pdf\" style=\"width: 500px;\" />\n",
    "\n",
    "The main problem with DeepWalk is that it lacks generalization ability. When a new node is added, the model must be re-trained to represent this node (transductive). As a result, such GNN is unsuitable for dynamic graphs with constantly changing nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSage\n",
    "\n",
    "Reference: https://www-cs-faculty.stanford.edu/people/jure/pubs/graphsage-nips17.pdf\n",
    "\n",
    "GraphSage allows induction by inductively learning an embedding for each node.\n",
    "In particular, each node is represented by the sum of its neighbors' features.\n",
    "As a result, even if a previously unseen node appears in the graph during training,\n",
    "it can still be properly represented by its neighbors.\n",
    "\n",
    "<img src=\"img/GraphSageAlgo.webp\" title=\"http://www.perozzi.net/publications/14_kdd_deepwalk.pdf\" style=\"width: 500px;\" />\n",
    "\n",
    "The number of update iterations is indicated by the outer loop, and $h^k_v$ is the latent vector of node $v$ at update iteration $k$. $h^k_v$ is updated at each update iteration using an aggregation function, the latent vectors of $v$ and $v$'s neighborhood from the previous iteration, and a weight matrix $W^k$. There are three aggregation functions as:\n",
    "\n",
    "1. **Mean aggregator**: takes the average of the latent vectors of a node and all its neighborhood.\n",
    "\n",
    "$$h_v^k\\leftarrow \\sigma(W\\cdot \\text{MEAN}(\\{h_v^{k-1}\\}\\cup \\{h_u^{k-1},\\forall u \\in \\mathcal{N}(v)\\}))$$\n",
    "\n",
    "Compared with the original equation, it removes the concatenation operation at line 5 in the above pseudo code. This operation can be viewed as a “skip-connection”, which later in the paper proved to largely improve the performance of the model.\n",
    "\n",
    "2. **LSTM aggregator**: Since the nodes in the graph don’t have any order, they assign the order randomly by permuting these nodes.\n",
    "\n",
    "3. **Pooling aggregator**: This operator performs an element-wise pooling function on the neighboring set. Below shows an example of max-pooling:\n",
    "\n",
    "$$\\text{AGGREGATE}_k^{pool}= \\max(\\{\\sigma(W_{pool}h_{u_i}^k+b),\\forall u_i \\in \\mathcal{N}(v)\\})$$\n",
    "\n",
    "which can be substituted for mean-pooling or any other symmetric pooling function. It is stated that the pooling aggregator performs the best, while the mean-pooling and max-pooling aggregators perform similarly. The paper's default aggregation function is max-pooling.\n",
    "\n",
    "### Loss function\n",
    "\n",
    "The loss function is defined as the following:\n",
    "\n",
    "$$J_{\\mathcal{G}}(z_u)=-\\log(\\sigma(z_u^\\top))-Q\\cdot \\mathbb{E}_{v_n\\sim P_n(v)}\\log(\\sigma(-z_u^\\top z_{v_n}))$$\n",
    "\n",
    "where $u$ and $v$ co-occur in a fixed-length random walk, while $v_n$ are the negative samples that don’t co-occur with $u$. Such loss function encourages nodes closer to have similar embedding, while those far apart to be separated in the projected space. Via this approach, the nodes will gain more and more information about their neighborhoods.\n",
    "\n",
    "By aggregating its nearby nodes, GraphSage generates representable embedding for unseen nodes. It enables the application of node embedding to domains involving dynamic graphs, where the structure of the graph is constantly changing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral graph convolution and GCNs\n",
    "\n",
    "See the lecture notes from class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN problems\n",
    "\n",
    "GNNs are generally used for three tasks:\n",
    "\n",
    "- Node classification\n",
    "- Link prediction\n",
    "- Graph classification\n",
    "\n",
    "### Node classification\n",
    "\n",
    "The goal of node classification is to predict the node embedding for each node in a graph. This type of problem is typically trained semi-supervised, with only a portion of the graph labeled. Citation networks, Reddit posts, YouTube videos, and Facebook friendships are examples of common node classification applications.\n",
    "\n",
    "### Link prediction\n",
    "\n",
    "The task of link prediction is to understand the relationship between entities in graphs and predict whether two entities are connected. A recommender system, for example, can be modeled as a link prediction problem. When we feed the model a collection of user reviews of various products, the task is to predict the users' preferences and tune the recommender system to push more relevant products based on the users' interests.\n",
    "\n",
    "### Graph classification\n",
    "\n",
    "The goal of graph classification is to divide the entire graph into different categories. It's similar to image classification, but the target is a graph. There are numerous industrial problems where graph classification can be used; for example, in chemistry, biomedicine, or physics, we can provide the model with a molecular structure and ask it to classify the target into meaningful categories. The model then speeds up the analysis of atoms, molecules, and other structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Applications\n",
    "\n",
    "### Natural Language Processing (NLP)\n",
    "\n",
    "GNN is frequently used in natural language processing (NLP), which is where GNN got its start. If you've worked with natural language processing (NLP), you're probably thinking that text is a type of sequential or temporal data that we can describe with a recurrent neural network (RNN) or a long short-term memory (LTSM). GNN, on the other hand, approaches the problem from an entirely different perspective. GNN predicts categories by utilizing the inner relationships of words or documents. A citation network, for example, attempts to predict each paper's label in a network based on the paper citation relationship and the words cited in other papers. GNN can also construct a syntactic model by examining different parts of sentences rather than only working sequentially as RNN or LTSM do.\n",
    "\n",
    "### Computer Vision\n",
    "\n",
    "Many GNN-based methods have achieved cutting-edge performance in image object detection, but we still don't know the relationships between the objects. Using graphs to model relationships between objects detected by a CNN-based detector is one successful application of GNN in computer vision (CV). After detecting objects in images, they are fed into a GNN inference for relationship prediction. The GNN inference produces a generated graph that models the relationships between various objects.\n",
    "\n",
    "<img src=\"img/16_gnn.png\" title=\"\" style=\"width: 500px;\" />\n",
    "\n",
    "Image generation from graph descriptions is another intriguing CV application. This is almost the inverse of the preceding application. Text-to-image generation using generative adversarial network (GAN) or autoencoder is the traditional method of image generation. Rather than using text to describe images, graph-to-image generation provides more information about the semantic structures of the images.\n",
    "\n",
    "<img src=\"img/17_gnn.png\" title=\"\" style=\"width: 500px;\" />\n",
    "\n",
    "The most intriguing application is zero-shot learning (ZSL), which learns to classify an object with no target class training samples. If no training samples are provided, the model must think in order to recognize a target. Assume we're given three images and told to find an okapi among them. We've never seen an okapi before, but if we're also told that an okapi is a deer-faced animal with four legs and zebra-striped skin, it's not difficult to figure out which one is an okapi. The detected features are typically converted into text to simulate this thought process. Text encodings, on the other hand, are independent of one another. The relationships between the text descriptions are difficult to model. Graph representations, on the other hand, accurately model these relationships and assist the machine in thinking more like a human.\n",
    "\n",
    "<img src=\"img/18_gnn.png\" title=\"\" style=\"width: 500px;\" />\n",
    "\n",
    "### Other applications\n",
    "\n",
    "Human behavior detection, traffic control, molecular structure study, recommender systems, program verification, logical reasoning, social influence prediction, and adversarial attack prevention are some of the more practical applications of GNN. Through social network analysis, for example, GNN can be used to cluster people into different community groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for PyTorch Geometric (PyG)\n",
    "\n",
    "PyG only seems to work with recent versions of PyTorch, so you may need to upgrade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set proxy for AIT\n",
    "\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "# Install newer torch version and PyG\n",
    "\n",
    "!pip install --upgrade torch\n",
    "!pip install torch_geometric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to restart your kernel if you're doing this in Jupyter.\n",
    "\n",
    "If you want to use some of the datasets that involve large sparse matrices, you may need\n",
    "a proper installation of the `pytorch-sparse` package. As of the time of writing, we found\n",
    "the following to work:\n",
    "\n",
    "    pip3 install torch==1.13.1+cu117 torchvision==0.14.1+cu117 \\\n",
    "                 torchaudio==0.13.1 torch_geometric --extra-index-url https://download.pytorch.org/whl/cu117\n",
    "    pip3 install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu117.html\n",
    "\n",
    "The main thing seems to be that the versions of `torch-scatter` and `torch-sparse` need to\n",
    "match your PyTorch and CUDA versions.\n",
    "\n",
    "## Our first graph\n",
    "\n",
    "OK, with that set up, let's use PyG to build a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that this defines a graph with three nodes and two edges. The edge index\n",
    "is in so-called [COO format](https://pytorch.org/docs/stable/sparse.html#sparse-coo-docs) (a format for representing sparse matrices)\n",
    "and in this case is a $2\\times 2|E|$ tensor.\n",
    "\n",
    "The indices are indexing the set of nodes, in the range 0 to $N-1$.\n",
    "\n",
    "The following is equivalent. Note that each undirected edge is denoted by two pairs of indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor `x` is providing the *features* of the nodes in the graph, in this case a scalar for each node. As we know,\n",
    "node features can be vectors as well, but all nodes must have the same feature dimensionality.\n",
    "\n",
    "We can check the validity of our graph with the `validate()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.validate(raise_on_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try some other attributes and:\n",
    "- `x`\n",
    "- `edge_index`\n",
    "- `edge_attr`\n",
    "- `num_nodes`\n",
    "- `num_edges`\n",
    "- `num_node_features`\n",
    "- `has_isolated_nodes()`\n",
    "- `has_self_loops`\n",
    "- `is_directed`\n",
    "\n",
    "And you can move a graph to a GPU just like a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG datasets (Cora)\n",
    "\n",
    "Let's load the Cora dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='./data/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a few of the dataset's methods:\n",
    "- `len(dataset)`\n",
    "- `dataset.num_classes`\n",
    "- `dataset.num_node_features`\n",
    "- `dataset[0]`\n",
    "\n",
    "From this we see that Cora is a single graph.\n",
    "We will only be doing transduction with this dataset.\n",
    "After assigning the single graph to a variable such as `data`,\n",
    "explore its characteristics:\n",
    "- `data.is_undirected()`\n",
    "- `data.train_mask.sum().item()`\n",
    "- `data.val_mask.sum().item()`\n",
    "- `data.test_mask.sum().item()`\n",
    "\n",
    "As this graph is mainly used to test semi-supervised learning algorithms, we see that the validation and test data are more numerous than the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batches\n",
    "\n",
    "How can we train on multiple examples in parallel? PyG puts multiple graphs together with block-diagonal adjacency matrices and concatenated features.\n",
    "See the [tutorial section on mini-batches](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html#mini-batches) for more\n",
    "information.\n",
    "\n",
    "For a GCN on Cora, however, we don't need fancy data loaders or parallel mini-batches, as we're dealing with just one graph.\n",
    "\n",
    "## Define a GCN\n",
    "\n",
    "So let's define a GCN for Cora, then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving the model to a GPU and training is the same as for any other PyTorch model. The \"data\" is treated as a single example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we an evaluate on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7950\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Implement early stopping using the validation set for the Cora GCN.\n",
    "2. Reproduce the rest of the results from Kipf and Welling with your GCN.\n",
    "3. Implement the [Graph Attention Network](https://arxiv.org/abs/1710.10903) and reproduce their results on the datasets available via PyG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import nell\n",
    "\n",
    "dataset = nell.NELL(root='./data/NELL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
