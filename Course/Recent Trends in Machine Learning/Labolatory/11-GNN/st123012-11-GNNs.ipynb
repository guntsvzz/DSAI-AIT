{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTML Lab 11: GNNs\n",
    "\n",
    "Today we explore GNNs, in particular [Graph Convolutional Networks by Kipf and Welling (2017)](https://arxiv.org/abs/1609.02907).\n",
    "\n",
    "This tutorial is based on the [PyTorch Geometric tutorial for GCN](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html).\n",
    "\n",
    "## Setup\n",
    "\n",
    "PyG only seems to work with recent versions of PyTorch, so you may need to upgrade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 123012\n",
    "name = 'Todsavad Tangtortan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch\n",
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to restart your kernel if you're doing this in Jupyter.\n",
    "\n",
    "## Our first graph\n",
    "\n",
    "OK, with that set up, let's use PyG to build a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric\n",
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "    \n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that this defines a graph with three nodes and two edges. The edge index\n",
    "is in so-called [COO format](https://pytorch.org/docs/stable/sparse.html#sparse-coo-docs) (a format for representing sparse matrices)\n",
    "and in this case is a $2\\times 2|E|$ tensor.\n",
    "\n",
    "The indices are indexing the set of nodes, in the range 0 to $N-1$.\n",
    "\n",
    "The following is equivalent. Note that each undirected edge is denoted by two pairs of indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensor `x` is providing the *features* of the nodes in the graph, in this case a scalar for each node. As we know,\n",
    "node features can be vectors as well, but all nodes must have the same feature dimensionality.\n",
    "\n",
    "We can check the validity of our graph with the `validate()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.validate(raise_on_error=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try some other attributes and:\n",
    "- `x`\n",
    "- `edge_index`\n",
    "- `edge_attr`\n",
    "- `num_nodes`\n",
    "- `num_edges`\n",
    "- `num_node_features`\n",
    "- `has_isolated_nodes()`\n",
    "- `has_self_loops()`\n",
    "- `is_directed()`\n",
    "\n",
    "And you can move a graph to a GPU just like a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG datasets (Cora)\n",
    "\n",
    "Let's load the Cora dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='./data/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a few of the dataset's methods:\n",
    "- `len(dataset)`\n",
    "- `dataset.num_classes`\n",
    "- `dataset.num_node_features`\n",
    "- `dataset[0]`\n",
    "\n",
    "From this we see that Cora is a single graph.\n",
    "We will only be doing transduction with this dataset.\n",
    "After assigning the single graph to a variable such as `data`,\n",
    "explore its characteristics:\n",
    "- `data.is_undirected()`\n",
    "- `data.train_mask.sum().item()`\n",
    "- `data.val_mask.sum().item()`\n",
    "- `data.test_mask.sum().item()`\n",
    "\n",
    "As this graph is mainly used to test semi-supervised learning algorithms, we see that the validation and test data are more numerous than the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batches\n",
    "\n",
    "How can we train on multiple examples in parallel? PyG puts multiple graphs together with block-diagonal adjacency matrices and concatenated features.\n",
    "See the [tutorial section on mini-batches](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html#mini-batches) for more\n",
    "information.\n",
    "\n",
    "For a GCN on Cora, however, we don't need fancy data loaders or parallel mini-batches, as we're dealing with just one graph.\n",
    "\n",
    "## Define a GCN\n",
    "\n",
    "So let's define a GCN for Cora, then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving the model to a GPU and training is the same as for any other PyTorch model. The \"data\" is treated as a single example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 50\n",
      "Epoch : 100\n",
      "Epoch : 150\n",
      "Epoch : 200\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 50 == 0: \n",
    "        print(f'Epoch : {epoch+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we an evaluate on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7970\n"
     ]
    }
   ],
   "source": [
    "model.eval() #No dropout\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Implement early stopping using the validation set for the Cora GCN.\n",
    "2. Reproduce the rest of the results from Kipf and Welling with your GCN.\n",
    "3. Implement the [Graph Attention Network](https://arxiv.org/abs/1710.10903) and reproduce their results on the datasets available via PyG.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Early Stopping \n",
    "Implement early stopping using the validation set for the Cora GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def valid(data):\n",
    "    model.eval() #No dropout\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.val_mask], data.y[data.val_mask])\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def test(data):\n",
    "    model.eval() #No dropout\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "    acc = int(correct) / int(data.test_mask.sum())\n",
    "    return acc\n",
    "\n",
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
    "    counter = 0\n",
    "    if (validation_loss - train_loss) > min_delta:\n",
    "        counter +=1\n",
    "        if counter >= tolerance:\n",
    "          return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 050, Loss: 0.7416, Test Acc: 0.7990\n",
      "Epoch : 100, Loss: 0.7499, Test Acc: 0.8110\n",
      "Epoch : 150, Loss: 0.7670, Test Acc: 0.8090\n",
      "Epoch : 200, Loss: 0.7974, Test Acc: 0.8030\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# best_val_loss = final_acc = 0 \n",
    "val_loss_old = np.infty\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(data)\n",
    "    val_loss  = valid(data)\n",
    "    test_acc = test(data)\n",
    "    # early stopping\n",
    "    if early_stopping(train_loss, val_loss, min_delta=1, tolerance = 10):\n",
    "      print(\"We are at epoch:\", epoch)\n",
    "      break\n",
    "\n",
    "    if (epoch+1) % 50 == 0: \n",
    "        print(f'Epoch : {epoch+1:03d}, Loss: {val_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kipf and Welling\n",
    "Reproduce the rest of the results from Kipf and Welling with your GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import NELL\n",
    "\n",
    "dataset_Citeseer = Planetoid(root='./data/Citeseer', name='Citeseer')\n",
    "dataset_Pubmed = Planetoid(root='./data/Pubmed', name='Pubmed')\n",
    "# dataset_NELL = NELL(root='./data/NELL')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GAT via PyG\n",
    "Implement the [Graph Attention Network](https://arxiv.org/abs/1710.10903) and reproduce their results on the datasets available via PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT_Transductive(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.head = 8\n",
    "        self.feature = 8 \n",
    "        self.conv1 = GATConv(in_channels = dataset.num_node_features, \n",
    "                             out_channels = self.feature, \n",
    "                             heads = self.head, \n",
    "                             dropout=0.6)\n",
    "        self.conv2 = GATConv(in_channels = self.feature * self.head, \n",
    "                             out_channels = dataset.num_classes, \n",
    "                             heads=1, \n",
    "                             concat=True,\n",
    "                             dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset_cora = Planetoid(root='./data/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 050 Loss : 0.3682\n",
      "Epoch : 100 Loss : 0.2445\n",
      "Epoch : 150 Loss : 0.3151\n",
      "Epoch : 200 Loss : 0.2876\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAT_Transductive().to(device)\n",
    "data = dataset_cora[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 50 == 0: \n",
    "        print(f'Epoch : {epoch+1:03d} Loss : {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we an evaluate on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "model.eval() #No dropout\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
