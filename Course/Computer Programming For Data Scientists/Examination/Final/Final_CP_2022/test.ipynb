{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Conv2d(3, 256, 3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 3, 3])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6912\n",
      "   256\n",
      "______\n",
      "  7168\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "    \n",
    "count_parameters(model) #why 400?, why 40000????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.LSTM(4,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 4])\n",
      "torch.Size([200, 50])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   800\n",
      " 10000\n",
      "   200\n",
      "   200\n",
      "______\n",
      " 11200\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    for item in params:\n",
    "        print(f'{item:>6}')\n",
    "    print(f'______\\n{sum(params):>6}')\n",
    "    \n",
    "count_parameters(model) #why 400?, why 40000????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim,embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim,hidden_dim,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim,output_dim)\n",
    "    def forward(self,text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, hn = self.rnn(embedded)\n",
    "        out = hn.squeeze(0)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Guntsv\\Downloads\\AIT\\AT82.01 Computer Programming for Data Science and Artificial Intelligence (PDS)\\Final_Examination\\test.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m RNN()\n",
      "\u001b[1;32mc:\\Users\\Guntsv\\Downloads\\AIT\\AT82.01 Computer Programming for Data Science and Artificial Intelligence (PDS)\\Final_Examination\\test.ipynb Cell 9\u001b[0m in \u001b[0;36mRNN.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(input_dim,emdbed_dim)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mRNN(embed_dim,hidden_dim,batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(hidden_dim,output_dim)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_dim' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_cnn,self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3,8,1,1,1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(8,32,1,1,1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Linear(32*19*19,10)\n",
    "        self.drop_out = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.drop_out(x1)\n",
    "        x3 = self.layer(x2)\n",
    "        x4 = self.drop_out(x3)\n",
    "        a,b,c,d = x4.shape\n",
    "        x5 = x4.shape(x4.size(0),-1)\n",
    "        out = self.fc(x5)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected 2D or 3D input (got 4D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Guntsv\\Downloads\\AIT\\AT82.01 Computer Programming for Data Science and Artificial Intelligence (PDS)\\Final_Examination\\test.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m my_cnn()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m random_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand((\u001b[39m100\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m32\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m out \u001b[39m=\u001b[39m model(random_image)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m out\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\Guntsv\\Downloads\\AIT\\AT82.01 Computer Programming for Data Science and Artificial Intelligence (PDS)\\Final_Examination\\test.ipynb Cell 11\u001b[0m in \u001b[0;36mmy_cnn.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     x2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop_out(x1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Downloads/AIT/AT82.01%20Computer%20Programming%20for%20Data%20Science%20and%20Artificial%20Intelligence%20%28PDS%29/Final_Examination/test.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     x3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer(x2)\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:135\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_input_dim(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    137\u001b[0m     \u001b[39m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[39m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[39m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:298\u001b[0m, in \u001b[0;36mBatchNorm1d._check_input_dim\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_input_dim\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    297\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 298\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    299\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mexpected 2D or 3D input (got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39mD input)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim())\n\u001b[0;32m    300\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: expected 2D or 3D input (got 4D input)"
     ]
    }
   ],
   "source": [
    "model = my_cnn()\n",
    "random_image = torch.rand((100,3,32,32))\n",
    "out = model(random_image)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
