{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym-super-mario-bros in c:\\python3.10.4\\lib\\site-packages (7.4.0)\n",
      "Requirement already satisfied: nes-py>=8.1.4 in c:\\python3.10.4\\lib\\site-packages (from gym-super-mario-bros) (8.2.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\python3.10.4\\lib\\site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.23.4)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in c:\\python3.10.4\\lib\\site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.5.21)\n",
      "Requirement already satisfied: gym>=0.17.2 in c:\\python3.10.4\\lib\\site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (0.26.2)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\python3.10.4\\lib\\site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (4.64.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\python3.10.4\\lib\\site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\python3.10.4\\lib\\site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (2.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\guntsv\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.48.2->nes-py>=8.1.4->gym-super-mario-bros) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym-super-mario-bros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym==0.21.0\n",
      "  Using cached gym-0.21.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\python3.10.4\\lib\\site-packages (from gym==0.21.0) (1.23.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\python3.10.4\\lib\\site-packages (from gym==0.21.0) (2.1.0)\n",
      "Installing collected packages: gym\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.26.2\n",
      "    Uninstalling gym-0.26.2:\n",
      "      Successfully uninstalled gym-0.26.2\n",
      "Successfully installed gym-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gym==0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from tqdm import trange\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.26.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it gym_super_mario_bros environment\n",
    "It requires to use gym environment version : 0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "# Super Mario environment for OpenAI Gym\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT,COMPLEX_MOVEMENT \n",
    "# env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", render_mode='human', apply_api_compatibility=True)\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "\n",
    "done = True\n",
    "for step in range(1000):\n",
    "    if done:\n",
    "        next_state = env.reset()\n",
    "    next_state, reward, done,_, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    # img=env.render(mode=\"rgb_array\")\n",
    "    \n",
    "env.close()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.10.4\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v1 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Python3.10.4\\lib\\site-packages\\gym\\envs\\registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Python3.10.4\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Guntsv\\Documents\\GitHub\\ML_Project\\mario.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/ML_Project/mario.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m    score \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/ML_Project/mario.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m    \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/ML_Project/mario.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m       next_state, reward, done,_, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(env\u001b[39m.\u001b[39;49maction_space\u001b[39m.\u001b[39;49msample())    \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/ML_Project/mario.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m       score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guntsv/Documents/GitHub/ML_Project/mario.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpisode:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m Score:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(episode, score))\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py:74\u001b[0m, in \u001b[0;36mJoypadSpace.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mTake a step using the given action.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m# take the step and record the output\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_action_map[action])\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m     \u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\gym\\wrappers\\compatibility.py:105\u001b[0m, in \u001b[0;36mEnvCompatibility.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, \u001b[39mfloat\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mbool\u001b[39m, Dict]:\n\u001b[0;32m     97\u001b[0m     \u001b[39m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     obs, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    108\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Python3.10.4\\lib\\site-packages\\nes_py\\nes_env.py:300\u001b[0m, in \u001b[0;36mNESEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrollers[\u001b[39m0\u001b[39m][:] \u001b[39m=\u001b[39m action\n\u001b[0;32m    299\u001b[0m \u001b[39m# pass the action to the emulator as an unsigned byte\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m _LIB\u001b[39m.\u001b[39;49mStep(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_env)\n\u001b[0;32m    301\u001b[0m \u001b[39m# get the reward for this step\u001b[39;00m\n\u001b[0;32m    302\u001b[0m reward \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_reward())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import time\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# Super Mario environment for OpenAI Gym\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT,COMPLEX_MOVEMENT,RIGHT_ONLY \n",
    "env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v1\", render_mode='human', apply_api_compatibility=True)\n",
    "env = JoypadSpace(env, RIGHT_ONLY)\n",
    "height, width, channels = env.observation_space.shape\n",
    "# actions = env.action_space.n\n",
    "# env.unwrapped.get_action_meanings()\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "   next_state = env.reset()\n",
    "   done = False\n",
    "   score = 0 \n",
    "   while not done:\n",
    "      next_state, reward, done,_, info = env.step(env.action_space.sample())    \n",
    "      score += reward\n",
    "print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\epsilon$ decay schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay bufferm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNNDQN(nn.Module):\n",
    "#     def __init__(self, input_shape, num_actions):\n",
    "#         super(CNNDQN, self).__init__()\n",
    "#         self._input_shape = input_shape\n",
    "#         self._num_actions = num_actions\n",
    "\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "#             nn.ReLU())\n",
    "\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(self.feature_size, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, num_actions))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x).view(x.size()[0], -1)\n",
    "#         return self.fc(x)\n",
    "\n",
    "#     @property\n",
    "#     def feature_size(self):\n",
    "#         x = self.features(torch.zeros(1, *self._input_shape))\n",
    "#         return x.view(1, -1).size(1)\n",
    "\n",
    "#     def act(self, state, epsilon, device):\n",
    "#         if random.random() > epsilon:\n",
    "#             state = torch.FloatTensor(np.float32(state)).unsqueeze(0).to(device)\n",
    "#             q_value = self.forward(state)\n",
    "#             action = q_value.max(1)[1].item()\n",
    "#         else:\n",
    "#             action = random.randrange(self._num_actions)\n",
    "#         return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create gym_super_mario_bros environment, prepare DQN for training\n",
    "\n",
    "Next we set up a gym environment for the cartpole simulation, create a DQN model with Adam optimization, and create a replay buffer of length 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 256, 3),\n",
      " 0.0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "env.reset()\n",
    "next_state, reward, done, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot rewards and losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play in the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c81d839d3c4227cd770621df97fe8191838af02e7eef185a922d8250cb33d344"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
